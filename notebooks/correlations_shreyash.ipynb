{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from globals import * \n",
    "from utils import * \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is there a correlation between cultural values and comfortablity sharing data?\n",
    "--- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read ../data/survey_finalized.csv.\n",
      "\n",
      "Analyzing Individualism:\n",
      "Spearman Correlation with Individual Comfort Levels:\n",
      "  Q3.3: Correlation = 0.215, p-value = 0.003\n",
      "  Q3.4: Correlation = 0.274, p-value = 0.000\n",
      "  Q3.5: Correlation = nan, p-value = nan\n",
      "  Q3.6_1: Correlation = 0.182, p-value = 0.014\n",
      "  Q3.6_2: Correlation = 0.196, p-value = 0.008\n",
      "  Q3.6_3: Correlation = 0.148, p-value = 0.046\n",
      "  Q3.6_4: Correlation = 0.091, p-value = 0.222\n",
      "  Q3.6_5: Correlation = 0.073, p-value = 0.323\n",
      "  Q3.6_6: Correlation = 0.108, p-value = 0.146\n",
      "  Q3.6_7: Correlation = 0.030, p-value = 0.689\n",
      "Chi-Square Test with Individual Comfort Levels:\n",
      "  Q3.3: Chi2 = 11.588, p-value = 0.072\n",
      "  Q3.4: Chi2 = 32.873, p-value = 0.000\n",
      "  Q3.5: Chi2 = 0.000, p-value = 1.000\n",
      "  Q3.6_1: Chi2 = 10.170, p-value = 0.118\n",
      "  Q3.6_2: Chi2 = 12.089, p-value = 0.060\n",
      "  Q3.6_3: Chi2 = 6.867, p-value = 0.333\n",
      "  Q3.6_4: Chi2 = 5.067, p-value = 0.535\n",
      "  Q3.6_5: Chi2 = 8.353, p-value = 0.213\n",
      "  Q3.6_6: Chi2 = 11.687, p-value = 0.069\n",
      "  Q3.6_7: Chi2 = 5.833, p-value = 0.442\n",
      "Spearman Correlation with Overall Comfort: Correlation = 0.309, p-value = 0.000\n",
      "Chi-Square Test with Overall Comfort: Chi2 = 17.573, p-value = 0.040\n",
      "\n",
      "Analyzing Collectivism:\n",
      "Spearman Correlation with Individual Comfort Levels:\n",
      "  Q3.3: Correlation = 0.164, p-value = 0.027\n",
      "  Q3.4: Correlation = 0.360, p-value = 0.000\n",
      "  Q3.5: Correlation = nan, p-value = nan\n",
      "  Q3.6_1: Correlation = 0.114, p-value = 0.126\n",
      "  Q3.6_2: Correlation = 0.274, p-value = 0.000\n",
      "  Q3.6_3: Correlation = 0.117, p-value = 0.116\n",
      "  Q3.6_4: Correlation = 0.135, p-value = 0.069\n",
      "  Q3.6_5: Correlation = 0.095, p-value = 0.201\n",
      "  Q3.6_6: Correlation = 0.086, p-value = 0.249\n",
      "  Q3.6_7: Correlation = 0.023, p-value = 0.759\n",
      "Chi-Square Test with Individual Comfort Levels:\n",
      "  Q3.3: Chi2 = 21.289, p-value = 0.002\n",
      "  Q3.4: Chi2 = 74.710, p-value = 0.000\n",
      "  Q3.5: Chi2 = 0.000, p-value = 1.000\n",
      "  Q3.6_1: Chi2 = 8.823, p-value = 0.184\n",
      "  Q3.6_2: Chi2 = 23.504, p-value = 0.001\n",
      "  Q3.6_3: Chi2 = 8.675, p-value = 0.193\n",
      "  Q3.6_4: Chi2 = 11.661, p-value = 0.070\n",
      "  Q3.6_5: Chi2 = 7.103, p-value = 0.311\n",
      "  Q3.6_6: Chi2 = 16.412, p-value = 0.012\n",
      "  Q3.6_7: Chi2 = 2.455, p-value = 0.874\n",
      "Spearman Correlation with Overall Comfort: Correlation = 0.326, p-value = 0.000\n",
      "Chi-Square Test with Overall Comfort: Chi2 = 47.183, p-value = 0.000\n",
      "\n",
      "Analyzing Family Values:\n",
      "Spearman Correlation with Individual Comfort Levels:\n",
      "  Q3.3: Correlation = 0.182, p-value = 0.014\n",
      "  Q3.4: Correlation = 0.412, p-value = 0.000\n",
      "  Q3.5: Correlation = nan, p-value = nan\n",
      "  Q3.6_1: Correlation = -0.001, p-value = 0.993\n",
      "  Q3.6_2: Correlation = 0.105, p-value = 0.158\n",
      "  Q3.6_3: Correlation = 0.187, p-value = 0.011\n",
      "  Q3.6_4: Correlation = 0.251, p-value = 0.001\n",
      "  Q3.6_5: Correlation = 0.162, p-value = 0.029\n",
      "  Q3.6_6: Correlation = 0.102, p-value = 0.171\n",
      "  Q3.6_7: Correlation = 0.056, p-value = 0.455\n",
      "Chi-Square Test with Individual Comfort Levels:\n",
      "  Q3.3: Chi2 = 13.271, p-value = 0.039\n",
      "  Q3.4: Chi2 = 44.578, p-value = 0.000\n",
      "  Q3.5: Chi2 = 0.000, p-value = 1.000\n",
      "  Q3.6_1: Chi2 = 4.288, p-value = 0.638\n",
      "  Q3.6_2: Chi2 = 6.458, p-value = 0.374\n",
      "  Q3.6_3: Chi2 = 10.858, p-value = 0.093\n",
      "  Q3.6_4: Chi2 = 15.491, p-value = 0.017\n",
      "  Q3.6_5: Chi2 = 7.264, p-value = 0.297\n",
      "  Q3.6_6: Chi2 = 3.898, p-value = 0.690\n",
      "  Q3.6_7: Chi2 = 3.586, p-value = 0.732\n",
      "Spearman Correlation with Overall Comfort: Correlation = 0.305, p-value = 0.000\n",
      "Chi-Square Test with Overall Comfort: Chi2 = 17.165, p-value = 0.046\n",
      "Analysis complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Baldw\\AppData\\Local\\Temp\\ipykernel_31100\\3280801300.py:63: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  correlation, p_value = spearmanr(valid_data[value_col], valid_data[comfort_col])\n",
      "C:\\Users\\Baldw\\AppData\\Local\\Temp\\ipykernel_31100\\3280801300.py:63: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  correlation, p_value = spearmanr(valid_data[value_col], valid_data[comfort_col])\n",
      "C:\\Users\\Baldw\\AppData\\Local\\Temp\\ipykernel_31100\\3280801300.py:63: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  correlation, p_value = spearmanr(valid_data[value_col], valid_data[comfort_col])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import spearmanr, chi2_contingency\n",
    "\n",
    "# Define mappings\n",
    "importance_mapping = {\n",
    "    'Extremely  Important': 5,\n",
    "    'Very Important': 4,\n",
    "    'Moderately Important': 3,\n",
    "    'Somewhat Important': 2,\n",
    "    'Slightly Important': 1,\n",
    "    'Not Familiar At All': 0  # Assuming this is the lowest importance\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "comfort_mapping = {\n",
    "    'Extremely': 5,\n",
    "    'Somewhat': 3,\n",
    "    'No': 1,\n",
    "    'Extremely Uncomfortable': 1,\n",
    "    'Somewhat Comfortable': 4,\n",
    "    'Yes': 4  # Inferred from context\n",
    "}\n",
    "\n",
    "# Define relevant columns\n",
    "value_columns = {\n",
    "    'Individualism': 'Q5.1_1',  # Adjust based on actual column name\n",
    "    'Collectivism': 'Q5.1_2',   # Adjust based on actual column name\n",
    "    'Family Values': 'Q5.1_14'  # Adjust based on actual column name\n",
    "}\n",
    "\n",
    "comfort_columns = [\n",
    "    'Q3.3', 'Q3.4', 'Q3.5', 'Q3.6_1', 'Q3.6_2', 'Q3.6_3', 'Q3.6_4',\n",
    "    'Q3.6_5', 'Q3.6_6', 'Q3.6_7', \n",
    "]\n",
    "\n",
    "def read_and_clean_csv(file_path):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, encoding='utf-8')\n",
    "        print(f\"Successfully read {file_path}.\")\n",
    "        return df\n",
    "    except UnicodeDecodeError:\n",
    "        print(f\"Failed to read {file_path} with utf-8 encoding.\")\n",
    "        return None\n",
    "\n",
    "def map_responses(df, mapping, columns):\n",
    "    for col in columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].map(mapping).fillna(0)  # Fill NaN with 0 for unmapped responses\n",
    "    return df\n",
    "\n",
    "def calculate_overall_comfort(df, comfort_columns):\n",
    "    df['Overall_Comfort'] = df[comfort_columns].mean(axis=1, skipna=True)\n",
    "    return df\n",
    "\n",
    "def perform_spearman_test(df, value_col, comfort_cols):\n",
    "    results = {}\n",
    "    for comfort_col in comfort_cols:\n",
    "        if value_col in df.columns and comfort_col in df.columns:\n",
    "            valid_data = df[[value_col, comfort_col]].dropna()\n",
    "            if len(valid_data) > 1:  # Ensure enough data for correlation\n",
    "                correlation, p_value = spearmanr(valid_data[value_col], valid_data[comfort_col])\n",
    "                results[comfort_col] = {'correlation': correlation, 'p_value': p_value}\n",
    "    return results\n",
    "\n",
    "def perform_chi_square_test(df, value_col, comfort_col):\n",
    "    if value_col in df.columns and comfort_col in df.columns:\n",
    "        # Create contingency table\n",
    "        contingency_table = pd.crosstab(df[value_col], df[comfort_col])\n",
    "        chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "        return {\n",
    "            'chi2': chi2,\n",
    "            'p_value': p,\n",
    "            'degrees_of_freedom': dof,\n",
    "            'expected': expected\n",
    "        }\n",
    "    return None\n",
    "\n",
    "def analyze_relationships(df):\n",
    "    # Map responses to numerical values\n",
    "    df = map_responses(df, importance_mapping, value_columns.values())\n",
    "    df = map_responses(df, comfort_mapping, comfort_columns)\n",
    "    df = calculate_overall_comfort(df, comfort_columns)\n",
    "\n",
    "    # Perform tests for each value and individual comfort levels\n",
    "    for value_name, value_col in value_columns.items():\n",
    "        print(f\"\\nAnalyzing {value_name}:\")\n",
    "        \n",
    "        # Spearman correlation for individual comfort levels\n",
    "        spearman_results = perform_spearman_test(df, value_col, comfort_columns)\n",
    "        print(f\"Spearman Correlation with Individual Comfort Levels:\")\n",
    "        for comfort_col, result in spearman_results.items():\n",
    "            print(f\"  {comfort_col}: Correlation = {result['correlation']:.3f}, p-value = {result['p_value']:.3f}\")\n",
    "\n",
    "        # Chi-square test for individual comfort levels\n",
    "        print(f\"Chi-Square Test with Individual Comfort Levels:\")\n",
    "        for comfort_col in comfort_columns:\n",
    "            chi2_result = perform_chi_square_test(df, value_col, comfort_col)\n",
    "            if chi2_result:\n",
    "                print(f\"  {comfort_col}: Chi2 = {chi2_result['chi2']:.3f}, p-value = {chi2_result['p_value']:.3f}\")\n",
    "\n",
    "        # Spearman correlation with overall comfort\n",
    "        valid_data = df[[value_col, 'Overall_Comfort']].dropna()\n",
    "        if len(valid_data) > 1:\n",
    "            correlation, p_value = spearmanr(valid_data[value_col], valid_data['Overall_Comfort'])\n",
    "            print(f\"Spearman Correlation with Overall Comfort: Correlation = {correlation:.3f}, p-value = {p_value:.3f}\")\n",
    "\n",
    "        # Chi-square test with overall comfort (categorized if needed)\n",
    "        df['Overall_Comfort_Category'] = pd.qcut(df['Overall_Comfort'], 4, labels=['Low', 'Medium-Low', 'Medium-High', 'High'])\n",
    "        chi2_result = perform_chi_square_test(df, value_col, 'Overall_Comfort_Category')\n",
    "        if chi2_result:\n",
    "            print(f\"Chi-Square Test with Overall Comfort: Chi2 = {chi2_result['chi2']:.3f}, p-value = {chi2_result['p_value']:.3f}\")\n",
    "\n",
    "# Main execution\n",
    "df = read_and_clean_csv(\"../data/survey_finalized.csv\")\n",
    "if df is not None:\n",
    "    analyze_relationships(df)\n",
    "    print(\"Analysis complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read ../data/survey_finalized.csv.\n",
      "Unique values in Q5.1_1 before mapping: ['How important are the following values to you when it comes to online privacy? - Indivisualism (e.g. Independence)'\n",
      " 'Extremely Important' 'Slightly Important' 'Moderately Important'\n",
      " 'Very Important' 'Not at all Important']\n",
      "Unique values in Q5.1_1 after mapping: [0. 5. 1. 3. 4.]\n",
      "Unique values in Q5.1_2 before mapping: ['How important are the following values to you when it comes to online privacy? - Collectivism (e.g. Community influence)'\n",
      " 'Not at all Important' 'Moderately Important' 'Slightly Important'\n",
      " 'Very Important' 'Extremely Important']\n",
      "Unique values in Q5.1_2 after mapping: [0. 3. 1. 4. 5.]\n",
      "Unique values in Q5.1_14 before mapping: ['How important are the following values to you when it comes to online privacy? - Family Values (e.g. Importance of family relationships)'\n",
      " 'Very Important' 'Extremely Important' 'Moderately Important'\n",
      " 'Slightly Important' 'Not at all Important']\n",
      "Unique values in Q5.1_14 after mapping: [0. 4. 5. 3. 1.]\n",
      "Unique values in Q7.1 before mapping: ['How much influence does your cultural background and personal values have on your trust in social media platforms regarding privacy?'\n",
      " 'No Influence' 'Significant Influence' 'Moderate Influence'\n",
      " 'Minimal Influence' 'Extremely Significant Influence']\n",
      "Unique values in Q7.1 after mapping: [0. 3. 2. 1. 4.]\n",
      "\n",
      "=== Correlation Analysis: Importance of Values vs. Influence of Cultural Background on Trust ===\n",
      "\n",
      "Analyzing Individualism vs. Influence of Cultural Background (Q7.1):\n",
      "  Spearman Correlation: Correlation = 0.435, p-value = 0.000\n",
      "Warning: Some expected frequencies are less than 5 for Q5.1_1 vs. Q7.1. Chi-square results may be unreliable.\n",
      "  Chi-Square Test: Chi2 = 119.998, p-value = 0.000, Degrees of Freedom = 16\n",
      "\n",
      "Analyzing Collectivism vs. Influence of Cultural Background (Q7.1):\n",
      "  Spearman Correlation: Correlation = 0.459, p-value = 0.000\n",
      "Warning: Some expected frequencies are less than 5 for Q5.1_2 vs. Q7.1. Chi-square results may be unreliable.\n",
      "  Chi-Square Test: Chi2 = 111.126, p-value = 0.000, Degrees of Freedom = 16\n",
      "\n",
      "Analyzing Family Values vs. Influence of Cultural Background (Q7.1):\n",
      "  Spearman Correlation: Correlation = 0.406, p-value = 0.000\n",
      "Warning: Some expected frequencies are less than 5 for Q5.1_14 vs. Q7.1. Chi-square results may be unreliable.\n",
      "  Chi-Square Test: Chi2 = 71.993, p-value = 0.000, Degrees of Freedom = 16\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Cell to analyze correlation between importance of values and influence of cultural background\n",
    "\n",
    "# Define mappings\n",
    "importance_mapping = {\n",
    "    'Extremely Important': 5,\n",
    "    'Very Important': 4,\n",
    "    'Moderately Important': 3,\n",
    "    'Somewhat Important': 2,\n",
    "    'Slightly Important': 1,\n",
    "    'Not Familiar At All': 0\n",
    "}\n",
    "\n",
    "influence_mapping = {\n",
    "    'Extremely Significant Influence': 4,\n",
    "    'Significant Influence': 3,\n",
    "    'Moderate Influence': 2,\n",
    "    'Minimal Influence': 1,\n",
    "    'No Influence': 0\n",
    "}\n",
    "\n",
    "# Define value columns and influence column\n",
    "value_columns = {\n",
    "    'Individualism': 'Q5.1_1',\n",
    "    'Collectivism': 'Q5.1_2',\n",
    "    'Family Values': 'Q5.1_14'\n",
    "}\n",
    "\n",
    "def read_and_clean_csv(file_path):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, encoding='utf-8')\n",
    "        print(f\"Successfully read {file_path}.\")\n",
    "        return df\n",
    "    except UnicodeDecodeError:\n",
    "        print(f\"Failed to read {file_path} with utf-8 encoding.\")\n",
    "        return None\n",
    "\n",
    "\n",
    "df = read_and_clean_csv(\"../data/survey_finalized.csv\")\n",
    "\n",
    "\n",
    "influence_column = 'Q7.1'\n",
    "\n",
    "def map_responses(df, mapping, columns):\n",
    "    \"\"\"Map categorical responses to numerical values.\"\"\"\n",
    "    for col in columns:\n",
    "        if col in df.columns:\n",
    "            unique_vals_before = df[col].dropna().unique()\n",
    "            print(f\"Unique values in {col} before mapping: {unique_vals_before}\")\n",
    "            df[col] = df[col].map(mapping).fillna(0)\n",
    "            unique_vals_after = df[col].dropna().unique()\n",
    "            print(f\"Unique values in {col} after mapping: {unique_vals_after}\")\n",
    "            if df[col].eq(0).all() and len(unique_vals_before) > 1:\n",
    "                print(f\"Warning: All values in {col} mapped to 0 despite non-constant input. Check mapping keys: {mapping.keys()}\")\n",
    "        else:\n",
    "            print(f\"Warning: Column {col} not found in DataFrame.\")\n",
    "    return df\n",
    "\n",
    "def perform_spearman_test(df, value_col, target_col):\n",
    "    \"\"\"Perform Spearman correlation test between a value and a target column.\"\"\"\n",
    "    if value_col in df.columns and target_col in df.columns:\n",
    "        valid_data = df[[value_col, target_col]].dropna()\n",
    "        if len(valid_data) > 1:\n",
    "            if valid_data[value_col].nunique() == 1 or valid_data[target_col].nunique() == 1:\n",
    "                return {'correlation': None, 'p_value': None}\n",
    "            else:\n",
    "                correlation, p_value = spearmanr(valid_data[value_col], valid_data[target_col])\n",
    "                return {'correlation': correlation, 'p_value': p_value}\n",
    "        else:\n",
    "            return {'correlation': None, 'p_value': None}\n",
    "    else:\n",
    "        return {'correlation': None, 'p_value': None}\n",
    "\n",
    "def perform_chi_square_test(df, value_col, target_col):\n",
    "    \"\"\"Perform Chi-square test between a value and a target column.\"\"\"\n",
    "    if value_col in df.columns and target_col in df.columns:\n",
    "        contingency_table = pd.crosstab(df[value_col], df[target_col])\n",
    "        if contingency_table.size == 0 or contingency_table.shape[0] == 1 or contingency_table.shape[1] == 1:\n",
    "            return None\n",
    "        chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "        if (expected < 5).any():\n",
    "            print(f\"Warning: Some expected frequencies are less than 5 for {value_col} vs. {target_col}. Chi-square results may be unreliable.\")\n",
    "        return {\n",
    "            'chi2': chi2,\n",
    "            'p_value': p,\n",
    "            'degrees_of_freedom': dof,\n",
    "            'expected': expected\n",
    "        }\n",
    "    return None\n",
    "\n",
    "def analyze_value_influence_correlation(df):\n",
    "    \"\"\"Analyze correlation between importance of values and influence of cultural background.\"\"\"\n",
    "    # Validate columns\n",
    "    missing_value_cols = [col for col in value_columns.values() if col not in df.columns]\n",
    "    if missing_value_cols:\n",
    "        print(f\"Error: Missing value columns: {missing_value_cols}\")\n",
    "        return\n",
    "    if influence_column not in df.columns:\n",
    "        print(f\"Error: Missing influence column: {influence_column}\")\n",
    "        return\n",
    "\n",
    "    # Map responses\n",
    "    df = map_responses(df, importance_mapping, value_columns.values())\n",
    "    df = map_responses(df, influence_mapping, [influence_column])\n",
    "\n",
    "    # If all values are 0 after mapping and the input had variety, skip analysis with a clear message\n",
    "    all_zero = all(df[col].eq(0).all() for col in value_columns.values())\n",
    "    if all_zero and any(len(df[col].dropna().unique()) > 1 for col in value_columns.values()):\n",
    "        print(\"\\n=== Correlation Analysis: Importance of Values vs. Influence of Cultural Background on Trust ===\")\n",
    "        print(\"Error: All value columns mapped to 0 despite non-constant input. Correlation analysis skipped. Please update importance_mapping.\")\n",
    "        return\n",
    "\n",
    "    # Perform correlation analysis\n",
    "    print(\"\\n=== Correlation Analysis: Importance of Values vs. Influence of Cultural Background on Trust ===\")\n",
    "    for value_name, value_col in value_columns.items():\n",
    "        print(f\"\\nAnalyzing {value_name} vs. Influence of Cultural Background (Q7.1):\")\n",
    "        \n",
    "        # Spearman correlation\n",
    "        spearman_result = perform_spearman_test(df, value_col, influence_column)\n",
    "        if spearman_result['correlation'] is not None:\n",
    "            print(f\"  Spearman Correlation: Correlation = {spearman_result['correlation']:.3f}, p-value = {spearman_result['p_value']:.3f}\")\n",
    "        else:\n",
    "            print(f\"  Spearman Correlation: Insufficient data for correlation or constant values.\")\n",
    "\n",
    "        # Chi-square test\n",
    "        chi2_result = perform_chi_square_test(df, value_col, influence_column)\n",
    "        if chi2_result:\n",
    "            print(f\"  Chi-Square Test: Chi2 = {chi2_result['chi2']:.3f}, p-value = {chi2_result['p_value']:.3f}, \"\n",
    "                  f\"Degrees of Freedom = {chi2_result['degrees_of_freedom']}\")\n",
    "        else:\n",
    "            print(f\"  Chi-Square Test: Unable to perform Chi-square test (missing data or no variability).\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "# Assuming df is already loaded from the previous main() function\n",
    "# If running independently, uncomment the following lines:\n",
    "# df = read_and_clean_csv(\"../data/survey_finalized.csv\")\n",
    "# if df is not None:\n",
    "analyze_value_influence_correlation(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import spearmanr, chi2_contingency\n",
    "\n",
    "# Define mappings\n",
    "importance_mapping = {\n",
    "    'Extremely Important': 5,\n",
    "    'Very Important': 4,\n",
    "    'Moderately Important': 3,\n",
    "    'Somewhat Important': 2,\n",
    "    'Slightly Important': 1,\n",
    "    'Not Familiar At All': 0  # Assuming this is the lowest importance\n",
    "}\n",
    "\n",
    "# Mapping for Q9.1 frequency of checking privacy settings\n",
    "q9_1_mapping = {\n",
    "    'Yes, Always': 5,\n",
    "    'Yes, Sometimes': 4,\n",
    "    'No, Sometimes': 3,  # Adjusted based on image; might be a typo in your data\n",
    "    'No, Rarely': 2,\n",
    "    'No, Never': 1\n",
    "}\n",
    "\n",
    "# Define relevant columns\n",
    "value_columns = {\n",
    "    'Individualism': 'Q5.1_1',  # Adjust based on actual column name\n",
    "    'Collectivism': 'Q5.1_2',   # Adjust based on actual column name\n",
    "    'Family Values': 'Q5.1_14'  # Adjust based on actual column name\n",
    "}\n",
    "\n",
    "q9_1_column = 'Q9.1'  # Column for frequency of checking privacy settings\n",
    "\n",
    "def read_and_clean_csv(file_path):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, encoding='utf-8')\n",
    "        print(f\"Successfully read {file_path}.\")\n",
    "        return df\n",
    "    except UnicodeDecodeError:\n",
    "        print(f\"Failed to read {file_path} with utf-8 encoding.\")\n",
    "        return None\n",
    "\n",
    "def map_responses(df, mapping, columns):\n",
    "    for col in columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].map(mapping).fillna(0)  # Fill NaN with 0 for unmapped responses\n",
    "    return df\n",
    "\n",
    "def perform_spearman_test(df, value_col, q9_1_col):\n",
    "    if value_col in df.columns and q9_1_col in df.columns:\n",
    "        valid_data = df[[value_col, q9_1_col]].dropna()\n",
    "        if len(valid_data) > 1:  # Ensure enough data for correlation\n",
    "            correlation, p_value = spearmanr(valid_data[value_col], valid_data[q9_1_col])\n",
    "            return {'correlation': correlation, 'p_value': p_value}\n",
    "    return None\n",
    "\n",
    "def perform_chi_square_test(df, value_col, q9_1_col):\n",
    "    if value_col in df.columns and q9_1_col in df.columns:\n",
    "        # Create contingency table\n",
    "        contingency_table = pd.crosstab(df[value_col], df[q9_1_col])\n",
    "        chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "        return {\n",
    "            'chi2': chi2,\n",
    "            'p_value': p,\n",
    "            'degrees_of_freedom': dof,\n",
    "            'expected': expected\n",
    "        }\n",
    "    return None\n",
    "\n",
    "def analyze_relationships(df):\n",
    "    # Map responses to numerical values\n",
    "    df = map_responses(df, importance_mapping, value_columns.values())\n",
    "    df = map_responses(df, q9_1_mapping, [q9_1_column])\n",
    "\n",
    "    # Perform tests for each value and Q9.1\n",
    "    for value_name, value_col in value_columns.items():\n",
    "        print(f\"\\nAnalyzing {value_name} with Q9.1 (Frequency of Checking Privacy Settings):\")\n",
    "        \n",
    "        # Spearman correlation\n",
    "        spearman_result = perform_spearman_test(df, value_col, q9_1_column)\n",
    "        if spearman_result:\n",
    "            print(f\"Spearman Correlation: Correlation = {spearman_result['correlation']:.3f}, p-value = {spearman_result['p_value']:.3f}\")\n",
    "\n",
    "        # Chi-square test\n",
    "        chi2_result = perform_chi_square_test(df, value_col, q9_1_column)\n",
    "        if chi2_result:\n",
    "            print(f\"Chi-Square Test: Chi2 = {chi2_result['chi2']:.3f}, p-value = {chi2_result['p_value']:.3f}\")\n",
    "\n",
    "# Main execution\n",
    "df = read_and_clean_csv(\"../data/survey_finalized.csv\")\n",
    "if df is not None:\n",
    "    analyze_relationships(df)\n",
    "    print(\"Analysis complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
