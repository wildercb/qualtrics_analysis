{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "# Move to the survey results directory \n",
    "data_dir = '../../data'\n",
    "os.chdir(data_dir)\n",
    "\n",
    "ai_study = \"AI_Study_Finalized.csv\"\n",
    "track_a_file = \"track_a.csv\"\n",
    "track_b_file = \"track_b.csv\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A.1.2: What are the primary applications of AI in your products that you see today and envision for the near future? Select all that apply.\n",
      "Total valid responses: 107\n",
      "Total unique AI applications mentioned: 18\n",
      "Average percentage per application: 35.36%\n",
      "Most common application: Chatbots, Personal Assistants or Recommender Systems (79 selections, 73.83% of respondents)\n",
      "Least common application: Other, please explain (3 selections, 2.80% of respondents)\n",
      "\n",
      "Breakdown of responses:\n",
      "Chatbots, Personal Assistants or Recommender Systems: 79 selections (73.83% of respondents)\n",
      "Translation or Text Generation: 60 selections (56.07% of respondents)\n",
      "Customer Service: 58 selections (54.21% of respondents)\n",
      "Code Completion or Code Generation): 51 selections (47.66% of respondents)\n",
      "Programming Analysis (e.g.: 51 selections (47.66% of respondents)\n",
      "Predictive Analysis: 46 selections (42.99% of respondents)\n",
      "Healthcare: 43 selections (40.19% of respondents)\n",
      "Financial Services: 38 selections (35.51% of respondents)\n",
      "Cybersecurity: 36 selections (33.64% of respondents)\n",
      "Robotics and Automation: 36 selections (33.64% of respondents)\n",
      "Personalization and Advertisement: 34 selections (31.78% of respondents)\n",
      "Entertainment or Communication: 29 selections (27.10% of respondents)\n",
      "Logistics: 29 selections (27.10% of respondents)\n",
      "Computer Vision: 28 selections (26.17% of respondents)\n",
      "Human Resources: 25 selections (23.36% of respondents)\n",
      "Legal: 18 selections (16.82% of respondents)\n",
      "Retail: 17 selections (15.89% of respondents)\n",
      "Other, please explain: 3 selections (2.80% of respondents)\n"
     ]
    }
   ],
   "source": [
    "########\n",
    "#  A.1.2 \n",
    "########\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Read CSV file into a DataFrame\n",
    "df = pd.read_csv(ai_study)\n",
    "\n",
    "# Skip the first two rows\n",
    "df = df.iloc[2:].reset_index(drop=True)\n",
    "\n",
    "# Function to split responses, keeping special categories together\n",
    "def split_responses(response):\n",
    "    if pd.isna(response):\n",
    "        return []\n",
    "    parts = str(response).split(',')\n",
    "    result = []\n",
    "    i = 0\n",
    "    chatbot_category_added = False\n",
    "    while i < len(parts):\n",
    "        if i+1 < len(parts) and parts[i].strip() == \"Other\" and parts[i+1].strip() == \"please explain\":\n",
    "            result.append(\"Other, please explain\")\n",
    "            i += 2\n",
    "        elif i+1 < len(parts) and parts[i].strip() == \"Programming analysis (e.g.\" and parts[i+1].strip().startswith(\"Code completion or code generation\"):\n",
    "            result.append(\"Programming analysis (e.g., Code completion or code generation)\")\n",
    "            i += 2\n",
    "        elif not chatbot_category_added and (parts[i].strip() in [\"Chatbots\", \"Personal Assistants or Recommender Systems\"] or (i+1 < len(parts) and parts[i].strip() == \"Personal Assistants\" and parts[i+1].strip() == \"or Recommender Systems\")):\n",
    "            result.append(\"Chatbots, Personal Assistants or Recommender Systems\")\n",
    "            chatbot_category_added = True\n",
    "            i += 2 if parts[i].strip() == \"Personal Assistants\" else 1\n",
    "        elif chatbot_category_added and parts[i].strip() in [\"Chatbots\", \"Personal Assistants\", \"Recommender Systems\", \"Personal Assistants or Recommender Systems\"]:\n",
    "            i += 1  # Skip this part as we've already added the category\n",
    "        else:\n",
    "            result.append(parts[i].strip())\n",
    "            i += 1\n",
    "    return result\n",
    "\n",
    "# Apply the split_responses function to the 'A.1.2' column\n",
    "df['A.1.2_split'] = df['A.1.2'].apply(split_responses)\n",
    "\n",
    "# Count the number of responses for each option\n",
    "option_counts = df['A.1.2_split'].explode().value_counts()\n",
    "\n",
    "# Calculate the total number of valid responses (rows with non-empty lists)\n",
    "total_valid_responses = df['A.1.2_split'].apply(len).ne(0).sum()\n",
    "\n",
    "# Calculate percentages\n",
    "option_percentages = (option_counts / total_valid_responses * 100).round(2)\n",
    "\n",
    "# Create a DataFrame for plotting\n",
    "plot_df = pd.DataFrame({\n",
    "    'Option': option_counts.index,\n",
    "    'Count': option_counts.values,\n",
    "    'Percentage': option_percentages.values\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by Count in descending order\n",
    "plot_df = plot_df.sort_values('Count', ascending=False)\n",
    "\n",
    "# Create the bar plot\n",
    "fig = px.bar(plot_df, x='Option', y='Count',\n",
    "             title='Survey Results for A.1.2',\n",
    "             labels={'Option': 'AI Application', 'Count': 'Number of Selections'},\n",
    "             color='Percentage',\n",
    "             color_continuous_scale='Blues',\n",
    "             text=plot_df['Percentage'].apply(lambda x: f'{x:.1f}%'))\n",
    "\n",
    "# Adjust the layout for better readability\n",
    "fig.update_layout(\n",
    "    xaxis_tickangle=45,\n",
    "    xaxis_title=\"AI Application\",\n",
    "    yaxis_title=\"Number of Selections\",\n",
    "    uniformtext_minsize=8,\n",
    "    uniformtext_mode='hide'\n",
    ")\n",
    "\n",
    "# Update traces to position and style the text\n",
    "fig.update_traces(texttemplate='%{text}', textposition='inside')\n",
    "\n",
    "# Adjust y-axis to ensure all labels are visible\n",
    "fig.update_layout(yaxis_range=[0, plot_df['Count'].max() * 1.1])\n",
    "\n",
    "# Show the plot\n",
    "fig.show(renderer=\"browser\")\n",
    "\n",
    "# Statistical Analysis\n",
    "total_options = len(plot_df)\n",
    "average_percentage = plot_df['Percentage'].mean()\n",
    "most_common = plot_df.iloc[0]\n",
    "least_common = plot_df.iloc[-1]\n",
    "\n",
    "print(\"A.1.2: What are the primary applications of AI in your products that you see today and envision for the near future? Select all that apply.\")\n",
    "print(f\"Total valid responses: {total_valid_responses}\")\n",
    "print(f\"Total unique AI applications mentioned: {total_options}\")\n",
    "print(f\"Average percentage per application: {average_percentage:.2f}%\")\n",
    "print(f\"Most common application: {most_common['Option']} ({most_common['Count']} selections, {most_common['Percentage']:.2f}% of respondents)\")\n",
    "print(f\"Least common application: {least_common['Option']} ({least_common['Count']} selections, {least_common['Percentage']:.2f}% of respondents)\")\n",
    "\n",
    "print(\"\\nBreakdown of responses:\")\n",
    "for _, row in plot_df.iterrows():\n",
    "    print(f\"{row['Option']}: {row['Count']} selections ({row['Percentage']:.2f}% of respondents)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A.1.3 Frequency of AI Tool Usage\n",
      "Total valid responses: 107\n",
      "Total unique frequency options: 6\n",
      "Average responses per option: 17.83\n",
      "Most common frequency: Daily (36 responses, 33.64% of respondents)\n",
      "Least common frequency: Prefer not to say (1 responses, 0.93% of respondents)\n",
      "\n",
      "Breakdown of responses:\n",
      "Daily: 36 responses (33.64% of respondents)\n",
      "4-6 times a week: 30 responses (28.04% of respondents)\n",
      "1-3 times a week: 22 responses (20.56% of respondents)\n",
      "Rarely: 17 responses (15.89% of respondents)\n",
      "Never: 1 responses (0.93% of respondents)\n",
      "Prefer not to say: 1 responses (0.93% of respondents)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Step 1: Read CSV file into a DataFrame\n",
    "df = pd.read_csv(ai_study)\n",
    "\n",
    "# Step 2: Exclude the first two rows\n",
    "df = df.iloc[2:]\n",
    "\n",
    "# Step 3: Remove NaNs or empty values in 'A.1.3'\n",
    "df = df[df['A.1.3'].notna()]  # Remove NaNs\n",
    "df['A.1.3'] = df['A.1.3'].astype(str).apply(lambda x: x.strip())\n",
    "df = df[df['A.1.3'] != \"\"]  # Remove empty strings\n",
    "\n",
    "# Step 4: Count occurrences of each response\n",
    "response_counts = df['A.1.3'].value_counts().reset_index()\n",
    "response_counts.columns = ['Response', 'Count']\n",
    "\n",
    "# Step 5: Calculate total number of valid responses\n",
    "total_valid_responses = df.shape[0]\n",
    "\n",
    "# Step 6: Calculate the percentage of each option based on valid responses\n",
    "response_counts['Percentage'] = (response_counts['Count'] / total_valid_responses * 100).round(2)\n",
    "\n",
    "# Step 7: Visualize the results with a Pie Chart using Plotly\n",
    "fig = px.pie(response_counts, names='Response', values='Count',\n",
    "             title='Frequency of AI Tool Usage (A.1.3)',\n",
    "             color_discrete_sequence=px.colors.sequential.Blues,\n",
    "             labels={'Response': 'Usage Frequency', 'Count': 'Number of Responses'})\n",
    "\n",
    "# Add percentage text to the pie slices\n",
    "fig.update_traces(textinfo='percent+label')\n",
    "\n",
    "# Step 8: Show the figure\n",
    "fig.show(renderer=\"browser\")\n",
    "\n",
    "# Step 9: Print summary results\n",
    "total_responses = response_counts['Count'].sum()\n",
    "total_options = len(response_counts)\n",
    "average_responses = total_responses / total_options\n",
    "most_common = response_counts.iloc[0]\n",
    "least_common = response_counts.iloc[-1]\n",
    "\n",
    "question_text = \"A.1.3 Frequency of AI Tool Usage\"\n",
    "print(question_text)\n",
    "print(f\"Total valid responses: {total_valid_responses}\")\n",
    "print(f\"Total unique frequency options: {total_options}\")\n",
    "print(f\"Average responses per option: {average_responses:.2f}\")\n",
    "print(f\"Most common frequency: {most_common['Response']} ({most_common['Count']} responses, {most_common['Percentage']}% of respondents)\")\n",
    "print(f\"Least common frequency: {least_common['Response']} ({least_common['Count']} responses, {least_common['Percentage']}% of respondents)\")\n",
    "\n",
    "print(\"\\nBreakdown of responses:\")\n",
    "for _, row in response_counts.iterrows():\n",
    "    print(f\"{row['Response']}: {row['Count']} responses ({row['Percentage']}% of respondents)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A.1.4 How do AI-enhanced tools affect your development process and/or your company's workflow?\n",
      "Total valid responses: 107\n",
      "Total responses across all effects: 377\n",
      "Total unique effects: 13\n",
      "Average responses per effect: 29.00\n",
      "Most common effect: Increased Efficiency (76 responses, 71.03% of respondents)\n",
      "Least common effect: Prefer not to say (1 responses, 0.93% of respondents)\n",
      "\n",
      "Breakdown of responses:\n",
      "Increased Efficiency: 76 responses (71.03% of respondents)\n",
      "Improved Accuracy: 44 responses (41.12% of respondents)\n",
      "Innovation and Creativity: 43 responses (40.19% of respondents)\n",
      "Enhanced Decision Making: 42 responses (39.25% of respondents)\n",
      "Improved Research Quality: 42 responses (39.25% of respondents)\n",
      "Training and Skill Development: 38 responses (35.51% of respondents)\n",
      "Cost Reduction: 33 responses (30.84% of respondents)\n",
      "Streamlined Workflows: 29 responses (27.1% of respondents)\n",
      "Security and Privacy Concerns: 17 responses (15.89% of respondents)\n",
      "No Significant Impact: 8 responses (7.48% of respondents)\n",
      "Other: 2 responses (1.87% of respondents)\n",
      "please explain: 2 responses (1.87% of respondents)\n",
      "Prefer not to say: 1 responses (0.93% of respondents)\n"
     ]
    }
   ],
   "source": [
    "####################################\n",
    "#  A.1.4\n",
    "####################################\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import re\n",
    "\n",
    "# Step 1: Read CSV file into a DataFrame\n",
    "df = pd.read_csv(ai_study)\n",
    "\n",
    "# Step 2: Exclude the first two rows\n",
    "df = df.iloc[2:]\n",
    "\n",
    "# Step 3: Remove NaNs or empty values in 'A.1.4'\n",
    "df = df[df['A.1.4'].notna()]  # Remove NaNs\n",
    "df['A.1.4'] = df['A.1.4'].astype(str).apply(lambda x: x.strip())\n",
    "df = df[df['A.1.4'] != \"\"]  # Remove empty strings\n",
    "\n",
    "# Step 4: Process the responses\n",
    "# Split the strings by comma and normalize by stripping whitespace\n",
    "df['A.1.4'] = df['A.1.4'].apply(lambda x: re.split(r',\\s*', x))\n",
    "\n",
    "# Flatten the list of responses and count occurrences\n",
    "all_responses = df['A.1.4'].explode().value_counts().reset_index()\n",
    "all_responses.columns = ['Option', 'Count']\n",
    "\n",
    "# Step 5: Calculate total number of valid responses (non-empty)\n",
    "total_valid_responses = df.shape[0]\n",
    "\n",
    "# Step 6: Calculate the percentage of each option based on valid responses\n",
    "all_responses['Percentage'] = (all_responses['Count'] / total_valid_responses * 100).round(2)\n",
    "\n",
    "# Step 7: Visualize the results with a Bar Chart using Plotly\n",
    "question_text = \"A.1.4 How do AI-enhanced tools affect your development process and/or your company's workflow?\"\n",
    "fig = px.bar(all_responses, x='Option', y='Count',\n",
    "             title=question_text,\n",
    "             labels={'Option': 'Effects', 'Count': 'Number of Responses'},\n",
    "             color='Count',\n",
    "             color_continuous_scale='Blues',\n",
    "             text=all_responses['Percentage'].apply(lambda x: f'{x}%'))  # Add percentage text\n",
    "\n",
    "# Update layout to make the chart clearer\n",
    "fig.update_layout(xaxis_tickangle=45, xaxis_title='Effects', yaxis_title='Number of Responses')\n",
    "\n",
    "# Step 8: Show the figure\n",
    "fig.show(renderer=\"browser\")\n",
    "\n",
    "# Statistical Analysis\n",
    "total_responses = all_responses['Count'].sum()\n",
    "total_options = len(all_responses)\n",
    "average_responses = total_responses / total_options\n",
    "most_common = all_responses.iloc[0]\n",
    "least_common = all_responses.iloc[-1]\n",
    "\n",
    "print(question_text)\n",
    "print(f\"Total valid responses: {total_valid_responses}\")\n",
    "print(f\"Total responses across all effects: {total_responses}\")\n",
    "print(f\"Total unique effects: {total_options}\")\n",
    "print(f\"Average responses per effect: {average_responses:.2f}\")\n",
    "print(f\"Most common effect: {most_common['Option']} ({most_common['Count']} responses, {most_common['Percentage']}% of respondents)\")\n",
    "print(f\"Least common effect: {least_common['Option']} ({least_common['Count']} responses, {least_common['Percentage']}% of respondents)\")\n",
    "\n",
    "print(\"\\nBreakdown of responses:\")\n",
    "for _, row in all_responses.iterrows():\n",
    "    print(f\"{row['Option']}: {row['Count']} responses ({row['Percentage']}% of respondents)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A.1.5: How do AI-enhanced tools affect your development process and/or your company's workflow? Select all that apply.\n",
      "Total valid responses: 104\n",
      "Total responses across all factors: 254\n",
      "Total unique limiting factors: 11\n",
      "Average responses per factor: 23.09\n",
      "Most common factor: Privacy and Security Concerns (47 responses, 45.19% of respondents)\n",
      "Least common factor: please explain (3 responses, 2.88% of respondents)\n",
      "\n",
      "Breakdown of responses:\n",
      "Privacy and Security Concerns: 47 responses (45.19% of respondents)\n",
      "Lack of Trust: 40 responses (38.46% of respondents)\n",
      "Lack of Expertise: 37 responses (35.58% of respondents)\n",
      "Financial: 31 responses (29.81% of respondents)\n",
      "Regulations: 28 responses (26.92% of respondents)\n",
      "Technology: 22 responses (21.15% of respondents)\n",
      "Proprietary Reasons: 21 responses (20.19% of respondents)\n",
      "Human Resources: 17 responses (16.35% of respondents)\n",
      "Prefer not to say: 5 responses (4.81% of respondents)\n",
      "Other: 3 responses (2.88% of respondents)\n",
      "please explain: 3 responses (2.88% of respondents)\n",
      "\n",
      "Grouped Location-based Analysis:\n",
      "\n",
      "Location Group: US\n",
      "Total responses from this location group: 47\n",
      "Breakdown of responses:\n",
      "Privacy and Security Concerns: 22 responses (46.81% of respondents from this location group)\n",
      "Lack of Expertise: 18 responses (38.3% of respondents from this location group)\n",
      "Lack of Trust: 15 responses (31.91% of respondents from this location group)\n",
      "Regulations: 15 responses (31.91% of respondents from this location group)\n",
      "Financial: 12 responses (25.53% of respondents from this location group)\n",
      "Proprietary Reasons: 10 responses (21.28% of respondents from this location group)\n",
      "Technology: 8 responses (17.02% of respondents from this location group)\n",
      "Human Resources: 8 responses (17.02% of respondents from this location group)\n",
      "Prefer not to say: 2 responses (4.26% of respondents from this location group)\n",
      "Other: 1 responses (2.13% of respondents from this location group)\n",
      "please explain: 1 responses (2.13% of respondents from this location group)\n",
      "Most common factor: Privacy and Security Concerns (22 responses, 46.81% of respondents from this location group)\n",
      "Least common factor: please explain (1 responses, 2.13% of respondents from this location group)\n",
      "\n",
      "Location Group: Europe\n",
      "Total responses from this location group: 35\n",
      "Breakdown of responses:\n",
      "Lack of Trust: 15 responses (42.86% of respondents from this location group)\n",
      "Privacy and Security Concerns: 14 responses (40.0% of respondents from this location group)\n",
      "Lack of Expertise: 13 responses (37.14% of respondents from this location group)\n",
      "Financial: 10 responses (28.57% of respondents from this location group)\n",
      "Proprietary Reasons: 8 responses (22.86% of respondents from this location group)\n",
      "Technology: 8 responses (22.86% of respondents from this location group)\n",
      "Regulations: 7 responses (20.0% of respondents from this location group)\n",
      "Human Resources: 5 responses (14.29% of respondents from this location group)\n",
      "Other: 1 responses (2.86% of respondents from this location group)\n",
      "please explain: 1 responses (2.86% of respondents from this location group)\n",
      "Prefer not to say: 1 responses (2.86% of respondents from this location group)\n",
      "Most common factor: Lack of Trust (15 responses, 42.86% of respondents from this location group)\n",
      "Least common factor: Prefer not to say (1 responses, 2.86% of respondents from this location group)\n",
      "\n",
      "Location Group: Other\n",
      "Total responses from this location group: 22\n",
      "Breakdown of responses:\n",
      "Privacy and Security Concerns: 11 responses (50.0% of respondents from this location group)\n",
      "Lack of Trust: 10 responses (45.45% of respondents from this location group)\n",
      "Financial: 9 responses (40.91% of respondents from this location group)\n",
      "Regulations: 6 responses (27.27% of respondents from this location group)\n",
      "Lack of Expertise: 6 responses (27.27% of respondents from this location group)\n",
      "Technology: 6 responses (27.27% of respondents from this location group)\n",
      "Human Resources: 4 responses (18.18% of respondents from this location group)\n",
      "Proprietary Reasons: 3 responses (13.64% of respondents from this location group)\n",
      "Prefer not to say: 2 responses (9.09% of respondents from this location group)\n",
      "Other: 1 responses (4.55% of respondents from this location group)\n",
      "please explain: 1 responses (4.55% of respondents from this location group)\n",
      "Most common factor: Privacy and Security Concerns (11 responses, 50.0% of respondents from this location group)\n",
      "Least common factor: please explain (1 responses, 4.55% of respondents from this location group)\n",
      "\n",
      "Role-based Analysis:\n",
      "\n",
      "Role Group: Other\n",
      "Total responses from this role group: 2\n",
      "Breakdown of responses:\n",
      "Regulations: 1 responses (50.0% of respondents from this role group)\n",
      "Lack of Expertise: 1 responses (50.0% of respondents from this role group)\n",
      "Lack of Trust: 1 responses (50.0% of respondents from this role group)\n",
      "Privacy and Security Concerns: 1 responses (50.0% of respondents from this role group)\n",
      "Most common factor: Regulations (1 responses, 50.0% of respondents from this role group)\n",
      "Least common factor: Privacy and Security Concerns (1 responses, 50.0% of respondents from this role group)\n",
      "\n",
      "Role Group: AI Researcher\n",
      "Total responses from this role group: 4\n",
      "Breakdown of responses:\n",
      "Financial: 2 responses (50.0% of respondents from this role group)\n",
      "Lack of Trust: 1 responses (25.0% of respondents from this role group)\n",
      "Regulations: 1 responses (25.0% of respondents from this role group)\n",
      "Privacy and Security Concerns: 1 responses (25.0% of respondents from this role group)\n",
      "Technology: 1 responses (25.0% of respondents from this role group)\n",
      "Prefer not to say: 1 responses (25.0% of respondents from this role group)\n",
      "Human Resources: 1 responses (25.0% of respondents from this role group)\n",
      "Most common factor: Financial (2 responses, 50.0% of respondents from this role group)\n",
      "Least common factor: Human Resources (1 responses, 25.0% of respondents from this role group)\n",
      "\n",
      "Role Group: QA and Maintanence\n",
      "Total responses from this role group: 7\n",
      "Breakdown of responses:\n",
      "Privacy and Security Concerns: 5 responses (71.43% of respondents from this role group)\n",
      "Financial: 4 responses (57.14% of respondents from this role group)\n",
      "Lack of Expertise: 4 responses (57.14% of respondents from this role group)\n",
      "Human Resources: 3 responses (42.86% of respondents from this role group)\n",
      "Regulations: 3 responses (42.86% of respondents from this role group)\n",
      "Lack of Trust: 3 responses (42.86% of respondents from this role group)\n",
      "Technology: 2 responses (28.57% of respondents from this role group)\n",
      "Proprietary Reasons: 1 responses (14.29% of respondents from this role group)\n",
      "Most common factor: Privacy and Security Concerns (5 responses, 71.43% of respondents from this role group)\n",
      "Least common factor: Proprietary Reasons (1 responses, 14.29% of respondents from this role group)\n",
      "\n",
      "Role Group: AI Manager\n",
      "Total responses from this role group: 14\n",
      "Breakdown of responses:\n",
      "Financial: 6 responses (42.86% of respondents from this role group)\n",
      "Privacy and Security Concerns: 6 responses (42.86% of respondents from this role group)\n",
      "Lack of Trust: 4 responses (28.57% of respondents from this role group)\n",
      "Lack of Expertise: 3 responses (21.43% of respondents from this role group)\n",
      "Regulations: 2 responses (14.29% of respondents from this role group)\n",
      "Proprietary Reasons: 2 responses (14.29% of respondents from this role group)\n",
      "Technology: 2 responses (14.29% of respondents from this role group)\n",
      "Prefer not to say: 1 responses (7.14% of respondents from this role group)\n",
      "Human Resources: 1 responses (7.14% of respondents from this role group)\n",
      "Most common factor: Financial (6 responses, 42.86% of respondents from this role group)\n",
      "Least common factor: Human Resources (1 responses, 7.14% of respondents from this role group)\n",
      "\n",
      "Role Group: Requirements analyst\n",
      "Total responses from this role group: 15\n",
      "Breakdown of responses:\n",
      "Privacy and Security Concerns: 9 responses (60.0% of respondents from this role group)\n",
      "Lack of Expertise: 8 responses (53.33% of respondents from this role group)\n",
      "Lack of Trust: 7 responses (46.67% of respondents from this role group)\n",
      "Financial: 6 responses (40.0% of respondents from this role group)\n",
      "Regulations: 5 responses (33.33% of respondents from this role group)\n",
      "Proprietary Reasons: 4 responses (26.67% of respondents from this role group)\n",
      "Technology: 3 responses (20.0% of respondents from this role group)\n",
      "Human Resources: 2 responses (13.33% of respondents from this role group)\n",
      "Prefer not to say: 1 responses (6.67% of respondents from this role group)\n",
      "Most common factor: Privacy and Security Concerns (9 responses, 60.0% of respondents from this role group)\n",
      "Least common factor: Prefer not to say (1 responses, 6.67% of respondents from this role group)\n",
      "\n",
      "Role Group: AI developers\n",
      "Total responses from this role group: 51\n",
      "Breakdown of responses:\n",
      "Lack of Expertise: 19 responses (37.25% of respondents from this role group)\n",
      "Privacy and Security Concerns: 19 responses (37.25% of respondents from this role group)\n",
      "Lack of Trust: 19 responses (37.25% of respondents from this role group)\n",
      "Regulations: 13 responses (25.49% of respondents from this role group)\n",
      "Technology: 13 responses (25.49% of respondents from this role group)\n",
      "Proprietary Reasons: 13 responses (25.49% of respondents from this role group)\n",
      "Financial: 12 responses (23.53% of respondents from this role group)\n",
      "Human Resources: 9 responses (17.65% of respondents from this role group)\n",
      "Other: 3 responses (5.88% of respondents from this role group)\n",
      "please explain: 3 responses (5.88% of respondents from this role group)\n",
      "Prefer not to say: 1 responses (1.96% of respondents from this role group)\n",
      "Most common factor: Lack of Expertise (19 responses, 37.25% of respondents from this role group)\n",
      "Least common factor: Prefer not to say (1 responses, 1.96% of respondents from this role group)\n",
      "\n",
      "Role Group: Security/Privacy\n",
      "Total responses from this role group: 6\n",
      "Breakdown of responses:\n",
      "Lack of Trust: 3 responses (50.0% of respondents from this role group)\n",
      "Privacy and Security Concerns: 3 responses (50.0% of respondents from this role group)\n",
      "Technology: 1 responses (16.67% of respondents from this role group)\n",
      "Lack of Expertise: 1 responses (16.67% of respondents from this role group)\n",
      "Prefer not to say: 1 responses (16.67% of respondents from this role group)\n",
      "Most common factor: Lack of Trust (3 responses, 50.0% of respondents from this role group)\n",
      "Least common factor: Prefer not to say (1 responses, 16.67% of respondents from this role group)\n"
     ]
    }
   ],
   "source": [
    "####################################\n",
    "#  A.1.5 with Grouped Location and Role Analysis\n",
    "####################################\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import re\n",
    "\n",
    "# Step 1: Read CSV file into a DataFrame\n",
    "df = pd.read_csv(ai_study)\n",
    "\n",
    "# Step 2: Exclude the first two rows\n",
    "df = df.iloc[2:]\n",
    "\n",
    "# Step 3: Remove NaNs or empty values in 'A.1.5'\n",
    "df = df[df['A.1.5'].notna()]  # Remove NaNs\n",
    "df['A.1.5'] = df['A.1.5'].astype(str).apply(lambda x: x.strip())\n",
    "df = df[df['A.1.5'] != \"\"]  # Remove empty strings\n",
    "\n",
    "# Step 4: Process the responses\n",
    "# Split the strings by comma and normalize by stripping whitespace\n",
    "df['A.1.5'] = df['A.1.5'].apply(lambda x: re.split(r',\\s*', x))\n",
    "\n",
    "# Add location data and group it\n",
    "location_mapping = {\n",
    "    'North America': 'US',\n",
    "    'Central/South America': 'Other',\n",
    "    'EU/UK/EEA': 'Europe',\n",
    "    'Europe - Outside of EU/UK/EEA': 'Europe',\n",
    "    'Africa': 'Other',\n",
    "    'Middle East': 'Other',\n",
    "    'Asia': 'Other',\n",
    "    'Australia and Oceania': 'Other',\n",
    "    'Prefer not to say': 'Other',\n",
    "    'Other, please specify': 'Other'\n",
    "}\n",
    "df['Location'] = df.iloc[:, 28].map(location_mapping)\n",
    "\n",
    "# Add role data and group it\n",
    "role_mapping = {\n",
    "    'Administrative role (CEO, Chief Technical Officer, Chief Operating Officer, Chief Information Officer)': 'AI Manager',\n",
    "    'AI Manager': 'AI Manager',\n",
    "    'Requirements Analyst or Engineer': 'Requirements analyst',\n",
    "    'Scrum Master, Product Manager, or Project Manager': 'Requirements analyst',\n",
    "    'AI Engineer or Developer': 'AI developers',\n",
    "    '(Software) Developer, Designer, or Architect': 'AI developers',\n",
    "    'Data Scientist or Data Analyst': 'AI developers',\n",
    "    'Information Security Analyst or Engineer': 'Security/Privacy',\n",
    "    'Information Privacy Analyst or Engineer': 'Security/Privacy',\n",
    "    'AI Ethicist': 'Other',\n",
    "    'AI Researcher': 'AI Researcher',\n",
    "    '(Software) Quality Assurance Engineer or Tester': 'QA and Maintanence',\n",
    "    'Other, please specify': 'Other'\n",
    "}\n",
    "df['Role'] = df.iloc[:, 30].map(role_mapping)\n",
    "\n",
    "# Flatten the list of responses and count occurrences\n",
    "all_responses = df['A.1.5'].explode().value_counts().reset_index()\n",
    "all_responses.columns = ['Option', 'Count']\n",
    "\n",
    "# Step 5: Calculate total number of valid responses (non-empty)\n",
    "total_valid_responses = df.shape[0]\n",
    "\n",
    "# Step 6: Calculate the percentage of each option based on valid responses\n",
    "all_responses['Percentage'] = (all_responses['Count'] / total_valid_responses * 100).round(2)\n",
    "\n",
    "# Step 7: Visualize the results with a Bar Chart using Plotly\n",
    "fig = px.bar(all_responses, x='Option', y='Count',\n",
    "             title=\"Factors Limiting Company's Involvement with AI A.1.5\",\n",
    "             labels={'Option': 'Limiting Factors', 'Count': 'Number of Responses'},\n",
    "             color='Count',\n",
    "             color_continuous_scale='Blues',\n",
    "             text=all_responses['Percentage'].apply(lambda x: f'{x}%'))  # Add percentage text\n",
    "\n",
    "# Update layout to make the chart clearer\n",
    "fig.update_layout(xaxis_tickangle=45, xaxis_title='Limiting Factors', yaxis_title='Number of Responses')\n",
    "\n",
    "# Step 8: Show the figure\n",
    "fig.show(renderer=\"browser\")\n",
    "\n",
    "# Statistical Analysis\n",
    "total_responses = all_responses['Count'].sum()\n",
    "total_options = len(all_responses)\n",
    "average_responses = total_responses / total_options\n",
    "most_common = all_responses.iloc[0]\n",
    "least_common = all_responses.iloc[-1]\n",
    "\n",
    "print(\"A.1.5: How do AI-enhanced tools affect your development process and/or your company's workflow? Select all that apply.\")\n",
    "print(f\"Total valid responses: {total_valid_responses}\")\n",
    "print(f\"Total responses across all factors: {total_responses}\")\n",
    "print(f\"Total unique limiting factors: {total_options}\")\n",
    "print(f\"Average responses per factor: {average_responses:.2f}\")\n",
    "print(f\"Most common factor: {most_common['Option']} ({most_common['Count']} responses, {most_common['Percentage']}% of respondents)\")\n",
    "print(f\"Least common factor: {least_common['Option']} ({least_common['Count']} responses, {least_common['Percentage']}% of respondents)\")\n",
    "\n",
    "print(\"\\nBreakdown of responses:\")\n",
    "for _, row in all_responses.iterrows():\n",
    "    print(f\"{row['Option']}: {row['Count']} responses ({row['Percentage']}% of respondents)\")\n",
    "\n",
    "# Grouped Location-based analysis\n",
    "print(\"\\nGrouped Location-based Analysis:\")\n",
    "grouped_locations = ['US', 'Europe', 'Other']\n",
    "\n",
    "for location in grouped_locations:\n",
    "    print(f\"\\nLocation Group: {location}\")\n",
    "    location_df = df[df['Location'] == location]\n",
    "    location_responses = location_df['A.1.5'].explode().value_counts().reset_index()\n",
    "    location_responses.columns = ['Option', 'Count']\n",
    "    location_total = location_df.shape[0]\n",
    "    location_responses['Percentage'] = (location_responses['Count'] / location_total * 100).round(2)\n",
    "    \n",
    "    print(f\"Total responses from this location group: {location_total}\")\n",
    "    print(\"Breakdown of responses:\")\n",
    "    for _, row in location_responses.iterrows():\n",
    "        print(f\"{row['Option']}: {row['Count']} responses ({row['Percentage']}% of respondents from this location group)\")\n",
    "    \n",
    "    if not location_responses.empty:\n",
    "        location_most_common = location_responses.iloc[0]\n",
    "        location_least_common = location_responses.iloc[-1]\n",
    "        print(f\"Most common factor: {location_most_common['Option']} ({location_most_common['Count']} responses, {location_most_common['Percentage']}% of respondents from this location group)\")\n",
    "        print(f\"Least common factor: {location_least_common['Option']} ({location_least_common['Count']} responses, {location_least_common['Percentage']}% of respondents from this location group)\")\n",
    "    else:\n",
    "        print(\"No responses from this location group.\")\n",
    "\n",
    "# Role-based analysis\n",
    "print(\"\\nRole-based Analysis:\")\n",
    "grouped_roles = list(set(role_mapping.values()))  # Get unique role groups\n",
    "\n",
    "for role in grouped_roles:\n",
    "    print(f\"\\nRole Group: {role}\")\n",
    "    role_df = df[df['Role'] == role]\n",
    "    role_responses = role_df['A.1.5'].explode().value_counts().reset_index()\n",
    "    role_responses.columns = ['Option', 'Count']\n",
    "    role_total = role_df.shape[0]\n",
    "    role_responses['Percentage'] = (role_responses['Count'] / role_total * 100).round(2)\n",
    "    \n",
    "    print(f\"Total responses from this role group: {role_total}\")\n",
    "    print(\"Breakdown of responses:\")\n",
    "    for _, row in role_responses.iterrows():\n",
    "        print(f\"{row['Option']}: {row['Count']} responses ({row['Percentage']}% of respondents from this role group)\")\n",
    "    \n",
    "    if not role_responses.empty:\n",
    "        role_most_common = role_responses.iloc[0]\n",
    "        role_least_common = role_responses.iloc[-1]\n",
    "        print(f\"Most common factor: {role_most_common['Option']} ({role_most_common['Count']} responses, {role_most_common['Percentage']}% of respondents from this role group)\")\n",
    "        print(f\"Least common factor: {role_least_common['Option']} ({role_least_common['Count']} responses, {role_least_common['Percentage']}% of respondents from this role group)\")\n",
    "    else:\n",
    "        print(\"No responses from this role group.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A.2.2: Which AI ethics principles do you consider to be at risk due to current AI systems? Select all that apply.\n",
      "Total valid responses: 92\n",
      "Total responses across all principles: 255\n",
      "Total unique ethics principles: 11\n",
      "Average responses per principle: 23.18\n",
      "Most common principle: Data Protection and Right to Privacy (66 responses, 71.74% of respondents)\n",
      "Least common principle: None (1 responses, 1.09% of respondents)\n",
      "\n",
      "Breakdown of responses:\n",
      "Data Protection and Right to Privacy: 66 responses (71.74% of respondents)\n",
      "Transparency and Explainability of AI Systems: 39 responses (42.39% of respondents)\n",
      "Accountability and Responsibility: 31 responses (33.7% of respondents)\n",
      "Fairness and Justice: 24 responses (26.09% of respondents)\n",
      "Harm Prevention and Beneficence: 22 responses (23.91% of respondents)\n",
      "Non-Discrimination and Freedom of Privileges: 20 responses (21.74% of respondents)\n",
      "Respect for Human Rights: 17 responses (18.48% of respondents)\n",
      "Democracy and Rule of Law: 15 responses (16.3% of respondents)\n",
      "Environment and Social Responsibility: 12 responses (13.04% of respondents)\n",
      "All: 8 responses (8.7% of respondents)\n",
      "None: 1 responses (1.09% of respondents)\n",
      "\n",
      "Grouped Location-based Analysis:\n",
      "\n",
      "Location Group: US\n",
      "Total responses from this location group: 39\n",
      "Breakdown of responses:\n",
      "Data Protection and Right to Privacy: 24 responses (61.54% of respondents from this location group)\n",
      "Transparency and Explainability of AI Systems: 15 responses (38.46% of respondents from this location group)\n",
      "Accountability and Responsibility: 12 responses (30.77% of respondents from this location group)\n",
      "Fairness and Justice: 12 responses (30.77% of respondents from this location group)\n",
      "Harm Prevention and Beneficence: 10 responses (25.64% of respondents from this location group)\n",
      "Non-Discrimination and Freedom of Privileges: 9 responses (23.08% of respondents from this location group)\n",
      "Respect for Human Rights: 9 responses (23.08% of respondents from this location group)\n",
      "Democracy and Rule of Law: 5 responses (12.82% of respondents from this location group)\n",
      "Environment and Social Responsibility: 4 responses (10.26% of respondents from this location group)\n",
      "All: 3 responses (7.69% of respondents from this location group)\n",
      "Most common principle: Data Protection and Right to Privacy (24 responses, 61.54% of respondents from this location group)\n",
      "Least common principle: All (3 responses, 7.69% of respondents from this location group)\n",
      "\n",
      "Location Group: Europe\n",
      "Total responses from this location group: 34\n",
      "Breakdown of responses:\n",
      "Data Protection and Right to Privacy: 29 responses (85.29% of respondents from this location group)\n",
      "Transparency and Explainability of AI Systems: 16 responses (47.06% of respondents from this location group)\n",
      "Accountability and Responsibility: 9 responses (26.47% of respondents from this location group)\n",
      "Harm Prevention and Beneficence: 8 responses (23.53% of respondents from this location group)\n",
      "Democracy and Rule of Law: 8 responses (23.53% of respondents from this location group)\n",
      "Environment and Social Responsibility: 6 responses (17.65% of respondents from this location group)\n",
      "Fairness and Justice: 6 responses (17.65% of respondents from this location group)\n",
      "Non-Discrimination and Freedom of Privileges: 6 responses (17.65% of respondents from this location group)\n",
      "Respect for Human Rights: 6 responses (17.65% of respondents from this location group)\n",
      "All: 4 responses (11.76% of respondents from this location group)\n",
      "Most common principle: Data Protection and Right to Privacy (29 responses, 85.29% of respondents from this location group)\n",
      "Least common principle: All (4 responses, 11.76% of respondents from this location group)\n",
      "\n",
      "Location Group: Other\n",
      "Total responses from this location group: 19\n",
      "Breakdown of responses:\n",
      "Data Protection and Right to Privacy: 13 responses (68.42% of respondents from this location group)\n",
      "Accountability and Responsibility: 10 responses (52.63% of respondents from this location group)\n",
      "Transparency and Explainability of AI Systems: 8 responses (42.11% of respondents from this location group)\n",
      "Fairness and Justice: 6 responses (31.58% of respondents from this location group)\n",
      "Non-Discrimination and Freedom of Privileges: 5 responses (26.32% of respondents from this location group)\n",
      "Harm Prevention and Beneficence: 4 responses (21.05% of respondents from this location group)\n",
      "Democracy and Rule of Law: 2 responses (10.53% of respondents from this location group)\n",
      "Respect for Human Rights: 2 responses (10.53% of respondents from this location group)\n",
      "Environment and Social Responsibility: 2 responses (10.53% of respondents from this location group)\n",
      "None: 1 responses (5.26% of respondents from this location group)\n",
      "All: 1 responses (5.26% of respondents from this location group)\n",
      "Most common principle: Data Protection and Right to Privacy (13 responses, 68.42% of respondents from this location group)\n",
      "Least common principle: All (1 responses, 5.26% of respondents from this location group)\n",
      "\n",
      "Role-based Analysis:\n",
      "\n",
      "Role Group: AI developers\n",
      "Total responses from this role group: 44\n",
      "Breakdown of responses:\n",
      "Data Protection and Right to Privacy: 31 responses (70.45% of respondents from this role group)\n",
      "Transparency and Explainability of AI Systems: 19 responses (43.18% of respondents from this role group)\n",
      "Fairness and Justice: 13 responses (29.55% of respondents from this role group)\n",
      "Accountability and Responsibility: 13 responses (29.55% of respondents from this role group)\n",
      "Harm Prevention and Beneficence: 11 responses (25.0% of respondents from this role group)\n",
      "Democracy and Rule of Law: 9 responses (20.45% of respondents from this role group)\n",
      "Non-Discrimination and Freedom of Privileges: 9 responses (20.45% of respondents from this role group)\n",
      "Respect for Human Rights: 8 responses (18.18% of respondents from this role group)\n",
      "Environment and Social Responsibility: 5 responses (11.36% of respondents from this role group)\n",
      "All: 4 responses (9.09% of respondents from this role group)\n",
      "None: 1 responses (2.27% of respondents from this role group)\n",
      "Most common principle: Data Protection and Right to Privacy (31 responses, 70.45% of respondents from this role group)\n",
      "Least common principle: None (1 responses, 2.27% of respondents from this role group)\n",
      "\n",
      "Role Group: Security/Privacy\n",
      "Total responses from this role group: 4\n",
      "Breakdown of responses:\n",
      "Data Protection and Right to Privacy: 4 responses (100.0% of respondents from this role group)\n",
      "Transparency and Explainability of AI Systems: 2 responses (50.0% of respondents from this role group)\n",
      "Accountability and Responsibility: 2 responses (50.0% of respondents from this role group)\n",
      "Harm Prevention and Beneficence: 1 responses (25.0% of respondents from this role group)\n",
      "Fairness and Justice: 1 responses (25.0% of respondents from this role group)\n",
      "Most common principle: Data Protection and Right to Privacy (4 responses, 100.0% of respondents from this role group)\n",
      "Least common principle: Fairness and Justice (1 responses, 25.0% of respondents from this role group)\n",
      "\n",
      "Role Group: Requirements analyst\n",
      "Total responses from this role group: 14\n",
      "Breakdown of responses:\n",
      "Data Protection and Right to Privacy: 10 responses (71.43% of respondents from this role group)\n",
      "Accountability and Responsibility: 7 responses (50.0% of respondents from this role group)\n",
      "Transparency and Explainability of AI Systems: 7 responses (50.0% of respondents from this role group)\n",
      "Non-Discrimination and Freedom of Privileges: 4 responses (28.57% of respondents from this role group)\n",
      "Harm Prevention and Beneficence: 4 responses (28.57% of respondents from this role group)\n",
      "Respect for Human Rights: 3 responses (21.43% of respondents from this role group)\n",
      "Fairness and Justice: 3 responses (21.43% of respondents from this role group)\n",
      "Democracy and Rule of Law: 2 responses (14.29% of respondents from this role group)\n",
      "Environment and Social Responsibility: 2 responses (14.29% of respondents from this role group)\n",
      "Most common principle: Data Protection and Right to Privacy (10 responses, 71.43% of respondents from this role group)\n",
      "Least common principle: Environment and Social Responsibility (2 responses, 14.29% of respondents from this role group)\n",
      "\n",
      "Role Group: Other\n",
      "Total responses from this role group: 1\n",
      "Breakdown of responses:\n",
      "Fairness and Justice: 1 responses (100.0% of respondents from this role group)\n",
      "Most common principle: Fairness and Justice (1 responses, 100.0% of respondents from this role group)\n",
      "Least common principle: Fairness and Justice (1 responses, 100.0% of respondents from this role group)\n",
      "\n",
      "Role Group: AI Researcher\n",
      "Total responses from this role group: 4\n",
      "Breakdown of responses:\n",
      "Data Protection and Right to Privacy: 3 responses (75.0% of respondents from this role group)\n",
      "Transparency and Explainability of AI Systems: 2 responses (50.0% of respondents from this role group)\n",
      "Environment and Social Responsibility: 1 responses (25.0% of respondents from this role group)\n",
      "All: 1 responses (25.0% of respondents from this role group)\n",
      "Respect for Human Rights: 1 responses (25.0% of respondents from this role group)\n",
      "Most common principle: Data Protection and Right to Privacy (3 responses, 75.0% of respondents from this role group)\n",
      "Least common principle: Respect for Human Rights (1 responses, 25.0% of respondents from this role group)\n",
      "\n",
      "Role Group: QA and Maintanence\n",
      "Total responses from this role group: 7\n",
      "Breakdown of responses:\n",
      "Transparency and Explainability of AI Systems: 4 responses (57.14% of respondents from this role group)\n",
      "Data Protection and Right to Privacy: 4 responses (57.14% of respondents from this role group)\n",
      "Harm Prevention and Beneficence: 3 responses (42.86% of respondents from this role group)\n",
      "Respect for Human Rights: 2 responses (28.57% of respondents from this role group)\n",
      "Fairness and Justice: 2 responses (28.57% of respondents from this role group)\n",
      "Democracy and Rule of Law: 2 responses (28.57% of respondents from this role group)\n",
      "Non-Discrimination and Freedom of Privileges: 2 responses (28.57% of respondents from this role group)\n",
      "Accountability and Responsibility: 2 responses (28.57% of respondents from this role group)\n",
      "Environment and Social Responsibility: 1 responses (14.29% of respondents from this role group)\n",
      "All: 1 responses (14.29% of respondents from this role group)\n",
      "Most common principle: Transparency and Explainability of AI Systems (4 responses, 57.14% of respondents from this role group)\n",
      "Least common principle: All (1 responses, 14.29% of respondents from this role group)\n",
      "\n",
      "Role Group: AI Manager\n",
      "Total responses from this role group: 13\n",
      "Breakdown of responses:\n",
      "Data Protection and Right to Privacy: 11 responses (84.62% of respondents from this role group)\n",
      "Accountability and Responsibility: 5 responses (38.46% of respondents from this role group)\n",
      "Non-Discrimination and Freedom of Privileges: 3 responses (23.08% of respondents from this role group)\n",
      "Transparency and Explainability of AI Systems: 3 responses (23.08% of respondents from this role group)\n",
      "Respect for Human Rights: 2 responses (15.38% of respondents from this role group)\n",
      "Fairness and Justice: 2 responses (15.38% of respondents from this role group)\n",
      "Harm Prevention and Beneficence: 2 responses (15.38% of respondents from this role group)\n",
      "Democracy and Rule of Law: 1 responses (7.69% of respondents from this role group)\n",
      "Environment and Social Responsibility: 1 responses (7.69% of respondents from this role group)\n",
      "Most common principle: Data Protection and Right to Privacy (11 responses, 84.62% of respondents from this role group)\n",
      "Least common principle: Environment and Social Responsibility (1 responses, 7.69% of respondents from this role group)\n"
     ]
    }
   ],
   "source": [
    "################################\n",
    "# A.2.2 with Grouped Location and Role Analysis\n",
    "################################\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import re\n",
    "\n",
    "# Step 1: Read CSV file into a DataFrame\n",
    "df = pd.read_csv(ai_study, encoding='latin-1')\n",
    "\n",
    "# Step 2: Exclude the first two rows\n",
    "df = df.iloc[2:]\n",
    "\n",
    "# Step 3: Remove NaNs or empty values in 'A.2.2'\n",
    "df = df[df['A.2.2'].notna()]  # Remove NaNs\n",
    "df['A.2.2'] = df['A.2.2'].astype(str).apply(lambda x: x.strip())\n",
    "df = df[df['A.2.2'] != \"\"]  # Remove empty strings\n",
    "\n",
    "# Step 4: Process the responses\n",
    "# Split the strings by comma and normalize by stripping whitespace\n",
    "df['A.2.2'] = df['A.2.2'].apply(lambda x: re.split(r',\\s*', x))\n",
    "\n",
    "# Add location data and group it\n",
    "location_mapping = {\n",
    "    'North America': 'US',\n",
    "    'Central/South America': 'Other',\n",
    "    'EU/UK/EEA': 'Europe',\n",
    "    'Europe - Outside of EU/UK/EEA': 'Europe',\n",
    "    'Africa': 'Other',\n",
    "    'Middle East': 'Other',\n",
    "    'Asia': 'Other',\n",
    "    'Australia and Oceania': 'Other',\n",
    "    'Prefer not to say': 'Other',\n",
    "    'Other, please specify': 'Other'\n",
    "}\n",
    "df['Location'] = df.iloc[:, 28].map(location_mapping)\n",
    "\n",
    "# Add role data and group it\n",
    "role_mapping = {\n",
    "    'Administrative role (CEO, Chief Technical Officer, Chief Operating Officer, Chief Information Officer)': 'AI Manager',\n",
    "    'AI Manager': 'AI Manager',\n",
    "    'Requirements Analyst or Engineer': 'Requirements analyst',\n",
    "    'Scrum Master, Product Manager, or Project Manager': 'Requirements analyst',\n",
    "    'AI Engineer or Developer': 'AI developers',\n",
    "    '(Software) Developer, Designer, or Architect': 'AI developers',\n",
    "    'Data Scientist or Data Analyst': 'AI developers',\n",
    "    'Information Security Analyst or Engineer': 'Security/Privacy',\n",
    "    'Information Privacy Analyst or Engineer': 'Security/Privacy',\n",
    "    'AI Ethicist': 'Other',\n",
    "    'AI Researcher': 'AI Researcher',\n",
    "    '(Software) Quality Assurance Engineer or Tester': 'QA and Maintanence',\n",
    "    'Other, please specify': 'Other'\n",
    "}\n",
    "df['Role'] = df.iloc[:, 30].map(role_mapping)\n",
    "\n",
    "# Flatten the list of responses and count occurrences\n",
    "all_responses = df['A.2.2'].explode().value_counts().reset_index()\n",
    "all_responses.columns = ['Option', 'Count']\n",
    "\n",
    "# Step 5: Calculate total number of valid responses (non-empty)\n",
    "total_valid_responses = df.shape[0]\n",
    "\n",
    "# Step 6: Calculate the percentage of each option based on valid responses\n",
    "all_responses['Percentage'] = (all_responses['Count'] / total_valid_responses * 100).round(2)\n",
    "\n",
    "# Step 7: Visualize the results with a Bar Chart using Plotly\n",
    "fig = px.bar(all_responses, x='Option', y='Count',\n",
    "             title='AI Ethics Principles at Risk Due to Current AI Systems A.2.2',\n",
    "             labels={'Option': 'Ethics Principles', 'Count': 'Number of Responses'},\n",
    "             color='Count',\n",
    "             color_continuous_scale='Blues',\n",
    "             text=all_responses['Percentage'].apply(lambda x: f'{x}%'))  # Add percentage text\n",
    "\n",
    "# Update layout to make the chart clearer\n",
    "fig.update_layout(xaxis_tickangle=45, xaxis_title='Ethics Principles', yaxis_title='Number of Responses')\n",
    "\n",
    "# Step 8: Show the figure\n",
    "fig.show(renderer=\"browser\")\n",
    "\n",
    "# Statistical Analysis\n",
    "total_responses = all_responses['Count'].sum()\n",
    "total_options = len(all_responses)\n",
    "average_responses = total_responses / total_options\n",
    "most_common = all_responses.iloc[0]\n",
    "least_common = all_responses.iloc[-1]\n",
    "\n",
    "print(\"A.2.2: Which AI ethics principles do you consider to be at risk due to current AI systems? Select all that apply.\")\n",
    "print(f\"Total valid responses: {total_valid_responses}\")\n",
    "print(f\"Total responses across all principles: {total_responses}\")\n",
    "print(f\"Total unique ethics principles: {total_options}\")\n",
    "print(f\"Average responses per principle: {average_responses:.2f}\")\n",
    "print(f\"Most common principle: {most_common['Option']} ({most_common['Count']} responses, {most_common['Percentage']}% of respondents)\")\n",
    "print(f\"Least common principle: {least_common['Option']} ({least_common['Count']} responses, {least_common['Percentage']}% of respondents)\")\n",
    "\n",
    "print(\"\\nBreakdown of responses:\")\n",
    "for _, row in all_responses.iterrows():\n",
    "    print(f\"{row['Option']}: {row['Count']} responses ({row['Percentage']}% of respondents)\")\n",
    "\n",
    "# Grouped Location-based analysis\n",
    "print(\"\\nGrouped Location-based Analysis:\")\n",
    "grouped_locations = ['US', 'Europe', 'Other']\n",
    "\n",
    "for location in grouped_locations:\n",
    "    print(f\"\\nLocation Group: {location}\")\n",
    "    location_df = df[df['Location'] == location]\n",
    "    location_responses = location_df['A.2.2'].explode().value_counts().reset_index()\n",
    "    location_responses.columns = ['Option', 'Count']\n",
    "    location_total = location_df.shape[0]\n",
    "    location_responses['Percentage'] = (location_responses['Count'] / location_total * 100).round(2)\n",
    "    \n",
    "    print(f\"Total responses from this location group: {location_total}\")\n",
    "    print(\"Breakdown of responses:\")\n",
    "    for _, row in location_responses.iterrows():\n",
    "        print(f\"{row['Option']}: {row['Count']} responses ({row['Percentage']}% of respondents from this location group)\")\n",
    "    \n",
    "    if not location_responses.empty:\n",
    "        location_most_common = location_responses.iloc[0]\n",
    "        location_least_common = location_responses.iloc[-1]\n",
    "        print(f\"Most common principle: {location_most_common['Option']} ({location_most_common['Count']} responses, {location_most_common['Percentage']}% of respondents from this location group)\")\n",
    "        print(f\"Least common principle: {location_least_common['Option']} ({location_least_common['Count']} responses, {location_least_common['Percentage']}% of respondents from this location group)\")\n",
    "    else:\n",
    "        print(\"No responses from this location group.\")\n",
    "\n",
    "# Role-based analysis\n",
    "print(\"\\nRole-based Analysis:\")\n",
    "grouped_roles = list(set(role_mapping.values()))  # Get unique role groups\n",
    "\n",
    "for role in grouped_roles:\n",
    "    print(f\"\\nRole Group: {role}\")\n",
    "    role_df = df[df['Role'] == role]\n",
    "    role_responses = role_df['A.2.2'].explode().value_counts().reset_index()\n",
    "    role_responses.columns = ['Option', 'Count']\n",
    "    role_total = role_df.shape[0]\n",
    "    role_responses['Percentage'] = (role_responses['Count'] / role_total * 100).round(2)\n",
    "    \n",
    "    print(f\"Total responses from this role group: {role_total}\")\n",
    "    print(\"Breakdown of responses:\")\n",
    "    for _, row in role_responses.iterrows():\n",
    "        print(f\"{row['Option']}: {row['Count']} responses ({row['Percentage']}% of respondents from this role group)\")\n",
    "    \n",
    "    if not role_responses.empty:\n",
    "        role_most_common = role_responses.iloc[0]\n",
    "        role_least_common = role_responses.iloc[-1]\n",
    "        print(f\"Most common principle: {role_most_common['Option']} ({role_most_common['Count']} responses, {role_most_common['Percentage']}% of respondents from this role group)\")\n",
    "        print(f\"Least common principle: {role_least_common['Option']} ({role_least_common['Count']} responses, {role_least_common['Percentage']}% of respondents from this role group)\")\n",
    "    else:\n",
    "        print(\"No responses from this role group.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for 'A.4.1': Can you envision a scenario where your company may integrate AI into future operations?\n",
      "Yes: 64 responses (59.81%)\n",
      "Maybe: 36 responses (33.64%)\n",
      "No: 6 responses (5.61%)\n",
      "Prefer not to say: 1 responses (0.93%)\n",
      "Total valid responses: 107\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "# A.4.1 statistics\n",
    "#########################\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Read CSV file into a DataFrame\n",
    "df = pd.read_csv(ai_study)\n",
    "\n",
    "# Step 2: Exclude the first two rows\n",
    "df = df.iloc[2:]\n",
    "\n",
    "# Step 3: Remove NaNs or empty values in 'A.4.1'\n",
    "df = df[df['A.4.1'].notna()]  # Remove NaNs\n",
    "df['A.4.1'] = df['A.4.1'].astype(str).apply(lambda x: x.strip())\n",
    "df = df[df['A.4.1'] != \"\"]  # Remove empty strings\n",
    "\n",
    "# Step 4: Count occurrences of each response\n",
    "response_counts = df['A.4.1'].value_counts().reset_index()\n",
    "response_counts.columns = ['Response', 'Count']\n",
    "\n",
    "# Step 5: Calculate total number of valid responses\n",
    "total_valid_responses = df.shape[0]\n",
    "\n",
    "# Step 6: Calculate the percentage of each option based on valid responses\n",
    "response_counts['Percentage'] = (response_counts['Count'] / total_valid_responses * 100).round(2)\n",
    "\n",
    "# Step 7: Print results in clear text\n",
    "print(\"Statistics for 'A.4.1': Can you envision a scenario where your company may integrate AI into future operations?\")\n",
    "for index, row in response_counts.iterrows():\n",
    "    print(f\"{row['Response']}: {row['Count']} responses ({row['Percentage']}%)\")\n",
    "\n",
    "print(f\"Total valid responses: {total_valid_responses}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################\n",
    "# A.4.2\n",
    "###################\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import re\n",
    "\n",
    "# Step 1: Read CSV file into a DataFrame\n",
    "df = pd.read_csv(ai_study)\n",
    "\n",
    "# Step 2: Exclude the first two rows\n",
    "df = df.iloc[2:]\n",
    "\n",
    "# Step 3: Remove NaNs or empty values in 'A.4.2'\n",
    "df = df[df['A.4.2'].notna()]  # Remove NaNs\n",
    "df['A.4.2'] = df['A.4.2'].astype(str).apply(lambda x: x.strip())\n",
    "df = df[df['A.4.2'] != \"\"]  # Remove empty strings\n",
    "\n",
    "# Step 4: Process the responses\n",
    "# Split the strings by comma and normalize by stripping whitespace\n",
    "df['A.4.2'] = df['A.4.2'].apply(lambda x: re.split(r',\\s*', x))\n",
    "\n",
    "# Flatten the list of responses and count occurrences\n",
    "all_responses = df['A.4.2'].explode().value_counts().reset_index()\n",
    "all_responses.columns = ['Option', 'Count']\n",
    "\n",
    "# Step 5: Calculate total number of valid responses (non-empty)\n",
    "total_valid_responses = df.shape[0]\n",
    "\n",
    "# Step 6: Calculate the percentage of each option based on valid responses\n",
    "all_responses['Percentage'] = (all_responses['Count'] / total_valid_responses * 100).round(2)\n",
    "\n",
    "# Step 7: Visualize the results with a Bar Chart using Plotly\n",
    "fig = px.bar(all_responses, x='Option', y='Count',\n",
    "             title='AI Ethics Principles to Consider for Future Operations',\n",
    "             labels={'Option': 'Ethics Principles', 'Count': 'Number of Responses'},\n",
    "             color='Count',\n",
    "             color_continuous_scale='Blues',\n",
    "             text=all_responses['Percentage'].apply(lambda x: f'{x}%'))  # Add percentage text\n",
    "\n",
    "# Update layout to make the chart clearer\n",
    "fig.update_layout(xaxis_tickangle=45, xaxis_title='Ethics Principles', yaxis_title='Number of Responses')\n",
    "\n",
    "# Step 8: Show the figure\n",
    "fig.show(renderer=\"browser\")\n",
    "\n",
    "# Statistical Analysis\n",
    "total_responses = all_responses['Count'].sum()\n",
    "total_options = len(all_responses)\n",
    "average_responses = total_responses / total_options\n",
    "most_common = all_responses.iloc[0]\n",
    "least_common = all_responses.iloc[-1]\n",
    "\n",
    "question_text = \"A.4.2 AI Ethics Principles to Consider for Future Operations\"\n",
    "print(question_text)\n",
    "print(f\"Total valid responses: {total_valid_responses}\")\n",
    "print(f\"Total responses across all principles: {total_responses}\")\n",
    "print(f\"Total unique ethics principles: {total_options}\")\n",
    "print(f\"Average responses per principle: {average_responses:.2f}\")\n",
    "print(f\"Most common principle: {most_common['Option']} ({most_common['Count']} responses, {most_common['Percentage']}% of respondents)\")\n",
    "print(f\"Least common principle: {least_common['Option']} ({least_common['Count']} responses, {least_common['Percentage']}% of respondents)\")\n",
    "\n",
    "print(\"\\nBreakdown of responses:\")\n",
    "for _, row in all_responses.iterrows():\n",
    "    print(f\"{row['Option']}: {row['Count']} responses ({row['Percentage']}% of respondents)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A.4.3 Reasons for Not Integrating AI Systems\n",
      "Total valid responses: 61\n",
      "Total responses across all reasons: 183\n",
      "Total unique reasons: 10\n",
      "Average responses per reason: 18.30\n",
      "Most common reason: Data Protection and Right to Privacy (37 responses, 60.66% of respondents)\n",
      "Least common reason: Democracy and Rule of Law (7 responses, 11.48% of respondents)\n",
      "\n",
      "Breakdown of responses:\n",
      "Data Protection and Right to Privacy: 37 responses (60.66% of respondents)\n",
      "Accountability and Responsibility: 26 responses (42.62% of respondents)\n",
      "Transparency and Explainability of AI Systems: 21 responses (34.43% of respondents)\n",
      "Respect for Human Rights: 19 responses (31.15% of respondents)\n",
      "All: 18 responses (29.51% of respondents)\n",
      "Harm Prevention and Beneficence: 16 responses (26.23% of respondents)\n",
      "Non-Discrimination and Freedom of Privileges: 14 responses (22.95% of respondents)\n",
      "Fairness and Justice: 13 responses (21.31% of respondents)\n",
      "Environment and Social Responsibility: 12 responses (19.67% of respondents)\n",
      "Democracy and Rule of Law: 7 responses (11.48% of respondents)\n"
     ]
    }
   ],
   "source": [
    "#################\n",
    "# A.4.3\n",
    "#################\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import re\n",
    "\n",
    "# Step 1: Read CSV file into a DataFrame\n",
    "df = pd.read_csv(ai_study)\n",
    "\n",
    "# Step 2: Exclude the first two rows\n",
    "df = df.iloc[2:]\n",
    "\n",
    "# Step 3: Remove NaNs or empty values in 'A.4.3'\n",
    "df = df[df['A.4.3'].notna()]  # Remove NaNs\n",
    "df['A.4.3'] = df['A.4.3'].astype(str).apply(lambda x: x.strip())\n",
    "df = df[df['A.4.3'] != \"\"]  # Remove empty strings\n",
    "\n",
    "# Step 4: Process the responses\n",
    "# Split the strings by comma and normalize by stripping whitespace\n",
    "df['A.4.3'] = df['A.4.3'].apply(lambda x: re.split(r',\\s*', x))\n",
    "\n",
    "# Flatten the list of responses and count occurrences\n",
    "all_responses = df['A.4.3'].explode().value_counts().reset_index()\n",
    "all_responses.columns = ['Option', 'Count']\n",
    "\n",
    "# Step 5: Calculate total number of valid responses (non-empty)\n",
    "total_valid_responses = df.shape[0]\n",
    "\n",
    "# Step 6: Calculate the percentage of each option based on valid responses\n",
    "all_responses['Percentage'] = (all_responses['Count'] / total_valid_responses * 100).round(2)\n",
    "\n",
    "# Step 7: Visualize the results with a Bar Chart using Plotly\n",
    "fig = px.bar(all_responses, x='Option', y='Count',\n",
    "             title='A.4.3 Reasons for Not Integrating AI Systems',\n",
    "             labels={'Option': 'Reasons for Not Integrating AI', 'Count': 'Number of Responses'},\n",
    "             color='Count',\n",
    "             color_continuous_scale='Blues',\n",
    "             text=all_responses['Percentage'].apply(lambda x: f'{x}%'))  # Add percentage text\n",
    "\n",
    "# Update layout to make the chart clearer\n",
    "fig.update_layout(xaxis_tickangle=45, xaxis_title='Reasons', yaxis_title='Number of Responses')\n",
    "\n",
    "# Step 8: Show the figure\n",
    "fig.show(renderer=\"browser\")\n",
    "\n",
    "\n",
    "# Statistical Analysis\n",
    "total_responses = all_responses['Count'].sum()\n",
    "total_options = len(all_responses)\n",
    "average_responses = total_responses / total_options\n",
    "most_common = all_responses.iloc[0]\n",
    "least_common = all_responses.iloc[-1]\n",
    "\n",
    "question_text = \"A.4.3 Reasons for Not Integrating AI Systems\"\n",
    "print(question_text)\n",
    "print(f\"Total valid responses: {total_valid_responses}\")\n",
    "print(f\"Total responses across all reasons: {total_responses}\")\n",
    "print(f\"Total unique reasons: {total_options}\")\n",
    "print(f\"Average responses per reason: {average_responses:.2f}\")\n",
    "print(f\"Most common reason: {most_common['Option']} ({most_common['Count']} responses, {most_common['Percentage']}% of respondents)\")\n",
    "print(f\"Least common reason: {least_common['Option']} ({least_common['Count']} responses, {least_common['Percentage']}% of respondents)\")\n",
    "\n",
    "print(\"\\nBreakdown of responses:\")\n",
    "for _, row in all_responses.iterrows():\n",
    "    print(f\"{row['Option']}: {row['Count']} responses ({row['Percentage']}% of respondents)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B.1.2 Primary Applications of AI in Products\n",
      "Total valid responses: 303\n",
      "Total responses across all applications: 1632\n",
      "Total unique AI applications: 18\n",
      "Average responses per application: 90.67\n",
      "Most common application: Chatbots, Personal Assistants or Recommender Systems (193 responses, 63.7% of respondents)\n",
      "Least common application: Prefer not to say (1 responses, 0.33% of respondents)\n",
      "\n",
      "Breakdown of responses:\n",
      "Chatbots, Personal Assistants or Recommender Systems: 193 responses (63.7% of respondents)\n",
      "Customer Service: 145 responses (47.85% of respondents)\n",
      "Programming analysis (e.g., Code completion or code generation): 132 responses (43.56% of respondents)\n",
      "Translation or Text Generation: 129 responses (42.57% of respondents)\n",
      "Predictive Analysis: 123 responses (40.59% of respondents)\n",
      "Robotics and Automation: 120 responses (39.6% of respondents)\n",
      "Cybersecurity: 113 responses (37.29% of respondents)\n",
      "Computer Vision: 101 responses (33.33% of respondents)\n",
      "Financial Services: 97 responses (32.01% of respondents)\n",
      "Healthcare: 81 responses (26.73% of respondents)\n",
      "Logistics: 74 responses (24.42% of respondents)\n",
      "Entertainment or Communication: 73 responses (24.09% of respondents)\n",
      "Personalization and Advertisement: 72 responses (23.76% of respondents)\n",
      "Human Resources: 71 responses (23.43% of respondents)\n",
      "Legal: 56 responses (18.48% of respondents)\n",
      "Retail: 44 responses (14.52% of respondents)\n",
      "Other, please explain: 7 responses (2.31% of respondents)\n",
      "Prefer not to say: 1 responses (0.33% of respondents)\n"
     ]
    }
   ],
   "source": [
    "#############################\n",
    "# B.1.2\n",
    "###################\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Step 1: Read CSV file into a DataFrame\n",
    "df = pd.read_csv(ai_study)\n",
    "\n",
    "# Step 2: Exclude the first two rows\n",
    "df = df.iloc[2:]\n",
    "\n",
    "# Function to split responses, keeping special categories together\n",
    "def split_responses(response):\n",
    "    if pd.isna(response):\n",
    "        return []\n",
    "    parts = str(response).split(',')\n",
    "    result = []\n",
    "    i = 0\n",
    "    chatbot_category_added = False\n",
    "    while i < len(parts):\n",
    "        if i+1 < len(parts) and parts[i].strip() == \"Other\" and parts[i+1].strip() == \"please explain\":\n",
    "            result.append(\"Other, please explain\")\n",
    "            i += 2\n",
    "        elif i+1 < len(parts) and parts[i].strip() == \"Programming Analysis (e.g.\" and parts[i+1].strip().startswith(\"Code Completion or Code Generation\"):\n",
    "            result.append(\"Programming analysis (e.g., Code completion or code generation)\")\n",
    "            i += 2\n",
    "        elif not chatbot_category_added and (parts[i].strip() in [\"Chatbots\", \"Personal Assistants or Recommender Systems\"] or (i+1 < len(parts) and parts[i].strip() == \"Personal Assistants\" and parts[i+1].strip() == \"or Recommender Systems\")):\n",
    "            result.append(\"Chatbots, Personal Assistants or Recommender Systems\")\n",
    "            chatbot_category_added = True\n",
    "            i += 2 if parts[i].strip() == \"Personal Assistants\" else 1\n",
    "        elif chatbot_category_added and parts[i].strip() in [\"Chatbots\", \"Personal Assistants\", \"Recommender Systems\", \"Personal Assistants or Recommender Systems\"]:\n",
    "            i += 1  # Skip this part as we've already added the category\n",
    "        else:\n",
    "            result.append(parts[i].strip())\n",
    "            i += 1\n",
    "    return result\n",
    "\n",
    "# Step 3: Process the responses using the split_responses function\n",
    "df['B.1.2'] = df['B.1.2'].apply(split_responses)\n",
    "\n",
    "# Step 4: Flatten the list of responses and count occurrences\n",
    "all_responses = df['B.1.2'].explode().dropna().value_counts().reset_index()\n",
    "all_responses.columns = ['Option', 'Count']\n",
    "\n",
    "# Step 5: Calculate total number of valid responses (non-empty)\n",
    "total_valid_responses = df[df['B.1.2'].apply(len) > 0].shape[0]\n",
    "\n",
    "# Step 6: Calculate the percentage of each option based on valid responses\n",
    "all_responses['Percentage'] = (all_responses['Count'] / total_valid_responses * 100).round(2)\n",
    "\n",
    "# Step 7: Visualize the results with a Bar Chart using Plotly\n",
    "fig = px.bar(all_responses, x='Option', y='Count',\n",
    "             title='B.1.2 Primary Applications of AI in Products',\n",
    "             labels={'Option': 'AI Application', 'Count': 'Number of Responses'},\n",
    "             color='Count',\n",
    "             color_continuous_scale='Blues',\n",
    "             text=all_responses['Percentage'].apply(lambda x: f'{x}%'))  # Add percentage text\n",
    "\n",
    "# Update layout to make the chart clearer\n",
    "fig.update_layout(xaxis_tickangle=45, xaxis_title='AI Application', yaxis_title='Number of Responses')\n",
    "\n",
    "# Step 8: Show the figure\n",
    "fig.show(renderer=\"browser\")\n",
    "\n",
    "\n",
    "# Statistical Analysis\n",
    "total_responses = all_responses['Count'].sum()\n",
    "total_options = len(all_responses)\n",
    "average_responses = total_responses / total_options\n",
    "most_common = all_responses.iloc[0]\n",
    "least_common = all_responses.iloc[-1]\n",
    "\n",
    "question_text = \"B.1.2 Primary Applications of AI in Products\"\n",
    "print(question_text)\n",
    "print(f\"Total valid responses: {total_valid_responses}\")\n",
    "print(f\"Total responses across all applications: {total_responses}\")\n",
    "print(f\"Total unique AI applications: {total_options}\")\n",
    "print(f\"Average responses per application: {average_responses:.2f}\")\n",
    "print(f\"Most common application: {most_common['Option']} ({most_common['Count']} responses, {most_common['Percentage']}% of respondents)\")\n",
    "print(f\"Least common application: {least_common['Option']} ({least_common['Count']} responses, {least_common['Percentage']}% of respondents)\")\n",
    "\n",
    "print(\"\\nBreakdown of responses:\")\n",
    "for _, row in all_responses.iterrows():\n",
    "    print(f\"{row['Option']}: {row['Count']} responses ({row['Percentage']}% of respondents)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B.1.3 Frequency of AI-Enhanced Tool Usage\n",
      "Total valid responses: 362\n",
      "Total unique frequency options: 7\n",
      "Average responses per option: 51.71\n",
      "Most common frequency: Daily (179 responses, 49.45% of respondents)\n",
      "Least common frequency: How often do you use AI-enhanced tools in your work? (1 responses, 0.28% of respondents)\n",
      "\n",
      "Breakdown of responses:\n",
      "Daily: 179 responses (49.45% of respondents)\n",
      "4-6 times a week: 88 responses (24.31% of respondents)\n",
      "1-3 times a week: 71 responses (19.61% of respondents)\n",
      "Rarely: 11 responses (3.04% of respondents)\n",
      "Prefer not to say: 7 responses (1.93% of respondents)\n",
      "Never: 5 responses (1.38% of respondents)\n",
      "How often do you use AI-enhanced tools in your work?: 1 responses (0.28% of respondents)\n"
     ]
    }
   ],
   "source": [
    "####################\n",
    "# B.1.3\n",
    "######################\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Step 1: Read CSV file into a DataFrame\n",
    "df = pd.read_csv(ai_study)\n",
    "\n",
    "# Step 2: Exclude the first two rows\n",
    "df = df.iloc[2:]\n",
    "\n",
    "# Step 3: Remove NaNs or empty values in 'B.1.3'\n",
    "df = df[df['B.1.3'].notna()]  # Remove NaNs\n",
    "df['B.1.3'] = df['B.1.3'].astype(str).apply(lambda x: x.strip())\n",
    "df = df[df['B.1.3'] != \"\"]  # Remove empty strings\n",
    "\n",
    "# Step 4: Count occurrences of each response\n",
    "response_counts = df['B.1.3'].value_counts().reset_index()\n",
    "response_counts.columns = ['Response', 'Count']\n",
    "\n",
    "# Step 5: Calculate total number of valid responses\n",
    "total_valid_responses = df.shape[0]\n",
    "\n",
    "# Step 6: Calculate the percentage of each option based on valid responses\n",
    "response_counts['Percentage'] = (response_counts['Count'] / total_valid_responses * 100).round(2)\n",
    "\n",
    "# Step 7: Visualize the results with a Pie Chart using Plotly\n",
    "fig = px.pie(response_counts, names='Response', values='Count',\n",
    "             title='Frequency of AI-Enhanced Tool Usage',\n",
    "             color_discrete_sequence=px.colors.sequential.Blues,\n",
    "             labels={'Response': 'Usage Frequency', 'Count': 'Number of Responses'})\n",
    "\n",
    "# Add percentage text to the pie slices\n",
    "fig.update_traces(textinfo='percent+label')\n",
    "\n",
    "# Step 8: Show the figure\n",
    "fig.show(renderer=\"browser\")\n",
    "\n",
    "total_responses = response_counts['Count'].sum()\n",
    "total_options = len(response_counts)\n",
    "average_responses = total_responses / total_options\n",
    "most_common = response_counts.iloc[0]\n",
    "least_common = response_counts.iloc[-1]\n",
    "\n",
    "question_text = \"B.1.3 Frequency of AI-Enhanced Tool Usage\"\n",
    "print(question_text)\n",
    "print(f\"Total valid responses: {total_valid_responses}\")\n",
    "print(f\"Total unique frequency options: {total_options}\")\n",
    "print(f\"Average responses per option: {average_responses:.2f}\")\n",
    "print(f\"Most common frequency: {most_common['Response']} ({most_common['Count']} responses, {most_common['Percentage']}% of respondents)\")\n",
    "print(f\"Least common frequency: {least_common['Response']} ({least_common['Count']} responses, {least_common['Percentage']}% of respondents)\")\n",
    "\n",
    "print(\"\\nBreakdown of responses:\")\n",
    "for _, row in response_counts.iterrows():\n",
    "    print(f\"{row['Response']}: {row['Count']} responses ({row['Percentage']}% of respondents)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track B: Effect of AI-Enhanced Tools on Development Process and Workflow\n",
      "Total valid responses: 302\n",
      "Total responses across all impacts: 1287\n",
      "Total unique impacts: 13\n",
      "Average responses per impact: 99.00\n",
      "Most common impact: Increased Efficiency (234 responses, 77.48% of respondents)\n",
      "Least common impact: Prefer not to say (3 responses, 0.99% of respondents)\n",
      "\n",
      "Breakdown of responses:\n",
      "Increased Efficiency: 234 responses (77.48% of respondents)\n",
      "Improved Accuracy: 167 responses (55.3% of respondents)\n",
      "Cost Reduction: 160 responses (52.98% of respondents)\n",
      "Innovation and Creativity: 141 responses (46.69% of respondents)\n",
      "Improved Research Quality: 140 responses (46.36% of respondents)\n",
      "Enhanced Decision Making: 120 responses (39.74% of respondents)\n",
      "Training and Skill Development: 112 responses (37.09% of respondents)\n",
      "Streamlined Workflows: 111 responses (36.75% of respondents)\n",
      "Security and Privacy Concerns: 70 responses (23.18% of respondents)\n",
      "No Significant Impact: 19 responses (6.29% of respondents)\n",
      "Other: 5 responses (1.66% of respondents)\n",
      "please explain: 5 responses (1.66% of respondents)\n",
      "Prefer not to say: 3 responses (0.99% of respondents)\n"
     ]
    }
   ],
   "source": [
    "##################\n",
    "# B.1.4\n",
    "##################  \n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import re\n",
    "\n",
    "# Step 1: Read CSV file into a DataFrame\n",
    "df = pd.read_csv(ai_study)\n",
    "\n",
    "# Step 2: Exclude the first two rows\n",
    "df = df.iloc[2:]\n",
    "\n",
    "# Step 3: Remove NaNs or empty values in 'B.1.4'\n",
    "df = df[df['B.1.4'].notna()]  # Remove NaNs\n",
    "df['B.1.4'] = df['B.1.4'].astype(str).apply(lambda x: x.strip())\n",
    "df = df[df['B.1.4'] != \"\"]  # Remove empty strings\n",
    "\n",
    "# Step 4: Process the responses\n",
    "# Split the strings by comma and normalize by stripping whitespace\n",
    "df['B.1.4'] = df['B.1.4'].apply(lambda x: re.split(r',\\s*', x))\n",
    "\n",
    "# Flatten the list of responses and count occurrences\n",
    "all_responses = df['B.1.4'].explode().value_counts().reset_index()\n",
    "all_responses.columns = ['Option', 'Count']\n",
    "\n",
    "# Step 5: Calculate total number of valid responses (non-empty)\n",
    "total_valid_responses = df.shape[0]\n",
    "\n",
    "# Step 6: Calculate the percentage of each option based on valid responses\n",
    "all_responses['Percentage'] = (all_responses['Count'] / total_valid_responses * 100).round(2)\n",
    "\n",
    "# Step 7: Visualize the results with a Bar Chart using Plotly\n",
    "fig = px.bar(all_responses, x='Option', y='Count',\n",
    "             title='B.1.4 Effect of AI-Enhanced Tools on Development Process and Workflow',\n",
    "             labels={'Option': 'Impact of AI-Enhanced Tools', 'Count': 'Number of Responses'},\n",
    "             color='Count',\n",
    "             color_continuous_scale='Blues',\n",
    "             text=all_responses['Percentage'].apply(lambda x: f'{x}%'))  # Add percentage text\n",
    "\n",
    "# Update layout to make the chart clearer\n",
    "fig.update_layout(xaxis_tickangle=45, xaxis_title='Impact', yaxis_title='Number of Responses')\n",
    "\n",
    "# Step 8: Show the figure\n",
    "fig.show(renderer=\"browser\")\n",
    "\n",
    "\n",
    "# Statistical Analysis\n",
    "total_responses = all_responses['Count'].sum()\n",
    "total_options = len(all_responses)\n",
    "average_responses = total_responses / total_options\n",
    "most_common = all_responses.iloc[0]\n",
    "least_common = all_responses.iloc[-1]\n",
    "\n",
    "question_text = \"Track B: Effect of AI-Enhanced Tools on Development Process and Workflow\"\n",
    "print(question_text)\n",
    "print(f\"Total valid responses: {total_valid_responses}\")\n",
    "print(f\"Total responses across all impacts: {total_responses}\")\n",
    "print(f\"Total unique impacts: {total_options}\")\n",
    "print(f\"Average responses per impact: {average_responses:.2f}\")\n",
    "print(f\"Most common impact: {most_common['Option']} ({most_common['Count']} responses, {most_common['Percentage']}% of respondents)\")\n",
    "print(f\"Least common impact: {least_common['Option']} ({least_common['Count']} responses, {least_common['Percentage']}% of respondents)\")\n",
    "\n",
    "print(\"\\nBreakdown of responses:\")\n",
    "for _, row in all_responses.iterrows():\n",
    "    print(f\"{row['Option']}: {row['Count']} responses ({row['Percentage']}% of respondents)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantitative Analysis for B.1.5: Tools and Technologies used to develop or deploy your products\n",
      "Total valid responses: 300\n",
      "\n",
      "Breakdown of responses:\n",
      "Google Cloud AI: 148 mentions (49.33% of respondents), Model provider APIs: 128 mentions (42.67% of respondents), Anthropic: 128 mentions (42.67% of respondents), DeepInfra: 128 mentions (42.67% of respondents), OpenAI: 128 mentions (42.67% of respondents), i.e.: 128 mentions (42.67% of respondents), LLama: 128 mentions (42.67% of respondents), Azure ML: 97 mentions (32.33% of respondents), PyTorch: 89 mentions (29.67% of respondents), AWS SageMaker: 75 mentions (25.0% of respondents), Pandas: 73 mentions (24.33% of respondents), TensorFlow / Keras: 72 mentions (24.0% of respondents), Convolutional Neural Network (CNN): 66 mentions (22.0% of respondents), HuggingFace: 64 mentions (21.33% of respondents), Sci-Kit Learn / NLTK: 62 mentions (20.67% of respondents), OpenCV: 58 mentions (19.33% of respondents), Transformer Based LLM: 53 mentions (17.67% of respondents), Vision Transformers (ViT): 52 mentions (17.33% of respondents), RNN: 46 mentions (15.33% of respondents), LSTM / GRU: 46 mentions (15.33% of respondents), Neural Auto Encoder: 45 mentions (15.0% of respondents), LangChain: 41 mentions (13.67% of respondents), Ollama: 32 mentions (10.67% of respondents), Other Data Science / AI programming framework - Please list: 18 mentions (6.0% of respondents), Other Deep Learning / Neural Network - Please list: 17 mentions (5.67% of respondents), Other Model Provider / Host / Server - Please list: 9 mentions (3.0% of respondents)\n",
      "\n",
      "Total mentions across all tools/technologies: 1931, Average mentions per tool/technology: 74.27, Most common tool/technology: Google Cloud AI (148 mentions, 49.33% of respondents), Least common tool/technology: Other Model Provider / Host / Server - Please list (9 mentions, 3.0% of respondents)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Step 1: Read CSV file into a DataFrame\n",
    "df = pd.read_csv(ai_study)\n",
    "\n",
    "# Step 2: Exclude the first two rows\n",
    "df = df.iloc[2:]\n",
    "\n",
    "# Function to split multiple responses (assumes responses are comma-separated)\n",
    "def split_responses(response):\n",
    "    if pd.isna(response):\n",
    "        return []\n",
    "    # Split by comma and strip any extra whitespace\n",
    "    return [part.strip() for part in str(response).split(',')]\n",
    "\n",
    "# Step 3: Process the responses for b.1.5 using the split_responses function\n",
    "df['B.1.5'] = df['B.1.5'].apply(split_responses)\n",
    "\n",
    "# Step 4: Flatten the list of responses and count occurrences\n",
    "all_responses = df['B.1.5'].explode().dropna().value_counts().reset_index()\n",
    "all_responses.columns = ['Tool or Technology', 'Count']\n",
    "\n",
    "# Step 5: Calculate total number of valid responses (rows with non-empty lists)\n",
    "total_valid_responses = df[df['B.1.5'].apply(len) > 0].shape[0]\n",
    "\n",
    "# Step 6: Calculate the percentage of rows that mention each tool/technology\n",
    "all_responses['Percentage'] = (all_responses['Count'] / total_valid_responses * 100).round(2)\n",
    "\n",
    "# Print quantitative analysis\n",
    "print(\"Quantitative Analysis for B.1.5: Tools and Technologies used to develop or deploy your products\")\n",
    "print(f\"Total valid responses: {total_valid_responses}\")\n",
    "\n",
    "print(\"\\nBreakdown of responses:\")\n",
    "breakdown = \", \".join([\n",
    "    f\"{row['Tool or Technology']}: {row['Count']} mentions ({row['Percentage']}% of respondents)\"\n",
    "    for _, row in all_responses.iterrows()\n",
    "])\n",
    "print(breakdown)\n",
    "\n",
    "# Calculate and print summary statistics\n",
    "total_mentions = all_responses['Count'].sum()\n",
    "average_mentions = total_mentions / len(all_responses)\n",
    "summary_stats = [\n",
    "    f\"Total mentions across all tools/technologies: {total_mentions}\",\n",
    "    f\"Average mentions per tool/technology: {average_mentions:.2f}\",\n",
    "    f\"Most common tool/technology: {all_responses.iloc[0]['Tool or Technology']} ({all_responses.iloc[0]['Count']} mentions, {all_responses.iloc[0]['Percentage']}% of respondents)\",\n",
    "    f\"Least common tool/technology: {all_responses.iloc[-1]['Tool or Technology']} ({all_responses.iloc[-1]['Count']} mentions, {all_responses.iloc[-1]['Percentage']}% of respondents)\"\n",
    "]\n",
    "print(\"\\n\" + \", \".join(summary_stats))\n",
    "\n",
    "# Step 7: Visualize the results with a Bar Chart using Plotly\n",
    "fig = px.bar(\n",
    "    all_responses, \n",
    "    x='Tool or Technology', \n",
    "    y='Count',\n",
    "    title='B.1.5: Tools and Technologies used in Product Development/Deployment',\n",
    "    labels={'Tool or Technology': 'Tool/Technology', 'Count': 'Number of Mentions'},\n",
    "    color='Count',\n",
    "    color_continuous_scale='Blues',\n",
    "    text=all_responses['Percentage'].apply(lambda x: f'{x}% of respondents')\n",
    ")\n",
    "\n",
    "# Update layout to enhance readability\n",
    "fig.update_layout(xaxis_tickangle=45, xaxis_title='Tool/Technology', yaxis_title='Number of Mentions')\n",
    "\n",
    "# Step 8: Show the figure\n",
    "fig.show(renderer=\"browser\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Step 1: Read CSV file into a DataFrame\n",
    "df = pd.read_csv(ai_study)\n",
    "\n",
    "# Step 2: Exclude the first two rows\n",
    "df = df.iloc[2:]\n",
    "\n",
    "# Step 3: Remove NaNs or empty values in 'B.2.2'\n",
    "df = df[df['B.2.2'].notna()]  # Remove NaNs\n",
    "df['B.2.2'] = df['B.2.2'].astype(str).apply(lambda x: x.strip())\n",
    "df = df[df['B.2.2'] != \"\"]  # Remove empty strings\n",
    "\n",
    "# Step 4: Process the responses\n",
    "# Split the strings by comma and normalize by stripping whitespace\n",
    "df['B.2.2'] = df['B.2.2'].apply(lambda x: [item.strip() for item in x.split(',')])\n",
    "\n",
    "# Step 5: Flatten the list of responses and count occurrences\n",
    "all_responses = df['B.2.2'].explode().value_counts().reset_index()\n",
    "all_responses.columns = ['Principle', 'Count']\n",
    "\n",
    "# Step 6: Calculate total number of valid responses (rows with non-empty lists)\n",
    "total_valid_responses = df[df['B.2.2'].apply(len) > 0].shape[0]\n",
    "\n",
    "# Step 7: Calculate the percentage of rows that mention each principle\n",
    "all_responses['Percentage'] = (all_responses['Count'] / total_valid_responses * 100).round(2)\n",
    "\n",
    "# Step 8: Visualize the results with a Bar Chart using Plotly\n",
    "fig = px.bar(all_responses, x='Principle', y='Count',\n",
    "             title='B.2.2 Principles Considered in Product Development or Deployment',\n",
    "             labels={'Principle': 'Ethical Principle', 'Count': 'Number of Mentions'},\n",
    "             color='Count',\n",
    "             color_continuous_scale='Blues',\n",
    "             text=all_responses['Percentage'].apply(lambda x: f'<b><span style=\"font-weight:900;\">{x}</span></b>'))\n",
    "\n",
    "# Update layout to match the visual\n",
    "fig.update_layout(\n",
    "    xaxis_tickangle=45,\n",
    "    xaxis_title='Ethical Principle',\n",
    "    yaxis_title='Number of Mentions',\n",
    "    title={\n",
    "        'text': 'B.2.2 Principles Considered in Product Development or Deployment',\n",
    "        'y': 0.95,\n",
    "        'x': 0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'\n",
    "    },\n",
    "    font=dict(size=12),\n",
    "    margin=dict(t=150),\n",
    "    yaxis=dict(range=[0, all_responses['Count'].max() * 1.15]),\n",
    "    coloraxis_showscale=False\n",
    ")\n",
    "\n",
    "# Update traces to position text just above the bars and ensure uniform text size\n",
    "fig.update_traces(\n",
    "    textposition='outside',\n",
    "    textfont=dict(size=16, family='sans-serif', weight='bold'),\n",
    "    cliponaxis=False\n",
    ")\n",
    "\n",
    "# Step 9: Show the figure\n",
    "fig.show(renderer=\"browser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read AI_Study_Accepted_with_replacement_codes.csv.\n",
      "Index(['Remove? (Yes/No/Maybe)', 'StartDate', 'EndDate', 'Finished',\n",
      "       'RecordedDate', 'Unnamed: 5', 'ResponseId', 'UserLanguage',\n",
      "       'Q_RecaptchaScore', 'Q_RelevantIDDuplicate',\n",
      "       ...\n",
      "       'C.1 _5', 'C.1 _6', 'C.1 _7', 'C.1 _8', 'C.2', 'C.3.a', 'C.3_1_TEXT',\n",
      "       'C.3_2_TEXT', 'C.3_3_TEXT', 'PROLIFIC_PID'],\n",
      "      dtype='object', length=234)\n",
      "Processing Location...\n",
      "\n",
      "Ranked Results for Location:\n",
      "\n",
      "| Principle                                     | Location   | Percentage   |\n",
      "|:----------------------------------------------|:-----------|:-------------|\n",
      "| Accountability and Responsibility             | Other      | 42.42        |\n",
      "| Accountability and Responsibility             | US         | 37.41        |\n",
      "| Accountability and Responsibility             | Europe     | 37.18        |\n",
      "| All                                           | US         | 21.58        |\n",
      "| All                                           | Other      | 19.7         |\n",
      "| All                                           | Europe     | 17.95        |\n",
      "| Data Protection and Right to Privacy          | Europe     | 78.21        |\n",
      "| Data Protection and Right to Privacy          | US         | 69.06        |\n",
      "| Data Protection and Right to Privacy          | Other      | 66.67        |\n",
      "| Democracy and Rule of Law                     | Europe     | 24.36        |\n",
      "| Democracy and Rule of Law                     | US         | 23.74        |\n",
      "| Democracy and Rule of Law                     | Other      | 22.73        |\n",
      "| Environment and Social Responsibility         | Other      | 33.33        |\n",
      "| Environment and Social Responsibility         | Europe     | 32.05        |\n",
      "| Environment and Social Responsibility         | US         | 17.99        |\n",
      "| Fairness and Justice                          | Other      | 45.45        |\n",
      "| Fairness and Justice                          | Europe     | 34.62        |\n",
      "| Fairness and Justice                          | US         | 34.53        |\n",
      "| Harm Prevention and Beneficence               | Other      | 51.52        |\n",
      "| Harm Prevention and Beneficence               | Europe     | 35.9         |\n",
      "| Harm Prevention and Beneficence               | US         | 33.81        |\n",
      "| Non-Discrimination and Freedom of Privileges  | US         | 38.85        |\n",
      "| Non-Discrimination and Freedom of Privileges  | Other      | 33.33        |\n",
      "| Non-Discrimination and Freedom of Privileges  | Europe     | 23.08        |\n",
      "| None                                          | US         | 0.72         |\n",
      "| Respect for Human Rights                      | Other      | 54.55        |\n",
      "| Respect for Human Rights                      | Europe     | 46.15        |\n",
      "| Respect for Human Rights                      | US         | 38.85        |\n",
      "| Transparency and Explainability of AI Systems | Other      | 57.58        |\n",
      "| Transparency and Explainability of AI Systems | US         | 46.76        |\n",
      "| Transparency and Explainability of AI Systems | Europe     | 38.46        |\n",
      "Processing Company Type...\n",
      "\n",
      "Ranked Results for Company Type:\n",
      "\n",
      "| Principle                                     | Company Type      | Percentage   |\n",
      "|:----------------------------------------------|:------------------|:-------------|\n",
      "| Accountability and Responsibility             | Other             | 53.12        |\n",
      "| Accountability and Responsibility             | Government        | 47.83        |\n",
      "| Accountability and Responsibility             | Multi-national    | 39.8         |\n",
      "| Accountability and Responsibility             | Academic/Research | 33.33        |\n",
      "| Accountability and Responsibility             | Startup/Small     | 30.53        |\n",
      "| All                                           | Academic/Research | 30           |\n",
      "| All                                           | Multi-national    | 23.47        |\n",
      "| All                                           | Government        | 21.74        |\n",
      "| All                                           | Other             | 15.62        |\n",
      "| All                                           | Startup/Small     | 13.68        |\n",
      "| Data Protection and Right to Privacy          | Academic/Research | 80           |\n",
      "| Data Protection and Right to Privacy          | Government        | 78.26        |\n",
      "| Data Protection and Right to Privacy          | Multi-national    | 71.43        |\n",
      "| Data Protection and Right to Privacy          | Startup/Small     | 70.53        |\n",
      "| Data Protection and Right to Privacy          | Other             | 65.62        |\n",
      "| Democracy and Rule of Law                     | Government        | 39.13        |\n",
      "| Democracy and Rule of Law                     | Multi-national    | 24.49        |\n",
      "| Democracy and Rule of Law                     | Other             | 21.88        |\n",
      "| Democracy and Rule of Law                     | Startup/Small     | 21.05        |\n",
      "| Democracy and Rule of Law                     | Academic/Research | 16.67        |\n",
      "| Environment and Social Responsibility         | Government        | 39.13        |\n",
      "| Environment and Social Responsibility         | Other             | 31.25        |\n",
      "| Environment and Social Responsibility         | Multi-national    | 28.57        |\n",
      "| Environment and Social Responsibility         | Startup/Small     | 17.89        |\n",
      "| Environment and Social Responsibility         | Academic/Research | 16.67        |\n",
      "| Fairness and Justice                          | Academic/Research | 56.67        |\n",
      "| Fairness and Justice                          | Government        | 56.52        |\n",
      "| Fairness and Justice                          | Other             | 43.75        |\n",
      "| Fairness and Justice                          | Multi-national    | 33.67        |\n",
      "| Fairness and Justice                          | Startup/Small     | 29.47        |\n",
      "| Harm Prevention and Beneficence               | Government        | 56.52        |\n",
      "| Harm Prevention and Beneficence               | Academic/Research | 46.67        |\n",
      "| Harm Prevention and Beneficence               | Other             | 40.62        |\n",
      "| Harm Prevention and Beneficence               | Multi-national    | 37.76        |\n",
      "| Harm Prevention and Beneficence               | Startup/Small     | 30.53        |\n",
      "| Non-Discrimination and Freedom of Privileges  | Government        | 60.87        |\n",
      "| Non-Discrimination and Freedom of Privileges  | Other             | 37.5         |\n",
      "| Non-Discrimination and Freedom of Privileges  | Academic/Research | 36.67        |\n",
      "| Non-Discrimination and Freedom of Privileges  | Startup/Small     | 29.47        |\n",
      "| Non-Discrimination and Freedom of Privileges  | Multi-national    | 25.51        |\n",
      "| None                                          | Other             | 3.12         |\n",
      "| Respect for Human Rights                      | Government        | 60.87        |\n",
      "| Respect for Human Rights                      | Academic/Research | 50           |\n",
      "| Respect for Human Rights                      | Multi-national    | 43.88        |\n",
      "| Respect for Human Rights                      | Other             | 43.75        |\n",
      "| Respect for Human Rights                      | Startup/Small     | 40           |\n",
      "| Transparency and Explainability of AI Systems | Other             | 59.38        |\n",
      "| Transparency and Explainability of AI Systems | Academic/Research | 56.67        |\n",
      "| Transparency and Explainability of AI Systems | Government        | 52.17        |\n",
      "| Transparency and Explainability of AI Systems | Multi-national    | 46.94        |\n",
      "| Transparency and Explainability of AI Systems | Startup/Small     | 40           |\n",
      "Processing Role...\n",
      "\n",
      "Ranked Results for Role:\n",
      "\n",
      "| Principle                                     | Role                 | Percentage   |\n",
      "|:----------------------------------------------|:---------------------|:-------------|\n",
      "| Accountability and Responsibility             | Other                | 66.67        |\n",
      "| Accountability and Responsibility             | AI Researcher        | 45           |\n",
      "| Accountability and Responsibility             | Requirements analyst | 44.12        |\n",
      "| Accountability and Responsibility             | AI Manager           | 43.86        |\n",
      "| Accountability and Responsibility             | Security/Privacy     | 41.67        |\n",
      "| Accountability and Responsibility             | AI developers        | 35.61        |\n",
      "| Accountability and Responsibility             | QA and Maintenance   | 30.77        |\n",
      "| All                                           | AI Researcher        | 35           |\n",
      "| All                                           | QA and Maintenance   | 30.77        |\n",
      "| All                                           | Security/Privacy     | 25           |\n",
      "| All                                           | AI developers        | 20.45        |\n",
      "| All                                           | AI Manager           | 15.79        |\n",
      "| All                                           | Requirements analyst | 14.71        |\n",
      "| Data Protection and Right to Privacy          | AI developers        | 76.52        |\n",
      "| Data Protection and Right to Privacy          | AI Manager           | 71.93        |\n",
      "| Data Protection and Right to Privacy          | Requirements analyst | 70.59        |\n",
      "| Data Protection and Right to Privacy          | AI Researcher        | 70           |\n",
      "| Data Protection and Right to Privacy          | Other                | 66.67        |\n",
      "| Data Protection and Right to Privacy          | QA and Maintenance   | 61.54        |\n",
      "| Data Protection and Right to Privacy          | Security/Privacy     | 58.33        |\n",
      "| Democracy and Rule of Law                     | Requirements analyst | 35.29        |\n",
      "| Democracy and Rule of Law                     | AI Manager           | 31.58        |\n",
      "| Democracy and Rule of Law                     | AI Researcher        | 25           |\n",
      "| Democracy and Rule of Law                     | AI developers        | 22.73        |\n",
      "| Democracy and Rule of Law                     | Security/Privacy     | 16.67        |\n",
      "| Democracy and Rule of Law                     | QA and Maintenance   | 7.69         |\n",
      "| Environment and Social Responsibility         | Other                | 66.67        |\n",
      "| Environment and Social Responsibility         | Requirements analyst | 35.29        |\n",
      "| Environment and Social Responsibility         | Security/Privacy     | 33.33        |\n",
      "| Environment and Social Responsibility         | AI Manager           | 31.58        |\n",
      "| Environment and Social Responsibility         | AI developers        | 22.73        |\n",
      "| Environment and Social Responsibility         | AI Researcher        | 15           |\n",
      "| Environment and Social Responsibility         | QA and Maintenance   | 7.69         |\n",
      "| Fairness and Justice                          | Other                | 66.67        |\n",
      "| Fairness and Justice                          | AI Manager           | 43.86        |\n",
      "| Fairness and Justice                          | Requirements analyst | 41.18        |\n",
      "| Fairness and Justice                          | AI Researcher        | 40           |\n",
      "| Fairness and Justice                          | QA and Maintenance   | 38.46        |\n",
      "| Fairness and Justice                          | AI developers        | 34.85        |\n",
      "| Fairness and Justice                          | Security/Privacy     | 25           |\n",
      "| Harm Prevention and Beneficence               | Other                | 66.67        |\n",
      "| Harm Prevention and Beneficence               | AI Manager           | 52.63        |\n",
      "| Harm Prevention and Beneficence               | Requirements analyst | 35.29        |\n",
      "| Harm Prevention and Beneficence               | AI Researcher        | 35           |\n",
      "| Harm Prevention and Beneficence               | AI developers        | 34.85        |\n",
      "| Harm Prevention and Beneficence               | Security/Privacy     | 33.33        |\n",
      "| Harm Prevention and Beneficence               | QA and Maintenance   | 30.77        |\n",
      "| Non-Discrimination and Freedom of Privileges  | AI Manager           | 49.12        |\n",
      "| Non-Discrimination and Freedom of Privileges  | Requirements analyst | 47.06        |\n",
      "| Non-Discrimination and Freedom of Privileges  | AI developers        | 28.79        |\n",
      "| Non-Discrimination and Freedom of Privileges  | AI Researcher        | 25           |\n",
      "| Non-Discrimination and Freedom of Privileges  | Security/Privacy     | 25           |\n",
      "| Non-Discrimination and Freedom of Privileges  | QA and Maintenance   | 15.38        |\n",
      "| None                                          | AI developers        | 0.76         |\n",
      "| Respect for Human Rights                      | AI Manager           | 54.39        |\n",
      "| Respect for Human Rights                      | AI Researcher        | 50           |\n",
      "| Respect for Human Rights                      | Requirements analyst | 47.06        |\n",
      "| Respect for Human Rights                      | QA and Maintenance   | 46.15        |\n",
      "| Respect for Human Rights                      | AI developers        | 43.94        |\n",
      "| Respect for Human Rights                      | Security/Privacy     | 16.67        |\n",
      "| Transparency and Explainability of AI Systems | Security/Privacy     | 58.33        |\n",
      "| Transparency and Explainability of AI Systems | AI Manager           | 52.63        |\n",
      "| Transparency and Explainability of AI Systems | AI Researcher        | 50           |\n",
      "| Transparency and Explainability of AI Systems | AI developers        | 49.24        |\n",
      "| Transparency and Explainability of AI Systems | Other                | 33.33        |\n",
      "| Transparency and Explainability of AI Systems | Requirements analyst | 32.35        |\n",
      "| Transparency and Explainability of AI Systems | QA and Maintenance   | 30.77        |\n",
      "Processing Education...\n",
      "\n",
      "Ranked Results for Education:\n",
      "\n",
      "| Principle                                     | Education          | Percentage   |\n",
      "|:----------------------------------------------|:-------------------|:-------------|\n",
      "| Accountability and Responsibility             | High School Degree | 42.11        |\n",
      "| Accountability and Responsibility             | Graduate Education | 40.98        |\n",
      "| Accountability and Responsibility             | Ph.D.              | 39.13        |\n",
      "| Accountability and Responsibility             | Bachelor's Degree  | 36.84        |\n",
      "| Accountability and Responsibility             | Other              | 25           |\n",
      "| All                                           | Bachelor's Degree  | 27.19        |\n",
      "| All                                           | Other              | 25           |\n",
      "| All                                           | Ph.D.              | 17.39        |\n",
      "| All                                           | High School Degree | 15.79        |\n",
      "| All                                           | Graduate Education | 13.93        |\n",
      "| Data Protection and Right to Privacy          | Graduate Education | 75.41        |\n",
      "| Data Protection and Right to Privacy          | Other              | 75           |\n",
      "| Data Protection and Right to Privacy          | High School Degree | 73.68        |\n",
      "| Data Protection and Right to Privacy          | Ph.D.              | 69.57        |\n",
      "| Data Protection and Right to Privacy          | Bachelor's Degree  | 66.67        |\n",
      "| Democracy and Rule of Law                     | Graduate Education | 27.05        |\n",
      "| Democracy and Rule of Law                     | Bachelor's Degree  | 23.68        |\n",
      "| Democracy and Rule of Law                     | Ph.D.              | 17.39        |\n",
      "| Democracy and Rule of Law                     | High School Degree | 15.79        |\n",
      "| Environment and Social Responsibility         | High School Degree | 31.58        |\n",
      "| Environment and Social Responsibility         | Graduate Education | 27.87        |\n",
      "| Environment and Social Responsibility         | Bachelor's Degree  | 24.56        |\n",
      "| Environment and Social Responsibility         | Ph.D.              | 21.74        |\n",
      "| Fairness and Justice                          | Ph.D.              | 43.48        |\n",
      "| Fairness and Justice                          | Graduate Education | 39.34        |\n",
      "| Fairness and Justice                          | Bachelor's Degree  | 36.84        |\n",
      "| Fairness and Justice                          | High School Degree | 36.84        |\n",
      "| Harm Prevention and Beneficence               | Graduate Education | 43.44        |\n",
      "| Harm Prevention and Beneficence               | Ph.D.              | 39.13        |\n",
      "| Harm Prevention and Beneficence               | Bachelor's Degree  | 35.96        |\n",
      "| Harm Prevention and Beneficence               | High School Degree | 31.58        |\n",
      "| Harm Prevention and Beneficence               | Other              | 25           |\n",
      "| Non-Discrimination and Freedom of Privileges  | Graduate Education | 37.7         |\n",
      "| Non-Discrimination and Freedom of Privileges  | Bachelor's Degree  | 32.46        |\n",
      "| Non-Discrimination and Freedom of Privileges  | High School Degree | 31.58        |\n",
      "| Non-Discrimination and Freedom of Privileges  | Ph.D.              | 17.39        |\n",
      "| None                                          | Graduate Education | 0.82         |\n",
      "| Respect for Human Rights                      | Ph.D.              | 52.17        |\n",
      "| Respect for Human Rights                      | Graduate Education | 46.72        |\n",
      "| Respect for Human Rights                      | Bachelor's Degree  | 46.49        |\n",
      "| Respect for Human Rights                      | Other              | 25           |\n",
      "| Respect for Human Rights                      | High School Degree | 21.05        |\n",
      "| Transparency and Explainability of AI Systems | Graduate Education | 55.74        |\n",
      "| Transparency and Explainability of AI Systems | Other              | 50           |\n",
      "| Transparency and Explainability of AI Systems | Bachelor's Degree  | 43.86        |\n",
      "| Transparency and Explainability of AI Systems | Ph.D.              | 39.13        |\n",
      "| Transparency and Explainability of AI Systems | High School Degree | 31.58        |\n",
      "Processing Dev Experience...\n",
      "\n",
      "Ranked Results for Dev Experience:\n",
      "\n",
      "| Principle                                     | Dev Experience   | Percentage   |\n",
      "|:----------------------------------------------|:-----------------|:-------------|\n",
      "| Accountability and Responsibility             | 2-5 Years        | 41.13        |\n",
      "| Accountability and Responsibility             | 5-10 Years       | 38.71        |\n",
      "| Accountability and Responsibility             | 10+ Years        | 36.73        |\n",
      "| All                                           | 5-10 Years       | 25.81        |\n",
      "| All                                           | 10+ Years        | 20.41        |\n",
      "| All                                           | 2-5 Years        | 17.02        |\n",
      "| Data Protection and Right to Privacy          | 10+ Years        | 75.51        |\n",
      "| Data Protection and Right to Privacy          | 2-5 Years        | 70.92        |\n",
      "| Data Protection and Right to Privacy          | 5-10 Years       | 66.13        |\n",
      "| Democracy and Rule of Law                     | 5-10 Years       | 27.42        |\n",
      "| Democracy and Rule of Law                     | 2-5 Years        | 25.53        |\n",
      "| Democracy and Rule of Law                     | 10+ Years        | 16.33        |\n",
      "| Environment and Social Responsibility         | 10+ Years        | 28.57        |\n",
      "| Environment and Social Responsibility         | 2-5 Years        | 26.24        |\n",
      "| Environment and Social Responsibility         | 5-10 Years       | 24.19        |\n",
      "| Fairness and Justice                          | 5-10 Years       | 40.32        |\n",
      "| Fairness and Justice                          | 2-5 Years        | 37.59        |\n",
      "| Fairness and Justice                          | 10+ Years        | 36.73        |\n",
      "| Harm Prevention and Beneficence               | 2-5 Years        | 43.26        |\n",
      "| Harm Prevention and Beneficence               | 5-10 Years       | 41.94        |\n",
      "| Harm Prevention and Beneficence               | 10+ Years        | 26.53        |\n",
      "| Non-Discrimination and Freedom of Privileges  | 2-5 Years        | 41.84        |\n",
      "| Non-Discrimination and Freedom of Privileges  | 5-10 Years       | 25.81        |\n",
      "| Non-Discrimination and Freedom of Privileges  | 10+ Years        | 24.49        |\n",
      "| None                                          | 5-10 Years       | 1.61         |\n",
      "| Respect for Human Rights                      | 5-10 Years       | 48.39        |\n",
      "| Respect for Human Rights                      | 2-5 Years        | 45.39        |\n",
      "| Respect for Human Rights                      | 10+ Years        | 38.78        |\n",
      "| Transparency and Explainability of AI Systems | 10+ Years        | 51.02        |\n",
      "| Transparency and Explainability of AI Systems | 2-5 Years        | 46.1         |\n",
      "| Transparency and Explainability of AI Systems | 5-10 Years       | 45.16        |\n",
      "Processing Gender...\n",
      "\n",
      "Ranked Results for Gender:\n",
      "\n",
      "| Principle                                     | Gender                    | Percentage   |\n",
      "|:----------------------------------------------|:--------------------------|:-------------|\n",
      "| Accountability and Responsibility             | Non-binary / Third gender | 100          |\n",
      "| Accountability and Responsibility             | Female                    | 41.67        |\n",
      "| Accountability and Responsibility             | Male                      | 37.19        |\n",
      "| All                                           | Female                    | 23.81        |\n",
      "| All                                           | Male                      | 18.09        |\n",
      "| Data Protection and Right to Privacy          | Non-binary / Third gender | 100          |\n",
      "| Data Protection and Right to Privacy          | Male                      | 73.87        |\n",
      "| Data Protection and Right to Privacy          | Female                    | 66.67        |\n",
      "| Democracy and Rule of Law                     | Female                    | 25           |\n",
      "| Democracy and Rule of Law                     | Male                      | 23.12        |\n",
      "| Environment and Social Responsibility         | Female                    | 26.19        |\n",
      "| Environment and Social Responsibility         | Male                      | 25.63        |\n",
      "| Fairness and Justice                          | Female                    | 42.86        |\n",
      "| Fairness and Justice                          | Male                      | 35.68        |\n",
      "| Harm Prevention and Beneficence               | Female                    | 46.43        |\n",
      "| Harm Prevention and Beneficence               | Male                      | 35.68        |\n",
      "| Non-Discrimination and Freedom of Privileges  | Female                    | 44.05        |\n",
      "| Non-Discrimination and Freedom of Privileges  | Male                      | 28.64        |\n",
      "| None                                          | Female                    | 1.19         |\n",
      "| Respect for Human Rights                      | Non-binary / Third gender | 100          |\n",
      "| Respect for Human Rights                      | Male                      | 44.72        |\n",
      "| Respect for Human Rights                      | Female                    | 44.05        |\n",
      "| Transparency and Explainability of AI Systems | Female                    | 51.19        |\n",
      "| Transparency and Explainability of AI Systems | Male                      | 45.73        |\n",
      "Processing Company Size...\n",
      "\n",
      "Ranked Results for Company Size:\n",
      "\n",
      "| Principle                                     | Company Size     | Percentage   |\n",
      "|:----------------------------------------------|:-----------------|:-------------|\n",
      "| Accountability and Responsibility             | 100+ Employees   | 42.64        |\n",
      "| Accountability and Responsibility             | 51-100 Employees | 41.86        |\n",
      "| Accountability and Responsibility             | 6-20 Employees   | 37.5         |\n",
      "| Accountability and Responsibility             | 21-50 Employees  | 30.61        |\n",
      "| Accountability and Responsibility             | 1-5 Employees    | 23.81        |\n",
      "| All                                           | 100+ Employees   | 27.91        |\n",
      "| All                                           | 6-20 Employees   | 17.5         |\n",
      "| All                                           | 21-50 Employees  | 14.29        |\n",
      "| All                                           | 51-100 Employees | 11.63        |\n",
      "| All                                           | 1-5 Employees    | 4.76         |\n",
      "| Data Protection and Right to Privacy          | 51-100 Employees | 79.07        |\n",
      "| Data Protection and Right to Privacy          | 100+ Employees   | 73.64        |\n",
      "| Data Protection and Right to Privacy          | 6-20 Employees   | 72.5         |\n",
      "| Data Protection and Right to Privacy          | 1-5 Employees    | 71.43        |\n",
      "| Data Protection and Right to Privacy          | 21-50 Employees  | 59.18        |\n",
      "| Democracy and Rule of Law                     | 21-50 Employees  | 32.65        |\n",
      "| Democracy and Rule of Law                     | 6-20 Employees   | 27.5         |\n",
      "| Democracy and Rule of Law                     | 100+ Employees   | 22.48        |\n",
      "| Democracy and Rule of Law                     | 51-100 Employees | 20.93        |\n",
      "| Democracy and Rule of Law                     | 1-5 Employees    | 9.52         |\n",
      "| Environment and Social Responsibility         | 51-100 Employees | 30.23        |\n",
      "| Environment and Social Responsibility         | 100+ Employees   | 29.46        |\n",
      "| Environment and Social Responsibility         | 21-50 Employees  | 22.45        |\n",
      "| Environment and Social Responsibility         | 1-5 Employees    | 19.05        |\n",
      "| Environment and Social Responsibility         | 6-20 Employees   | 15           |\n",
      "| Fairness and Justice                          | 51-100 Employees | 41.86        |\n",
      "| Fairness and Justice                          | 1-5 Employees    | 38.1         |\n",
      "| Fairness and Justice                          | 6-20 Employees   | 37.5         |\n",
      "| Fairness and Justice                          | 21-50 Employees  | 36.73        |\n",
      "| Fairness and Justice                          | 100+ Employees   | 36.43        |\n",
      "| Harm Prevention and Beneficence               | 51-100 Employees | 48.84        |\n",
      "| Harm Prevention and Beneficence               | 100+ Employees   | 37.98        |\n",
      "| Harm Prevention and Beneficence               | 6-20 Employees   | 37.5         |\n",
      "| Harm Prevention and Beneficence               | 21-50 Employees  | 34.69        |\n",
      "| Harm Prevention and Beneficence               | 1-5 Employees    | 33.33        |\n",
      "| Non-Discrimination and Freedom of Privileges  | 21-50 Employees  | 40.82        |\n",
      "| Non-Discrimination and Freedom of Privileges  | 6-20 Employees   | 37.5         |\n",
      "| Non-Discrimination and Freedom of Privileges  | 1-5 Employees    | 33.33        |\n",
      "| Non-Discrimination and Freedom of Privileges  | 100+ Employees   | 30.23        |\n",
      "| Non-Discrimination and Freedom of Privileges  | 51-100 Employees | 30.23        |\n",
      "| None                                          | 100+ Employees   | 0.78         |\n",
      "| Respect for Human Rights                      | 6-20 Employees   | 55           |\n",
      "| Respect for Human Rights                      | 51-100 Employees | 46.51        |\n",
      "| Respect for Human Rights                      | 21-50 Employees  | 44.9         |\n",
      "| Respect for Human Rights                      | 100+ Employees   | 43.41        |\n",
      "| Respect for Human Rights                      | 1-5 Employees    | 33.33        |\n",
      "| Transparency and Explainability of AI Systems | 51-100 Employees | 60.47        |\n",
      "| Transparency and Explainability of AI Systems | 100+ Employees   | 48.84        |\n",
      "| Transparency and Explainability of AI Systems | 1-5 Employees    | 42.86        |\n",
      "| Transparency and Explainability of AI Systems | 21-50 Employees  | 42.86        |\n",
      "| Transparency and Explainability of AI Systems | 6-20 Employees   | 37.5         |\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Define file path\n",
    "file_path = 'AI_Study_Accepted_with_replacement_codes.csv'\n",
    "\n",
    "# Demographic columns and their mappings (using column numbers)\n",
    "demographics = {\n",
    "    'Location': {\n",
    "        'column': 28,  # Column number for Location\n",
    "        'mapping': {\n",
    "            'North America': 'US',\n",
    "            'Central/South America': 'Other',\n",
    "            'EU/UK/EEA': 'Europe',\n",
    "            'Europe - Outside of EU/UK/EEA': 'Europe',\n",
    "            'Africa': 'Other',\n",
    "            'Middle East': 'Other',\n",
    "            'Asia': 'Other',\n",
    "            'Australia and Oceania': 'Other',\n",
    "            'Prefer not to say': 'Other',\n",
    "            'Other, please specify': 'Other'\n",
    "        }\n",
    "    },\n",
    "    'Company Type': {\n",
    "        'column': 26,  # Column number for Company Type\n",
    "        'mapping': {\n",
    "            'Multi-national Corporate': 'Multi-national',\n",
    "            'Startup/Small Business': 'Startup/Small',\n",
    "            'Academic Institution/Research Center': 'Academic/Research',\n",
    "            'Government': 'Government',\n",
    "            'Individual': 'Other',\n",
    "            'Other, please specify': 'Other'\n",
    "        }\n",
    "    },\n",
    "    'Role': {\n",
    "        'column': 30,  # Column number for Role\n",
    "        'mapping': {\n",
    "            'Administrative role (CEO, Chief Technical Officer, Chief Operating Officer, Chief Information Officer)': 'AI Manager',\n",
    "            'AI Manager': 'AI Manager',\n",
    "            'Requirements Analyst or Engineer': 'Requirements analyst',\n",
    "            'Scrum Master, Product Manager, or Project Manager': 'Requirements analyst',\n",
    "            'AI Engineer or Developer': 'AI developers',\n",
    "            '(Software) Developer, Designer, or Architect': 'AI developers',\n",
    "            'Data Scientist or Data Analyst': 'AI developers',\n",
    "            'Information Security Analyst or Engineer': 'Security/Privacy',\n",
    "            'Information Privacy Analyst or Engineer': 'Security/Privacy',\n",
    "            'AI Ethicist': 'Other',\n",
    "            'AI Researcher': 'AI Researcher',\n",
    "            '(Software) Quality Assurance Engineer or Tester': 'QA and Maintenance',\n",
    "            'Other, please specify': 'Other'\n",
    "        }\n",
    "    },\n",
    "    'Education': {\n",
    "        'column': 21,  # Column number for Education\n",
    "        'mapping': {\n",
    "            \"High School Degree\": \"High School Degree\",\n",
    "            \"Bachelor's Degree\": \"Bachelor's Degree\",\n",
    "            \"Master's Degree (i.e., MSc., M.A., etc.)\": \"Graduate Education\",\n",
    "            \"MBA (Master of Business Administration)\": \"Graduate Education\",\n",
    "            \"Graduate Certificates\": \"Graduate Education\",\n",
    "            \"Ph.D.\": \"Ph.D.\",\n",
    "            \"Other, please specify\": \"Other\"\n",
    "        }\n",
    "    },\n",
    "    'Dev Experience': {\n",
    "        'column': 32,  # Column number for Dev Experience\n",
    "        'mapping': {\n",
    "            'None': 'None',\n",
    "            '1-2 Years': '1-2 Years',\n",
    "            '2-5 Years': '2-5 Years',\n",
    "            '5-10 Years': '5-10 Years',\n",
    "            '10+ Years': '10+ Years'\n",
    "        }\n",
    "    },\n",
    "    'Gender': {\n",
    "        'column': 19,  # Column number for Gender\n",
    "        'mapping': {  # No predefined mapping for gender; use unique values directly\n",
    "            'Male': 'Male',\n",
    "            'Female': 'Female',\n",
    "            'Non-binary / Third gender': 'Non-binary / Third gender',\n",
    "            'Prefer not to say': 'Prefer not to say',\n",
    "            'Other, please specify': 'Other'\n",
    "        }\n",
    "    },\n",
    "    'Company Size': {\n",
    "        'column': 25,  # Column number for Company Size\n",
    "        'mapping': {\n",
    "            '1-5 Employees': '1-5 Employees',\n",
    "            '6-20 Employees': '6-20 Employees',\n",
    "            '21-50 Employees': '21-50 Employees',\n",
    "            '51-100 Employees': '51-100 Employees',\n",
    "            '101+ Employees': '100+ Employees'\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "def read_and_clean_csv(file_path):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, encoding='utf-8')\n",
    "        print(f\"Successfully read {file_path}.\")\n",
    "        return df\n",
    "    except UnicodeDecodeError:\n",
    "        print(f\"Failed to read {file_path} with utf-8 encoding.\")\n",
    "        return None\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        return None\n",
    "\n",
    "def process_data(df, demographic):\n",
    "    try:\n",
    "        if demographics[demographic]['mapping']:\n",
    "            categories = set(demographics[demographic]['mapping'].values())\n",
    "            df['GroupedCategory'] = df.iloc[:, demographics[demographic]['column']].map(demographics[demographic]['mapping'])\n",
    "        else:\n",
    "            categories = df.iloc[:, demographics[demographic]['column']].dropna().unique()\n",
    "            df['GroupedCategory'] = df.iloc[:, demographics[demographic]['column']]\n",
    "\n",
    "        all_results = {}\n",
    "\n",
    "        for category in categories:\n",
    "            df_category = df[df['GroupedCategory'] == category]\n",
    "\n",
    "            # Step 2: Exclude the first two rows\n",
    "            df_category = df_category.iloc[2:]\n",
    "\n",
    "            # Step 3: Remove NaNs or empty values in 'B.2.2'\n",
    "            df_category = df_category[df_category['B.2.2'].notna()]  # Remove NaNs\n",
    "            df_category['B.2.2'] = df_category['B.2.2'].astype(str).apply(lambda x: x.strip())\n",
    "            df_category = df_category[df_category['B.2.2'] != \"\"]  # Remove empty strings\n",
    "\n",
    "            # Step 4: Process the responses\n",
    "            df_category['B.2.2'] = df_category['B.2.2'].apply(lambda x: [item.strip() for item in x.split(',')])\n",
    "\n",
    "            # Step 5: Flatten the list of responses and count occurrences\n",
    "            all_responses = df_category['B.2.2'].explode().value_counts().reset_index()\n",
    "            all_responses.columns = ['Principle', 'Count']\n",
    "\n",
    "            # Step 6: Calculate total number of valid responses (rows with non-empty lists)\n",
    "            total_valid_responses = df_category[df_category['B.2.2'].apply(len) > 0].shape[0]\n",
    "\n",
    "            # Step 7: Calculate the percentage of rows that mention each principle\n",
    "            all_responses['Percentage'] = (all_responses['Count'] / total_valid_responses * 100).round(2)\n",
    "\n",
    "            all_results[category] = all_responses\n",
    "\n",
    "        # Combine and rank results\n",
    "        combined_results = pd.concat(all_results, names=[demographic, 'Category'])\n",
    "        combined_results = combined_results.reset_index()\n",
    "\n",
    "        ranked_results = combined_results.groupby(['Principle', demographic])['Percentage'].mean().reset_index()\n",
    "        ranked_results = ranked_results.sort_values(by=['Principle', 'Percentage'], ascending=[True, False])\n",
    "\n",
    "        return ranked_results\n",
    "    except KeyError as e:\n",
    "        print(f\"Error: Column '{e}' not found in the DataFrame. Check your demographics dictionary and CSV file.\")\n",
    "        return pd.DataFrame()  # Return an empty DataFrame to avoid further errors\n",
    "\n",
    "# Main execution\n",
    "df = read_and_clean_csv(file_path)\n",
    "if df is not None:\n",
    "    print(df.columns)  # Print the columns for debugging\n",
    "    for demographic in demographics:\n",
    "        print(f\"Processing {demographic}...\")\n",
    "        ranked_results = process_data(df, demographic)  # Call the updated function name\n",
    "\n",
    "        # Print the ranked results\n",
    "        print(f\"\\nRanked Results for {demographic}:\\n\")\n",
    "        print(ranked_results.to_markdown(index=False, numalign=\"left\", stralign=\"left\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read AI_Study_Accepted_with_replacement_codes.csv.\n",
      "Index(['Remove? (Yes/No/Maybe)', 'StartDate', 'EndDate', 'Finished',\n",
      "       'RecordedDate', 'Unnamed: 5', 'ResponseId', 'UserLanguage',\n",
      "       'Q_RecaptchaScore', 'Q_RelevantIDDuplicate',\n",
      "       ...\n",
      "       'C.1 _5', 'C.1 _6', 'C.1 _7', 'C.1 _8', 'C.2', 'C.3.a', 'C.3_1_TEXT',\n",
      "       'C.3_2_TEXT', 'C.3_3_TEXT', 'PROLIFIC_PID'],\n",
      "      dtype='object', length=234)\n",
      "Processing Location...\n",
      "\n",
      "Ranked Results for Location:\n",
      "\n",
      "| Location   | Percentage   |\n",
      "|:-----------|:-------------|\n",
      "| Other      | 89.55        |\n",
      "| US         | 89.19        |\n",
      "| Europe     | 79.75        |\n",
      "Processing Company Type...\n",
      "\n",
      "Ranked Results for Company Type:\n",
      "\n",
      "| Company Type      | Percentage   |\n",
      "|:------------------|:-------------|\n",
      "| Government        | 95.65        |\n",
      "| Academic/Research | 90.62        |\n",
      "| Multi-national    | 86.28        |\n",
      "| Startup/Small     | 84.54        |\n",
      "| Other             | 82.86        |\n",
      "Processing Role...\n",
      "\n",
      "Ranked Results for Role:\n",
      "\n",
      "| Role                 | Percentage   |\n",
      "|:---------------------|:-------------|\n",
      "| QA and Maintenance   | 92.31        |\n",
      "| Security/Privacy     | 91.67        |\n",
      "| AI Manager           | 91.53        |\n",
      "| AI Researcher        | 90           |\n",
      "| AI developers        | 85.41        |\n",
      "| Requirements analyst | 75           |\n",
      "| Other                | 66.66        |\n",
      "Processing Education...\n",
      "\n",
      "Ranked Results for Education:\n",
      "\n",
      "| Education          | Percentage   |\n",
      "|:-------------------|:-------------|\n",
      "| Bachelor's Degree  | 89.83        |\n",
      "| Ph.D.              | 87.49        |\n",
      "| Graduate Education | 86.4         |\n",
      "| High School Degree | 77.27        |\n",
      "| Other              | 75           |\n",
      "Processing Dev Experience...\n",
      "\n",
      "Ranked Results for Dev Experience:\n",
      "\n",
      "| Dev Experience   | Percentage   |\n",
      "|:-----------------|:-------------|\n",
      "| 2-5 Years        | 88.89        |\n",
      "| 5-10 Years       | 87.87        |\n",
      "| 10+ Years        | 76.46        |\n",
      "| 1-2 Years        | 0            |\n",
      "| None             | 0            |\n",
      "Processing Gender...\n",
      "\n",
      "Ranked Results for Gender:\n",
      "\n",
      "| Gender                    | Percentage   |\n",
      "|:--------------------------|:-------------|\n",
      "| Non-binary / Third gender | 100          |\n",
      "| Female                    | 96.47        |\n",
      "| Male                      | 83.73        |\n",
      "| Other                     | 0            |\n",
      "| Prefer not to say         | 0            |\n",
      "Processing Company Size...\n",
      "\n",
      "Ranked Results for Company Size:\n",
      "\n",
      "| Company Size     | Percentage   |\n",
      "|:-----------------|:-------------|\n",
      "| 51-100 Employees | 97.73        |\n",
      "| 6-20 Employees   | 90           |\n",
      "| 100+ Employees   | 86.57        |\n",
      "| 21-50 Employees  | 80.77        |\n",
      "| 1-5 Employees    | 72.72        |\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define file path\n",
    "file_path = 'AI_Study_Accepted_with_replacement_codes.csv'\n",
    "\n",
    "# Demographic columns and their mappings (using column numbers)\n",
    "demographics = {\n",
    "    'Location': {\n",
    "        'column': 28,  # Column number for Location\n",
    "        'mapping': {\n",
    "            'North America': 'US',\n",
    "            'Central/South America': 'Other',\n",
    "            'EU/UK/EEA': 'Europe',\n",
    "            'Europe - Outside of EU/UK/EEA': 'Europe',\n",
    "            'Africa': 'Other',\n",
    "            'Middle East': 'Other',\n",
    "            'Asia': 'Other',\n",
    "            'Australia and Oceania': 'Other',\n",
    "            'Prefer not to say': 'Other',\n",
    "            'Other, please specify': 'Other'\n",
    "        }\n",
    "    },\n",
    "    'Company Type': {\n",
    "        'column': 26,  # Column number for Company Type\n",
    "        'mapping': {\n",
    "            'Multi-national Corporate': 'Multi-national',\n",
    "            'Startup/Small Business': 'Startup/Small',\n",
    "            'Academic Institution/Research Center': 'Academic/Research',\n",
    "            'Government': 'Government',\n",
    "            'Individual': 'Other',\n",
    "            'Other, please specify': 'Other'\n",
    "        }\n",
    "    },\n",
    "    'Role': {\n",
    "        'column': 30,  # Column number for Role\n",
    "        'mapping': {\n",
    "            'Administrative role (CEO, Chief Technical Officer, Chief Operating Officer, Chief Information Officer)': 'AI Manager',\n",
    "            'AI Manager': 'AI Manager',\n",
    "            'Requirements Analyst or Engineer': 'Requirements analyst',\n",
    "            'Scrum Master, Product Manager, or Project Manager': 'Requirements analyst',\n",
    "            'AI Engineer or Developer': 'AI developers',\n",
    "            '(Software) Developer, Designer, or Architect': 'AI developers',\n",
    "            'Data Scientist or Data Analyst': 'AI developers',\n",
    "            'Information Security Analyst or Engineer': 'Security/Privacy',\n",
    "            'Information Privacy Analyst or Engineer': 'Security/Privacy',\n",
    "            'AI Ethicist': 'Other',\n",
    "            'AI Researcher': 'AI Researcher',\n",
    "            '(Software) Quality Assurance Engineer or Tester': 'QA and Maintenance',\n",
    "            'Other, please specify': 'Other'\n",
    "        }\n",
    "    },\n",
    "    'Education': {\n",
    "        'column': 21,  # Column number for Education\n",
    "        'mapping': {\n",
    "            \"High School Degree\": \"High School Degree\",\n",
    "            \"Bachelor's Degree\": \"Bachelor's Degree\",\n",
    "            \"Master's Degree (i.e., MSc., M.A., etc.)\": \"Graduate Education\",\n",
    "            \"MBA (Master of Business Administration)\": \"Graduate Education\",\n",
    "            \"Graduate Certificates\": \"Graduate Education\",\n",
    "            \"Ph.D.\": \"Ph.D.\",\n",
    "            \"Other, please specify\": \"Other\"\n",
    "        }\n",
    "    },\n",
    "    'Dev Experience': {\n",
    "        'column': 32,  # Column number for Dev Experience\n",
    "        'mapping': {\n",
    "            'None': 'None',\n",
    "            '1-2 Years': '1-2 Years',\n",
    "            '2-5 Years': '2-5 Years',\n",
    "            '5-10 Years': '5-10 Years',\n",
    "            '10+ Years': '10+ Years'\n",
    "        }\n",
    "    },\n",
    "    'Gender': {\n",
    "        'column': 19,  # Column number for Gender\n",
    "        'mapping': {  # No predefined mapping for gender; use unique values directly\n",
    "            'Male': 'Male',\n",
    "            'Female': 'Female',\n",
    "            'Non-binary / Third gender': 'Non-binary / Third gender',\n",
    "            'Prefer not to say': 'Prefer not to say',\n",
    "            'Other, please specify': 'Other'\n",
    "        }\n",
    "    },\n",
    "    'Company Size': {\n",
    "        'column': 25,  # Column number for Company Size\n",
    "        'mapping': {\n",
    "            '1-5 Employees': '1-5 Employees',\n",
    "            '6-20 Employees': '6-20 Employees',\n",
    "            '21-50 Employees': '21-50 Employees',\n",
    "            '51-100 Employees': '51-100 Employees',\n",
    "            '101+ Employees': '100+ Employees'\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "def read_and_clean_csv(file_path):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, encoding='utf-8')\n",
    "        print(f\"Successfully read {file_path}.\")\n",
    "        return df\n",
    "    except UnicodeDecodeError:\n",
    "        print(f\"Failed to read {file_path} with utf-8 encoding.\")\n",
    "        return None\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        return None\n",
    "\n",
    "def process_data(df, demographic):\n",
    "    try:\n",
    "        if demographics[demographic]['mapping']:\n",
    "            categories = set(demographics[demographic]['mapping'].values())\n",
    "            df['GroupedCategory'] = df.iloc[:, demographics[demographic]['column']].map(demographics[demographic]['mapping'])\n",
    "        else:\n",
    "            categories = df.iloc[:, demographics[demographic]['column']].dropna().unique()\n",
    "            df['GroupedCategory'] = df.iloc[:, demographics[demographic]['column']]\n",
    "\n",
    "        all_results = {}\n",
    "\n",
    "        for category in categories:\n",
    "            df_category = df[df['GroupedCategory'] == category]\n",
    "\n",
    "            # Step 2: Exclude the first two rows\n",
    "            df_category = df_category.iloc[2:]\n",
    "\n",
    "            # Step 3: Remove NaNs or empty values in 'B.2.3'\n",
    "            df_category = df_category[df_category['B.2.3'].notna()]  # Remove NaNs\n",
    "            df_category['B.2.3'] = df_category['B.2.3'].astype(str).apply(lambda x: x.strip())\n",
    "            df_category = df_category[df_category['B.2.3'] != \"\"]  # Remove empty strings\n",
    "\n",
    "            # Step 4: Count occurrences of each response\n",
    "            response_counts = df_category['B.2.3'].value_counts().reset_index()\n",
    "            response_counts.columns = ['Response', 'Count']\n",
    "\n",
    "            # Step 5: Calculate total number of valid responses\n",
    "            total_valid_responses = df_category.shape[0]\n",
    "\n",
    "            # Step 6: Calculate the percentage of each option based on valid responses\n",
    "            response_counts['Percentage'] = (response_counts['Count'] / total_valid_responses * 100).round(2)\n",
    "\n",
    "            # --- Calculate percentage considering \"at least sometimes\" ---\n",
    "            at_least_sometimes_percentage = response_counts[response_counts['Response'].isin(['Sometimes', 'Often', 'Always'])][\n",
    "                'Percentage'\n",
    "            ].sum()\n",
    "\n",
    "            all_results[category] = pd.DataFrame({'Response': ['At Least Sometimes'], 'Percentage': [at_least_sometimes_percentage]})\n",
    "\n",
    "        # Combine and rank results\n",
    "        combined_results = pd.concat(all_results, names=[demographic, 'Category'])\n",
    "        combined_results = combined_results.reset_index()\n",
    "\n",
    "        ranked_results = combined_results.groupby([demographic])['Percentage'].mean().reset_index()\n",
    "\n",
    "        # Sort by average percentage in descending order\n",
    "        ranked_results = ranked_results.sort_values(by=['Percentage'], ascending=[False])\n",
    "\n",
    "        return ranked_results\n",
    "    except KeyError as e:\n",
    "        print(f\"Error: Column '{e}' not found in the DataFrame. Check your demographics dictionary and CSV file.\")\n",
    "        return pd.DataFrame()  # Return an empty DataFrame to avoid further errors\n",
    "\n",
    "# Main execution\n",
    "df = read_and_clean_csv(file_path)\n",
    "if df is not None:\n",
    "    print(df.columns)  # Print the columns for debugging\n",
    "    for demographic in demographics:\n",
    "        print(f\"Processing {demographic}...\")\n",
    "        ranked_results = process_data(df, demographic)\n",
    "\n",
    "        # Print the ranked results\n",
    "        print(f\"\\nRanked Results for {demographic}:\\n\")\n",
    "        print(ranked_results.to_markdown(index=False, numalign=\"left\", stralign=\"left\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read AI_Study_Accepted_with_replacement_codes.csv.\n",
      "Index(['Remove? (Yes/No/Maybe)', 'StartDate', 'EndDate', 'Finished',\n",
      "       'RecordedDate', 'Unnamed: 5', 'ResponseId', 'UserLanguage',\n",
      "       'Q_RecaptchaScore', 'Q_RelevantIDDuplicate',\n",
      "       ...\n",
      "       'C.1 _5', 'C.1 _6', 'C.1 _7', 'C.1 _8', 'C.2', 'C.3.a', 'C.3_1_TEXT',\n",
      "       'C.3_2_TEXT', 'C.3_3_TEXT', 'PROLIFIC_PID'],\n",
      "      dtype='object', length=234)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Define file path\n",
    "file_path = 'AI_Study_Accepted_with_replacement_codes.csv'\n",
    "\n",
    "# Create a folder named 'graphs/b.2.4' if it doesn't exist\n",
    "if not os.path.exists('graphs/b.2.4'):\n",
    "    os.makedirs('graphs/b.2.4')\n",
    "\n",
    "# Demographic columns and their mappings (using column numbers)\n",
    "demographics = {\n",
    "    'Location': {\n",
    "        'column': 28,  # Column number for Location\n",
    "        'mapping': {\n",
    "            'North America': 'US',\n",
    "            'Central/South America': 'Other',\n",
    "            'EU/UK/EEA': 'Europe',\n",
    "            'Europe - Outside of EU/UK/EEA': 'Europe',\n",
    "            'Africa': 'Other',\n",
    "            'Middle East': 'Other',\n",
    "            'Asia': 'Other',\n",
    "            'Australia and Oceania': 'Other',\n",
    "            'Prefer not to say': 'Other',\n",
    "            'Other, please specify': 'Other'\n",
    "        }\n",
    "    },\n",
    "    'Company Type': {\n",
    "        'column': 26,  # Column number for Company Type\n",
    "        'mapping': {\n",
    "            'Multi-national Corporate': 'Multi-national',\n",
    "            'Startup/Small Business': 'Startup/Small',\n",
    "            'Academic Institution/Research Center': 'Academic/Research',\n",
    "            'Government': 'Government',\n",
    "            'Individual': 'Other',\n",
    "            'Other, please specify': 'Other'\n",
    "        }\n",
    "    },\n",
    "    'Role': {\n",
    "        'column': 30,  # Column number for Role\n",
    "        'mapping': {\n",
    "            'Administrative role (CEO, Chief Technical Officer, Chief Operating Officer, Chief Information Officer)': 'AI Manager',\n",
    "            'AI Manager': 'AI Manager',\n",
    "            'Requirements Analyst or Engineer': 'Requirements analyst',\n",
    "            'Scrum Master, Product Manager, or Project Manager': 'Requirements analyst',\n",
    "            'AI Engineer or Developer': 'AI developers',\n",
    "            '(Software) Developer, Designer, or Architect': 'AI developers',\n",
    "            'Data Scientist or Data Analyst': 'AI developers',\n",
    "            'Information Security Analyst or Engineer': 'Security/Privacy',\n",
    "            'Information Privacy Analyst or Engineer': 'Security/Privacy',\n",
    "            'AI Ethicist': 'Other',\n",
    "            'AI Researcher': 'AI Researcher',\n",
    "            '(Software) Quality Assurance Engineer or Tester': 'QA and Maintenance',\n",
    "            'Other, please specify': 'Other'\n",
    "        }\n",
    "    },\n",
    "    'Education': {\n",
    "        'column': 21,  # Column number for Education\n",
    "        'mapping': {\n",
    "            \"High School Degree\": \"High School Degree\",\n",
    "            \"Bachelor's Degree\": \"Bachelor's Degree\",\n",
    "            \"Master's Degree (i.e., MSc., M.A., etc.)\": \"Graduate Education\",\n",
    "            \"MBA (Master of Business Administration)\": \"Graduate Education\",\n",
    "            \"Graduate Certificates\": \"Graduate Education\",\n",
    "            \"Ph.D.\": \"Ph.D.\",\n",
    "            \"Other, please specify\": \"Other\"\n",
    "        }\n",
    "    },\n",
    "    'Dev Experience': {\n",
    "        'column': 32,  # Column number for Dev Experience\n",
    "        'mapping': {\n",
    "            'None': 'None',\n",
    "            '1-2 Years': '1-2 Years',\n",
    "            '2-5 Years': '2-5 Years',\n",
    "            '5-10 Years': '5-10 Years',\n",
    "            '10+ Years': '10+ Years'\n",
    "        }\n",
    "    },\n",
    "    'Gender': {\n",
    "        'column': 19,  # Column number for Gender\n",
    "        'mapping': {  # No predefined mapping for gender; use unique values directly\n",
    "            'Male': 'Male',\n",
    "            'Female': 'Female',\n",
    "            'Non-binary / Third gender': 'Non-binary / Third gender',\n",
    "            'Prefer not to say': 'Prefer not to say',\n",
    "            'Other, please specify': 'Other'\n",
    "        }\n",
    "    },\n",
    "    'Company Size': {\n",
    "        'column': 25,  # Column number for Company Size\n",
    "        'mapping': {\n",
    "            '1-5 Employees': '1-5 Employees',\n",
    "            '6-20 Employees': '6-20 Employees',\n",
    "            '21-50 Employees': '21-50 Employees',\n",
    "            '51-100 Employees': '51-100 Employees',\n",
    "            '101+ Employees': '100+ Employees'\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "def read_and_clean_csv(file_path):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, encoding='utf-8')\n",
    "        print(f\"Successfully read {file_path}.\")\n",
    "        return df\n",
    "    except UnicodeDecodeError:\n",
    "        print(f\"Failed to read {file_path} with utf-8 encoding.\")\n",
    "        return None\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        return None\n",
    "\n",
    "def process_data(df):\n",
    "    # Step 2: Exclude the first two rows\n",
    "    df = df.iloc[2:]\n",
    "\n",
    "    # Step 3: Remove NaNs or empty values in 'B.2.4'\n",
    "    df = df[df['B.2.4'].notna()]  # Remove NaNs\n",
    "    df['B.2.4'] = df['B.2.4'].astype(str).apply(lambda x: x.strip())\n",
    "    df = df[df['B.2.4'] != \"\"]  # Remove empty strings\n",
    "\n",
    "    # Step 4: Process the responses\n",
    "    df['B.2.4'] = df['B.2.4'].apply(lambda x: [item.strip() for item in x.split(',')])\n",
    "\n",
    "    # Step 5: Flatten the list of responses and count occurrences\n",
    "    all_responses = df['B.2.4'].explode().value_counts().reset_index()\n",
    "    all_responses.columns = ['Principle', 'Count']\n",
    "\n",
    "    # Step 6: Calculate total number of valid responses (rows with non-empty lists)\n",
    "    total_valid_responses = df[df['B.2.4'].apply(len) > 0].shape[0]\n",
    "\n",
    "    # Step 7: Calculate the percentage of rows that mention each principle\n",
    "    all_responses['Percentage'] = (all_responses['Count'] / total_valid_responses * 100).round(2)\n",
    "\n",
    "    # --- Rank demographics by principle ---\n",
    "\n",
    "    all_results = {}\n",
    "    for demographic in demographics:\n",
    "        if demographics[demographic]['mapping']:\n",
    "            categories = set(demographics[demographic]['mapping'].values())\n",
    "            df['GroupedCategory'] = df.iloc[:, demographics[demographic]['column']].map(demographics[demographic]['mapping'])\n",
    "        else:\n",
    "            categories = df.iloc[:, demographics[demographic]['column']].dropna().unique()\n",
    "            df['GroupedCategory'] = df.iloc[:, demographics[demographic]['column']]\n",
    "\n",
    "        demographic_results = {}\n",
    "        for category in categories:\n",
    "            df_category = df[df['GroupedCategory'] == category]\n",
    "            category_responses = df_category['B.2.4'].explode().value_counts().reset_index()\n",
    "            category_responses.columns = ['Principle', 'Count']\n",
    "            category_responses['Percentage'] = (category_responses['Count'] / len(df_category) * 100).round(2)\n",
    "            demographic_results[category] = category_responses\n",
    "\n",
    "        combined_results = pd.concat(demographic_results, names=[demographic, 'Category'])\n",
    "        combined_results = combined_results.reset_index()\n",
    "\n",
    "        ranked_results = combined_results.groupby(['Principle', demographic])['Percentage'].mean().reset_index()\n",
    "        ranked_results = ranked_results.sort_values(by=['Principle', 'Percentage'], ascending=[True, False])\n",
    "\n",
    "        all_results[demographic] = ranked_results\n",
    "\n",
    "    return all_results\n",
    "\n",
    "# Main execution\n",
    "df = read_and_clean_csv(file_path)\n",
    "if df is not None:\n",
    "    print(df.columns)  # Print the columns for debugging\n",
    "    all_ranked_results = process_data(df)\n",
    "\n",
    "    # Determine the maximum number of unique demographic options across all demographics\n",
    "    max_demographic_options = max([len(result[demographic].unique()) for demographic, result in all_ranked_results.items()])\n",
    "\n",
    "    # Create a color scale with more saturated blues and yellows\n",
    "    blue_colors = px.colors.sequential.Blues[2:]  # Start from a darker blue\n",
    "    yellow_colors = px.colors.sequential.YlOrRd[1:]  # Start from a darker yellow\n",
    "    color_scale = blue_colors[:max_demographic_options//2] + yellow_colors[max_demographic_options//2:]\n",
    "\n",
    "    for demographic, ranked_results in all_ranked_results.items():\n",
    "        # --- Create graph for each demographic ---\n",
    "        fig = px.bar(\n",
    "            ranked_results,\n",
    "            x='Principle',  # Principles on the x-axis\n",
    "            y='Percentage',\n",
    "            color=demographic,  # Demographic options as colors\n",
    "            title=f'AI Ethics Principles at Risk by {demographic}',\n",
    "            labels={'Percentage': 'Average Percentage of Mentions', 'Principle': 'Principle'},\n",
    "            color_discrete_sequence=color_scale,  # Use the generated color scale\n",
    "            barmode='group'  # Grouped bar chart\n",
    "        )\n",
    "\n",
    "        fig.update_layout(\n",
    "            xaxis_tickangle=45,\n",
    "            xaxis_title='Principle',  # X-axis label\n",
    "            yaxis_title='Average Percentage of Mentions',\n",
    "            title={\n",
    "                'y': 0.95,\n",
    "                'x': 0.5,\n",
    "                'xanchor': 'center',\n",
    "                'yanchor': 'top'\n",
    "            },\n",
    "            font=dict(size=12),\n",
    "            margin=dict(t=150),\n",
    "            yaxis_range=[0, 100]  # Set y-axis range to 0-100\n",
    "        )\n",
    "\n",
    "        # Show the figure in browser\n",
    "        fig.show(renderer=\"browser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# B.2.5\n",
    "####################\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Step 1: Read CSV file into a DataFrame\n",
    "df = pd.read_csv(ai_study)\n",
    "\n",
    "# Step 2: Exclude the first two rows\n",
    "df = df.iloc[2:]\n",
    "\n",
    "# Function to split responses and merge specific categories\n",
    "def split_and_merge_responses(response):\n",
    "    if pd.isna(response):\n",
    "        return []\n",
    "    parts = [part.strip() for part in str(response).split(',')]\n",
    "    result = []\n",
    "    current_item = \"\"\n",
    "    for part in parts:\n",
    "        if current_item:\n",
    "            current_item += \", \" + part\n",
    "            if \"Biases\" in part or \"Measures\" in part:\n",
    "                result.append(current_item)\n",
    "                current_item = \"\"\n",
    "        elif \"Clean Data\" in part:\n",
    "            current_item = part\n",
    "        elif \"Use or Implement\" in part:\n",
    "            current_item = part\n",
    "        else:\n",
    "            result.append(part)\n",
    "    if current_item:\n",
    "        result.append(current_item)\n",
    "    return result\n",
    "\n",
    "# Step 3: Process the responses using the split_and_merge_responses function\n",
    "df['B.2.5'] = df['B.2.5'].apply(split_and_merge_responses)\n",
    "\n",
    "# Step 4: Flatten the list of responses and count occurrences\n",
    "all_responses = df['B.2.5'].explode().dropna().value_counts().reset_index()\n",
    "all_responses.columns = ['Mitigation Strategy', 'Count']\n",
    "\n",
    "# Step 5: Calculate total number of valid responses (rows with non-empty lists)\n",
    "total_valid_responses = df[df['B.2.5'].apply(len) > 0].shape[0]\n",
    "\n",
    "# Step 6: Calculate the percentage of rows that mention each strategy\n",
    "all_responses['Percentage'] = (all_responses['Count'] / total_valid_responses * 100).round(2)\n",
    "\n",
    "# Print quantitative analysis\n",
    "print(\"Quantitative Analysis for B.2.5: Strategies to Mitigate Risks Associated with AI Technologies\")\n",
    "print(f\"Total valid responses: {total_valid_responses}\")\n",
    "\n",
    "print(\"\\nBreakdown of responses:\")\n",
    "breakdown = \", \".join([f\"{row['Mitigation Strategy']}: {row['Count']} mentions ({row['Percentage']}% of respondents)\" for _, row in all_responses.iterrows()])\n",
    "print(breakdown)\n",
    "\n",
    "# Calculate and print summary statistics\n",
    "total_mentions = all_responses['Count'].sum()\n",
    "average_mentions = total_mentions / len(all_responses)\n",
    "summary_stats = [\n",
    "    f\"Total mentions across all strategies: {total_mentions}\",\n",
    "    f\"Average mentions per strategy: {average_mentions:.2f}\",\n",
    "    f\"Most common strategy: {all_responses.iloc[0]['Mitigation Strategy']} ({all_responses.iloc[0]['Count']} mentions, {all_responses.iloc[0]['Percentage']}% of respondents)\",\n",
    "    f\"Least common strategy: {all_responses.iloc[-1]['Mitigation Strategy']} ({all_responses.iloc[-1]['Count']} mentions, {all_responses.iloc[-1]['Percentage']}% of respondents)\"\n",
    "]\n",
    "print(\"\\n\" + \", \".join(summary_stats))\n",
    "\n",
    "# Step 7: Visualize the results with a Bar Chart using Plotly\n",
    "fig = px.bar(all_responses, x='Mitigation Strategy', y='Count',\n",
    "             title='B.2.5 Strategies to Mitigate Risks Associated with AI Technologies',\n",
    "             labels={'Mitigation Strategy': 'Strategy', 'Count': 'Number of Mentions'},\n",
    "             color='Count',\n",
    "             color_continuous_scale='Blues',\n",
    "             text=all_responses['Percentage'].apply(lambda x: f'{x}% of respondents'))  # Add percentage text\n",
    "\n",
    "# Update layout to make the chart clearer\n",
    "fig.update_layout(xaxis_tickangle=45, xaxis_title='Mitigation Strategy', yaxis_title='Number of Mentions')\n",
    "\n",
    "# Step 8: Show the figure\n",
    "fig.show(renderer=\"browser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total valid responses: 300\n",
      "\n",
      "Breakdown of responses:\n",
      "Clean Data to Remove, Mitigate, or Minimize Biases: 162 mentions (54.0% of respondents)\n",
      "Monitor AI System Performance: 158 mentions (52.67% of respondents)\n",
      "Use AI Testing and Validation: 149 mentions (49.67% of respondents)\n",
      "Invest in Training and Education: 143 mentions (47.67% of respondents)\n",
      "Develop Ethical Guidelines: 131 mentions (43.67% of respondents)\n",
      "Implement Robust Security Measures: 130 mentions (43.33% of respondents)\n",
      "Conduct Regular Audits and Assessments: 129 mentions (43.0% of respondents)\n",
      "Use or Implement Privacy Enhancing Tools or Measures: 115 mentions (38.33% of respondents)\n",
      "Implement Transparent and Explainable Approaches: 93 mentions (31.0% of respondents)\n",
      "Implement Feedback Mechanisms: 88 mentions (29.33% of respondents)\n",
      "Adopt AI Governance Frameworks: 79 mentions (26.33% of respondents)\n",
      "Open Design and Development of Models and Datasets: 78 mentions (26.0% of respondents)\n",
      "Conduct Ethical and Privacy Impact Assessments: 77 mentions (25.67% of respondents)\n",
      "Create Contingency Plans: 75 mentions (25.0% of respondents)\n",
      "Collaborate with Experts: 72 mentions (24.0% of respondents)\n",
      "Others, please specify: 2 mentions (0.67% of respondents)\n",
      "\n",
      "Summary Statistics:\n",
      "Total mentions across all strategies: 1681\n",
      "Average mentions per strategy: 105.06\n",
      "Most common strategy: Clean Data to Remove, Mitigate, or Minimize Biases (162 mentions, 54.0% of respondents)\n",
      "Least common strategy: Others, please specify (2 mentions, 0.67% of respondents)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import re\n",
    "\n",
    "# Step 1: Read CSV file into a DataFrame\n",
    "df = pd.read_csv(ai_study)\n",
    "\n",
    "# Step 2: Exclude the first two rows\n",
    "df = df.iloc[2:]\n",
    "\n",
    "# Function to split responses and merge specific categories\n",
    "def split_and_merge_responses(response):\n",
    "    if pd.isna(response):\n",
    "        return []\n",
    "    # First, protect the specific phrases we want to keep together\n",
    "    response = response.replace(\"Clean Data to Remove, Mitigate, or Minimize Biases\", \"Clean Data to Remove Mitigate or Minimize Biases\")\n",
    "    response = response.replace(\"Others, please specify\", \"Others please specify\")\n",
    "    parts = [part.strip() for part in response.split(',')]\n",
    "    # Now, restore the original phrases\n",
    "    parts = [part.replace(\"Clean Data to Remove Mitigate or Minimize Biases\", \"Clean Data to Remove, Mitigate, or Minimize Biases\") for part in parts]\n",
    "    parts = [part.replace(\"Others please specify\", \"Others, please specify\") for part in parts]\n",
    "    return parts\n",
    "\n",
    "# Step 3: Process the responses using the split_and_merge_responses function\n",
    "df['B.2.5'] = df['B.2.5'].apply(split_and_merge_responses)\n",
    "\n",
    "# Step 4: Flatten the list of responses and count occurrences\n",
    "all_responses = df['B.2.5'].explode().dropna().value_counts().reset_index()\n",
    "all_responses.columns = ['Mitigation Strategy', 'Count']\n",
    "\n",
    "# Step 5: Calculate total number of valid responses (rows with non-empty lists)\n",
    "total_valid_responses = df[df['B.2.5'].apply(len) > 0].shape[0]\n",
    "\n",
    "# Step 6: Calculate the percentage of rows that mention each strategy\n",
    "all_responses['Percentage'] = (all_responses['Count'] / total_valid_responses * 100).round(2)\n",
    "\n",
    "# Step 7: Visualize the results with a Bar Chart using Plotly\n",
    "fig = px.bar(all_responses, x='Mitigation Strategy', y='Count',\n",
    "             title='B.2.5 Strategies to Mitigate Risks Associated with AI Technologies',\n",
    "             labels={'Mitigation Strategy': 'Strategy', 'Count': 'Number of Mentions'},\n",
    "             color='Count',\n",
    "             color_continuous_scale='Blues',\n",
    "             text=all_responses['Percentage'].apply(lambda x: f'<b><span style=\"font-size:12px;\">{x}</span></b>'))\n",
    "\n",
    "# Step 8: Update layout to match the visual style\n",
    "fig.update_layout(\n",
    "    xaxis_tickangle=45,\n",
    "    xaxis_title='Mitigation Strategy',\n",
    "    yaxis_title='Number of Mentions',\n",
    "    title={\n",
    "        'text': 'B.2.5 Strategies to Mitigate Risks Associated with AI Technologies',\n",
    "        'y': 0.95,\n",
    "        'x': 0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'\n",
    "    },\n",
    "    font=dict(size=12),\n",
    "    margin=dict(t=150),\n",
    "    yaxis=dict(range=[0, all_responses['Count'].max() * 1.15]),\n",
    "    coloraxis_showscale=False\n",
    ")\n",
    "\n",
    "# Step 9: Update traces to position text just above the bars and ensure uniform text size\n",
    "fig.update_traces(\n",
    "    textposition='outside',\n",
    "    textfont=dict(size=16, family='sans-serif', weight='bold'),\n",
    "    cliponaxis=False\n",
    ")\n",
    "\n",
    "# Step 10: Show the figure\n",
    "fig.show(renderer=\"browser\")\n",
    "\n",
    "# Print summary statistics\n",
    "print(f\"\\nTotal valid responses: {total_valid_responses}\")\n",
    "print(\"\\nBreakdown of responses:\")\n",
    "for _, row in all_responses.iterrows():\n",
    "    print(f\"{row['Mitigation Strategy']}: {row['Count']} mentions ({row['Percentage']}% of respondents)\")\n",
    "\n",
    "total_mentions = all_responses['Count'].sum()\n",
    "average_mentions = total_mentions / len(all_responses)\n",
    "print(f\"\\nSummary Statistics:\")\n",
    "print(f\"Total mentions across all strategies: {total_mentions}\")\n",
    "print(f\"Average mentions per strategy: {average_mentions:.2f}\")\n",
    "print(f\"Most common strategy: {all_responses.iloc[0]['Mitigation Strategy']} ({all_responses.iloc[0]['Count']} mentions, {all_responses.iloc[0]['Percentage']}% of respondents)\")\n",
    "print(f\"Least common strategy: {all_responses.iloc[-1]['Mitigation Strategy']} ({all_responses.iloc[-1]['Count']} mentions, {all_responses.iloc[-1]['Percentage']}% of respondents)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read AI_Study_Accepted_with_replacement_codes.csv.\n",
      "Index(['Remove? (Yes/No/Maybe)', 'StartDate', 'EndDate', 'Finished',\n",
      "       'RecordedDate', 'Unnamed: 5', 'ResponseId', 'UserLanguage',\n",
      "       'Q_RecaptchaScore', 'Q_RelevantIDDuplicate',\n",
      "       ...\n",
      "       'C.1 _5', 'C.1 _6', 'C.1 _7', 'C.1 _8', 'C.2', 'C.3.a', 'C.3_1_TEXT',\n",
      "       'C.3_2_TEXT', 'C.3_3_TEXT', 'PROLIFIC_PID'],\n",
      "      dtype='object', length=234)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Baldw\\AppData\\Local\\Temp\\ipykernel_16512\\943055147.py:133: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\Baldw\\AppData\\Local\\Temp\\ipykernel_16512\\943055147.py:151: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\Baldw\\AppData\\Local\\Temp\\ipykernel_16512\\943055147.py:151: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\Baldw\\AppData\\Local\\Temp\\ipykernel_16512\\943055147.py:151: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\Baldw\\AppData\\Local\\Temp\\ipykernel_16512\\943055147.py:151: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\Baldw\\AppData\\Local\\Temp\\ipykernel_16512\\943055147.py:151: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\Baldw\\AppData\\Local\\Temp\\ipykernel_16512\\943055147.py:151: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "C:\\Users\\Baldw\\AppData\\Local\\Temp\\ipykernel_16512\\943055147.py:151: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ranked Results for Location:\n",
      "\n",
      "| Mitigation Strategy                                  | Location   | Percentage   |\n",
      "|:-----------------------------------------------------|:-----------|:-------------|\n",
      "| Adopt AI Governance Frameworks                       | Other      | 21.74        |\n",
      "| Adopt AI Governance Frameworks                       | US         | 20.9         |\n",
      "| Adopt AI Governance Frameworks                       | Europe     | 13.68        |\n",
      "| Clean Data to Remove, Mitigate, or Minimize Biases   | Other      | 45.65        |\n",
      "| Clean Data to Remove, Mitigate, or Minimize Biases   | Europe     | 41.03        |\n",
      "| Clean Data to Remove, Mitigate, or Minimize Biases   | US         | 35.32        |\n",
      "| Collaborate with Experts                             | Europe     | 26.5         |\n",
      "| Collaborate with Experts                             | US         | 14.93        |\n",
      "| Collaborate with Experts                             | Other      | 11.96        |\n",
      "| Conduct Ethical and Privacy Impact Assessments       | Other      | 28.26        |\n",
      "| Conduct Ethical and Privacy Impact Assessments       | US         | 16.42        |\n",
      "| Conduct Ethical and Privacy Impact Assessments       | Europe     | 14.53        |\n",
      "| Conduct Regular Audits and Assessments               | Other      | 44.57        |\n",
      "| Conduct Regular Audits and Assessments               | US         | 27.86        |\n",
      "| Conduct Regular Audits and Assessments               | Europe     | 26.5         |\n",
      "| Create Contingency Plans                             | Other      | 21.74        |\n",
      "| Create Contingency Plans                             | US         | 21.39        |\n",
      "| Create Contingency Plans                             | Europe     | 10.26        |\n",
      "| Develop Ethical Guidelines                           | Other      | 32.61        |\n",
      "| Develop Ethical Guidelines                           | US         | 32.34        |\n",
      "| Develop Ethical Guidelines                           | Europe     | 29.91        |\n",
      "| Implement Feedback Mechanisms                        | Other      | 27.17        |\n",
      "| Implement Feedback Mechanisms                        | US         | 19.4         |\n",
      "| Implement Feedback Mechanisms                        | Europe     | 18.8         |\n",
      "| Implement Robust Security Measures                   | Other      | 40.22        |\n",
      "| Implement Robust Security Measures                   | US         | 29.85        |\n",
      "| Implement Robust Security Measures                   | Europe     | 26.5         |\n",
      "| Implement Transparent and Explainable Approaches     | US         | 26.37        |\n",
      "| Implement Transparent and Explainable Approaches     | Other      | 25           |\n",
      "| Implement Transparent and Explainable Approaches     | Europe     | 14.53        |\n",
      "| Invest in Training and Education                     | Other      | 39.13        |\n",
      "| Invest in Training and Education                     | Europe     | 36.75        |\n",
      "| Invest in Training and Education                     | US         | 30.85        |\n",
      "| Monitor AI System Performance                        | Other      | 39.13        |\n",
      "| Monitor AI System Performance                        | US         | 38.81        |\n",
      "| Monitor AI System Performance                        | Europe     | 35.9         |\n",
      "| Open Design and Development of Models and Datasets   | US         | 21.89        |\n",
      "| Open Design and Development of Models and Datasets   | Other      | 19.57        |\n",
      "| Open Design and Development of Models and Datasets   | Europe     | 13.68        |\n",
      "| Others, please specify                               | Europe     | 0.85         |\n",
      "| Others, please specify                               | US         | 0.5          |\n",
      "| Use AI Testing and Validation                        | US         | 38.31        |\n",
      "| Use AI Testing and Validation                        | Europe     | 34.19        |\n",
      "| Use AI Testing and Validation                        | Other      | 32.61        |\n",
      "| Use or Implement Privacy Enhancing Tools or Measures | Other      | 36.96        |\n",
      "| Use or Implement Privacy Enhancing Tools or Measures | US         | 27.36        |\n",
      "| Use or Implement Privacy Enhancing Tools or Measures | Europe     | 22.22        |\n",
      "\n",
      "Ranked Results for Company Type:\n",
      "\n",
      "| Mitigation Strategy                                  | Company Type      | Percentage   |\n",
      "|:-----------------------------------------------------|:------------------|:-------------|\n",
      "| Adopt AI Governance Frameworks                       | Government        | 30.3         |\n",
      "| Adopt AI Governance Frameworks                       | Multi-national    | 21.88        |\n",
      "| Adopt AI Governance Frameworks                       | Startup/Small     | 19.26        |\n",
      "| Adopt AI Governance Frameworks                       | Other             | 15.09        |\n",
      "| Adopt AI Governance Frameworks                       | Academic/Research | 12.73        |\n",
      "| Clean Data to Remove, Mitigate, or Minimize Biases   | Multi-national    | 47.66        |\n",
      "| Clean Data to Remove, Mitigate, or Minimize Biases   | Academic/Research | 47.27        |\n",
      "| Clean Data to Remove, Mitigate, or Minimize Biases   | Government        | 45.45        |\n",
      "| Clean Data to Remove, Mitigate, or Minimize Biases   | Startup/Small     | 30.37        |\n",
      "| Clean Data to Remove, Mitigate, or Minimize Biases   | Other             | 30.19        |\n",
      "| Collaborate with Experts                             | Multi-national    | 21.88        |\n",
      "| Collaborate with Experts                             | Academic/Research | 21.82        |\n",
      "| Collaborate with Experts                             | Other             | 20.75        |\n",
      "| Collaborate with Experts                             | Startup/Small     | 12.59        |\n",
      "| Collaborate with Experts                             | Government        | 12.12        |\n",
      "| Conduct Ethical and Privacy Impact Assessments       | Government        | 30.3         |\n",
      "| Conduct Ethical and Privacy Impact Assessments       | Multi-national    | 22.66        |\n",
      "| Conduct Ethical and Privacy Impact Assessments       | Startup/Small     | 17.04        |\n",
      "| Conduct Ethical and Privacy Impact Assessments       | Academic/Research | 12.73        |\n",
      "| Conduct Ethical and Privacy Impact Assessments       | Other             | 11.32        |\n",
      "| Conduct Regular Audits and Assessments               | Government        | 39.39        |\n",
      "| Conduct Regular Audits and Assessments               | Multi-national    | 36.72        |\n",
      "| Conduct Regular Audits and Assessments               | Startup/Small     | 29.63        |\n",
      "| Conduct Regular Audits and Assessments               | Academic/Research | 27.27        |\n",
      "| Conduct Regular Audits and Assessments               | Other             | 22.64        |\n",
      "| Create Contingency Plans                             | Government        | 21.21        |\n",
      "| Create Contingency Plans                             | Multi-national    | 19.53        |\n",
      "| Create Contingency Plans                             | Startup/Small     | 19.26        |\n",
      "| Create Contingency Plans                             | Other             | 16.98        |\n",
      "| Create Contingency Plans                             | Academic/Research | 10.91        |\n",
      "| Develop Ethical Guidelines                           | Government        | 45.45        |\n",
      "| Develop Ethical Guidelines                           | Multi-national    | 36.72        |\n",
      "| Develop Ethical Guidelines                           | Academic/Research | 32.73        |\n",
      "| Develop Ethical Guidelines                           | Other             | 32.08        |\n",
      "| Develop Ethical Guidelines                           | Startup/Small     | 25.19        |\n",
      "| Implement Feedback Mechanisms                        | Multi-national    | 25.78        |\n",
      "| Implement Feedback Mechanisms                        | Government        | 24.24        |\n",
      "| Implement Feedback Mechanisms                        | Startup/Small     | 20.74        |\n",
      "| Implement Feedback Mechanisms                        | Other             | 16.98        |\n",
      "| Implement Feedback Mechanisms                        | Academic/Research | 12.73        |\n",
      "| Implement Robust Security Measures                   | Multi-national    | 35.94        |\n",
      "| Implement Robust Security Measures                   | Startup/Small     | 34.07        |\n",
      "| Implement Robust Security Measures                   | Government        | 33.33        |\n",
      "| Implement Robust Security Measures                   | Academic/Research | 23.64        |\n",
      "| Implement Robust Security Measures                   | Other             | 20.75        |\n",
      "| Implement Transparent and Explainable Approaches     | Government        | 30.3         |\n",
      "| Implement Transparent and Explainable Approaches     | Academic/Research | 27.27        |\n",
      "| Implement Transparent and Explainable Approaches     | Multi-national    | 25.78        |\n",
      "| Implement Transparent and Explainable Approaches     | Startup/Small     | 17.78        |\n",
      "| Implement Transparent and Explainable Approaches     | Other             | 15.09        |\n",
      "| Invest in Training and Education                     | Multi-national    | 39.84        |\n",
      "| Invest in Training and Education                     | Government        | 36.36        |\n",
      "| Invest in Training and Education                     | Startup/Small     | 35.56        |\n",
      "| Invest in Training and Education                     | Academic/Research | 29.09        |\n",
      "| Invest in Training and Education                     | Other             | 24.53        |\n",
      "| Monitor AI System Performance                        | Government        | 45.45        |\n",
      "| Monitor AI System Performance                        | Other             | 45.28        |\n",
      "| Monitor AI System Performance                        | Multi-national    | 42.19        |\n",
      "| Monitor AI System Performance                        | Startup/Small     | 36.3         |\n",
      "| Monitor AI System Performance                        | Academic/Research | 25.45        |\n",
      "| Open Design and Development of Models and Datasets   | Academic/Research | 23.64        |\n",
      "| Open Design and Development of Models and Datasets   | Government        | 21.21        |\n",
      "| Open Design and Development of Models and Datasets   | Multi-national    | 21.09        |\n",
      "| Open Design and Development of Models and Datasets   | Startup/Small     | 16.3         |\n",
      "| Open Design and Development of Models and Datasets   | Other             | 15.09        |\n",
      "| Others, please specify                               | Multi-national    | 0.78         |\n",
      "| Others, please specify                               | Startup/Small     | 0.74         |\n",
      "| Use AI Testing and Validation                        | Multi-national    | 44.53        |\n",
      "| Use AI Testing and Validation                        | Startup/Small     | 35.56        |\n",
      "| Use AI Testing and Validation                        | Government        | 33.33        |\n",
      "| Use AI Testing and Validation                        | Other             | 28.3         |\n",
      "| Use AI Testing and Validation                        | Academic/Research | 27.27        |\n",
      "| Use or Implement Privacy Enhancing Tools or Measures | Multi-national    | 30.47        |\n",
      "| Use or Implement Privacy Enhancing Tools or Measures | Government        | 30.3         |\n",
      "| Use or Implement Privacy Enhancing Tools or Measures | Startup/Small     | 28.89        |\n",
      "| Use or Implement Privacy Enhancing Tools or Measures | Other             | 28.3         |\n",
      "| Use or Implement Privacy Enhancing Tools or Measures | Academic/Research | 21.82        |\n",
      "\n",
      "Ranked Results for Role:\n",
      "\n",
      "| Mitigation Strategy                                  | Role                 | Percentage   |\n",
      "|:-----------------------------------------------------|:---------------------|:-------------|\n",
      "| Adopt AI Governance Frameworks                       | AI Researcher        | 42.31        |\n",
      "| Adopt AI Governance Frameworks                       | Requirements analyst | 24.07        |\n",
      "| Adopt AI Governance Frameworks                       | Other                | 20           |\n",
      "| Adopt AI Governance Frameworks                       | AI Manager           | 19.74        |\n",
      "| Adopt AI Governance Frameworks                       | QA and Maintenance   | 18.18        |\n",
      "| Adopt AI Governance Frameworks                       | AI developers        | 15.98        |\n",
      "| Clean Data to Remove, Mitigate, or Minimize Biases   | AI Researcher        | 69.23        |\n",
      "| Clean Data to Remove, Mitigate, or Minimize Biases   | QA and Maintenance   | 45.45        |\n",
      "| Clean Data to Remove, Mitigate, or Minimize Biases   | AI Manager           | 40.79        |\n",
      "| Clean Data to Remove, Mitigate, or Minimize Biases   | AI developers        | 39.69        |\n",
      "| Clean Data to Remove, Mitigate, or Minimize Biases   | Security/Privacy     | 31.58        |\n",
      "| Clean Data to Remove, Mitigate, or Minimize Biases   | Requirements analyst | 29.63        |\n",
      "| Collaborate with Experts                             | AI Researcher        | 50           |\n",
      "| Collaborate with Experts                             | QA and Maintenance   | 27.27        |\n",
      "| Collaborate with Experts                             | Other                | 20           |\n",
      "| Collaborate with Experts                             | AI developers        | 15.46        |\n",
      "| Collaborate with Experts                             | Requirements analyst | 14.81        |\n",
      "| Collaborate with Experts                             | AI Manager           | 14.47        |\n",
      "| Collaborate with Experts                             | Security/Privacy     | 10.53        |\n",
      "| Conduct Ethical and Privacy Impact Assessments       | Other                | 40           |\n",
      "| Conduct Ethical and Privacy Impact Assessments       | AI Manager           | 25           |\n",
      "| Conduct Ethical and Privacy Impact Assessments       | AI Researcher        | 23.08        |\n",
      "| Conduct Ethical and Privacy Impact Assessments       | QA and Maintenance   | 18.18        |\n",
      "| Conduct Ethical and Privacy Impact Assessments       | AI developers        | 18.04        |\n",
      "| Conduct Ethical and Privacy Impact Assessments       | Security/Privacy     | 15.79        |\n",
      "| Conduct Ethical and Privacy Impact Assessments       | Requirements analyst | 9.26         |\n",
      "| Conduct Regular Audits and Assessments               | AI Researcher        | 42.31        |\n",
      "| Conduct Regular Audits and Assessments               | Other                | 40           |\n",
      "| Conduct Regular Audits and Assessments               | AI Manager           | 34.21        |\n",
      "| Conduct Regular Audits and Assessments               | QA and Maintenance   | 31.82        |\n",
      "| Conduct Regular Audits and Assessments               | Security/Privacy     | 31.58        |\n",
      "| Conduct Regular Audits and Assessments               | Requirements analyst | 31.48        |\n",
      "| Conduct Regular Audits and Assessments               | AI developers        | 28.87        |\n",
      "| Create Contingency Plans                             | Requirements analyst | 24.07        |\n",
      "| Create Contingency Plans                             | AI Manager           | 21.05        |\n",
      "| Create Contingency Plans                             | Other                | 20           |\n",
      "| Create Contingency Plans                             | QA and Maintenance   | 18.18        |\n",
      "| Create Contingency Plans                             | AI developers        | 16.49        |\n",
      "| Create Contingency Plans                             | Security/Privacy     | 15.79        |\n",
      "| Create Contingency Plans                             | AI Researcher        | 11.54        |\n",
      "| Develop Ethical Guidelines                           | AI Researcher        | 53.85        |\n",
      "| Develop Ethical Guidelines                           | AI Manager           | 44.74        |\n",
      "| Develop Ethical Guidelines                           | AI developers        | 29.38        |\n",
      "| Develop Ethical Guidelines                           | QA and Maintenance   | 27.27        |\n",
      "| Develop Ethical Guidelines                           | Requirements analyst | 24.07        |\n",
      "| Develop Ethical Guidelines                           | Other                | 20           |\n",
      "| Develop Ethical Guidelines                           | Security/Privacy     | 15.79        |\n",
      "| Implement Feedback Mechanisms                        | Other                | 40           |\n",
      "| Implement Feedback Mechanisms                        | AI developers        | 24.23        |\n",
      "| Implement Feedback Mechanisms                        | Requirements analyst | 22.22        |\n",
      "| Implement Feedback Mechanisms                        | AI Manager           | 18.42        |\n",
      "| Implement Feedback Mechanisms                        | QA and Maintenance   | 18.18        |\n",
      "| Implement Feedback Mechanisms                        | Security/Privacy     | 15.79        |\n",
      "| Implement Feedback Mechanisms                        | AI Researcher        | 15.38        |\n",
      "| Implement Robust Security Measures                   | AI Manager           | 40.79        |\n",
      "| Implement Robust Security Measures                   | AI Researcher        | 38.46        |\n",
      "| Implement Robust Security Measures                   | Security/Privacy     | 36.84        |\n",
      "| Implement Robust Security Measures                   | Requirements analyst | 29.63        |\n",
      "| Implement Robust Security Measures                   | AI developers        | 29.38        |\n",
      "| Implement Robust Security Measures                   | Other                | 20           |\n",
      "| Implement Robust Security Measures                   | QA and Maintenance   | 18.18        |\n",
      "| Implement Transparent and Explainable Approaches     | Other                | 40           |\n",
      "| Implement Transparent and Explainable Approaches     | AI Manager           | 28.95        |\n",
      "| Implement Transparent and Explainable Approaches     | AI Researcher        | 26.92        |\n",
      "| Implement Transparent and Explainable Approaches     | AI developers        | 25.77        |\n",
      "| Implement Transparent and Explainable Approaches     | Requirements analyst | 11.11        |\n",
      "| Implement Transparent and Explainable Approaches     | Security/Privacy     | 10.53        |\n",
      "| Implement Transparent and Explainable Approaches     | QA and Maintenance   | 9.09         |\n",
      "| Invest in Training and Education                     | AI Researcher        | 50           |\n",
      "| Invest in Training and Education                     | AI Manager           | 46.05        |\n",
      "| Invest in Training and Education                     | Security/Privacy     | 36.84        |\n",
      "| Invest in Training and Education                     | Requirements analyst | 33.33        |\n",
      "| Invest in Training and Education                     | AI developers        | 28.35        |\n",
      "| Invest in Training and Education                     | QA and Maintenance   | 27.27        |\n",
      "| Invest in Training and Education                     | Other                | 20           |\n",
      "| Monitor AI System Performance                        | AI Researcher        | 42.31        |\n",
      "| Monitor AI System Performance                        | AI developers        | 41.24        |\n",
      "| Monitor AI System Performance                        | Requirements analyst | 37.04        |\n",
      "| Monitor AI System Performance                        | QA and Maintenance   | 36.36        |\n",
      "| Monitor AI System Performance                        | AI Manager           | 35.53        |\n",
      "| Monitor AI System Performance                        | Security/Privacy     | 31.58        |\n",
      "| Monitor AI System Performance                        | Other                | 20           |\n",
      "| Open Design and Development of Models and Datasets   | AI Researcher        | 30.77        |\n",
      "| Open Design and Development of Models and Datasets   | AI Manager           | 21.05        |\n",
      "| Open Design and Development of Models and Datasets   | AI developers        | 20.62        |\n",
      "| Open Design and Development of Models and Datasets   | Security/Privacy     | 15.79        |\n",
      "| Open Design and Development of Models and Datasets   | Requirements analyst | 14.81        |\n",
      "| Open Design and Development of Models and Datasets   | QA and Maintenance   | 4.55         |\n",
      "| Others, please specify                               | Requirements analyst | 1.85         |\n",
      "| Others, please specify                               | AI developers        | 0.52         |\n",
      "| Use AI Testing and Validation                        | AI Researcher        | 57.69        |\n",
      "| Use AI Testing and Validation                        | QA and Maintenance   | 45.45        |\n",
      "| Use AI Testing and Validation                        | AI developers        | 37.11        |\n",
      "| Use AI Testing and Validation                        | Security/Privacy     | 31.58        |\n",
      "| Use AI Testing and Validation                        | Requirements analyst | 31.48        |\n",
      "| Use AI Testing and Validation                        | AI Manager           | 30.26        |\n",
      "| Use or Implement Privacy Enhancing Tools or Measures | AI Researcher        | 42.31        |\n",
      "| Use or Implement Privacy Enhancing Tools or Measures | Other                | 40           |\n",
      "| Use or Implement Privacy Enhancing Tools or Measures | AI Manager           | 38.16        |\n",
      "| Use or Implement Privacy Enhancing Tools or Measures | Requirements analyst | 33.33        |\n",
      "| Use or Implement Privacy Enhancing Tools or Measures | Security/Privacy     | 31.58        |\n",
      "| Use or Implement Privacy Enhancing Tools or Measures | AI developers        | 20.62        |\n",
      "| Use or Implement Privacy Enhancing Tools or Measures | QA and Maintenance   | 18.18        |\n",
      "\n",
      "Ranked Results for Education:\n",
      "\n",
      "| Mitigation Strategy                                  | Education          | Percentage   |\n",
      "|:-----------------------------------------------------|:-------------------|:-------------|\n",
      "| Adopt AI Governance Frameworks                       | Other              | 25           |\n",
      "| Adopt AI Governance Frameworks                       | Bachelor's Degree  | 21.82        |\n",
      "| Adopt AI Governance Frameworks                       | Graduate Education | 20           |\n",
      "| Adopt AI Governance Frameworks                       | Ph.D.              | 15.15        |\n",
      "| Adopt AI Governance Frameworks                       | High School Degree | 5.56         |\n",
      "| Clean Data to Remove, Mitigate, or Minimize Biases   | Ph.D.              | 51.52        |\n",
      "| Clean Data to Remove, Mitigate, or Minimize Biases   | Graduate Education | 42.35        |\n",
      "| Clean Data to Remove, Mitigate, or Minimize Biases   | Bachelor's Degree  | 38.79        |\n",
      "| Clean Data to Remove, Mitigate, or Minimize Biases   | High School Degree | 22.22        |\n",
      "| Clean Data to Remove, Mitigate, or Minimize Biases   | Other              | 12.5         |\n",
      "| Collaborate with Experts                             | Other              | 37.5         |\n",
      "| Collaborate with Experts                             | Ph.D.              | 30.3         |\n",
      "| Collaborate with Experts                             | Graduate Education | 18.82        |\n",
      "| Collaborate with Experts                             | Bachelor's Degree  | 14.55        |\n",
      "| Collaborate with Experts                             | High School Degree | 8.33         |\n",
      "| Conduct Ethical and Privacy Impact Assessments       | Bachelor's Degree  | 21.21        |\n",
      "| Conduct Ethical and Privacy Impact Assessments       | Ph.D.              | 21.21        |\n",
      "| Conduct Ethical and Privacy Impact Assessments       | Graduate Education | 18.82        |\n",
      "| Conduct Ethical and Privacy Impact Assessments       | Other              | 12.5         |\n",
      "| Conduct Ethical and Privacy Impact Assessments       | High School Degree | 5.56         |\n",
      "| Conduct Regular Audits and Assessments               | Ph.D.              | 39.39        |\n",
      "| Conduct Regular Audits and Assessments               | Graduate Education | 35.88        |\n",
      "| Conduct Regular Audits and Assessments               | Bachelor's Degree  | 29.09        |\n",
      "| Conduct Regular Audits and Assessments               | Other              | 25           |\n",
      "| Conduct Regular Audits and Assessments               | High School Degree | 13.89        |\n",
      "| Create Contingency Plans                             | Bachelor's Degree  | 21.82        |\n",
      "| Create Contingency Plans                             | Graduate Education | 17.65        |\n",
      "| Create Contingency Plans                             | Ph.D.              | 15.15        |\n",
      "| Create Contingency Plans                             | High School Degree | 11.11        |\n",
      "| Develop Ethical Guidelines                           | Ph.D.              | 45.45        |\n",
      "| Develop Ethical Guidelines                           | Other              | 37.5         |\n",
      "| Develop Ethical Guidelines                           | Bachelor's Degree  | 36.36        |\n",
      "| Develop Ethical Guidelines                           | Graduate Education | 26.47        |\n",
      "| Develop Ethical Guidelines                           | High School Degree | 22.22        |\n",
      "| Implement Feedback Mechanisms                        | Other              | 25           |\n",
      "| Implement Feedback Mechanisms                        | Bachelor's Degree  | 23.64        |\n",
      "| Implement Feedback Mechanisms                        | Graduate Education | 23.53        |\n",
      "| Implement Feedback Mechanisms                        | High School Degree | 11.11        |\n",
      "| Implement Feedback Mechanisms                        | Ph.D.              | 9.09         |\n",
      "| Implement Robust Security Measures                   | Bachelor's Degree  | 34.55        |\n",
      "| Implement Robust Security Measures                   | Graduate Education | 32.94        |\n",
      "| Implement Robust Security Measures                   | Ph.D.              | 30.3         |\n",
      "| Implement Robust Security Measures                   | Other              | 25           |\n",
      "| Implement Robust Security Measures                   | High School Degree | 13.89        |\n",
      "| Implement Transparent and Explainable Approaches     | Ph.D.              | 33.33        |\n",
      "| Implement Transparent and Explainable Approaches     | Other              | 25           |\n",
      "| Implement Transparent and Explainable Approaches     | Bachelor's Degree  | 23.64        |\n",
      "| Implement Transparent and Explainable Approaches     | Graduate Education | 21.76        |\n",
      "| Implement Transparent and Explainable Approaches     | High School Degree | 8.33         |\n",
      "| Invest in Training and Education                     | Other              | 50           |\n",
      "| Invest in Training and Education                     | Ph.D.              | 42.42        |\n",
      "| Invest in Training and Education                     | Bachelor's Degree  | 34.55        |\n",
      "| Invest in Training and Education                     | Graduate Education | 34.12        |\n",
      "| Invest in Training and Education                     | High School Degree | 27.78        |\n",
      "| Monitor AI System Performance                        | Other              | 62.5         |\n",
      "| Monitor AI System Performance                        | Graduate Education | 41.76        |\n",
      "| Monitor AI System Performance                        | Bachelor's Degree  | 37.58        |\n",
      "| Monitor AI System Performance                        | Ph.D.              | 33.33        |\n",
      "| Monitor AI System Performance                        | High School Degree | 25           |\n",
      "| Open Design and Development of Models and Datasets   | Ph.D.              | 27.27        |\n",
      "| Open Design and Development of Models and Datasets   | Other              | 25           |\n",
      "| Open Design and Development of Models and Datasets   | Graduate Education | 21.18        |\n",
      "| Open Design and Development of Models and Datasets   | Bachelor's Degree  | 17.58        |\n",
      "| Open Design and Development of Models and Datasets   | High School Degree | 5.56         |\n",
      "| Others, please specify                               | Graduate Education | 1.18         |\n",
      "| Use AI Testing and Validation                        | Other              | 75           |\n",
      "| Use AI Testing and Validation                        | Bachelor's Degree  | 38.18        |\n",
      "| Use AI Testing and Validation                        | Ph.D.              | 36.36        |\n",
      "| Use AI Testing and Validation                        | High School Degree | 33.33        |\n",
      "| Use AI Testing and Validation                        | Graduate Education | 32.94        |\n",
      "| Use or Implement Privacy Enhancing Tools or Measures | Ph.D.              | 36.36        |\n",
      "| Use or Implement Privacy Enhancing Tools or Measures | Bachelor's Degree  | 33.33        |\n",
      "| Use or Implement Privacy Enhancing Tools or Measures | Other              | 25           |\n",
      "| Use or Implement Privacy Enhancing Tools or Measures | Graduate Education | 22.94        |\n",
      "| Use or Implement Privacy Enhancing Tools or Measures | High School Degree | 19.44        |\n",
      "\n",
      "Ranked Results for Dev Experience:\n",
      "\n",
      "| Mitigation Strategy                                  | Dev Experience   | Percentage   |\n",
      "|:-----------------------------------------------------|:-----------------|:-------------|\n",
      "| Adopt AI Governance Frameworks                       | 5-10 Years       | 21.28        |\n",
      "| Adopt AI Governance Frameworks                       | 10+ Years        | 19.12        |\n",
      "| Adopt AI Governance Frameworks                       | 2-5 Years        | 17.41        |\n",
      "| Clean Data to Remove, Mitigate, or Minimize Biases   | 10+ Years        | 42.65        |\n",
      "| Clean Data to Remove, Mitigate, or Minimize Biases   | 5-10 Years       | 42.55        |\n",
      "| Clean Data to Remove, Mitigate, or Minimize Biases   | 2-5 Years        | 35.32        |\n",
      "| Collaborate with Experts                             | 10+ Years        | 19.12        |\n",
      "| Collaborate with Experts                             | 5-10 Years       | 15.96        |\n",
      "| Collaborate with Experts                             | 2-5 Years        | 14.93        |\n",
      "| Conduct Ethical and Privacy Impact Assessments       | 10+ Years        | 22.06        |\n",
      "| Conduct Ethical and Privacy Impact Assessments       | 2-5 Years        | 18.91        |\n",
      "| Conduct Ethical and Privacy Impact Assessments       | 5-10 Years       | 18.09        |\n",
      "| Conduct Regular Audits and Assessments               | 10+ Years        | 36.76        |\n",
      "| Conduct Regular Audits and Assessments               | 2-5 Years        | 30.85        |\n",
      "| Conduct Regular Audits and Assessments               | 5-10 Years       | 28.72        |\n",
      "| Create Contingency Plans                             | 5-10 Years       | 21.28        |\n",
      "| Create Contingency Plans                             | 10+ Years        | 20.59        |\n",
      "| Create Contingency Plans                             | 2-5 Years        | 15.42        |\n",
      "| Develop Ethical Guidelines                           | 10+ Years        | 35.29        |\n",
      "| Develop Ethical Guidelines                           | 2-5 Years        | 29.85        |\n",
      "| Develop Ethical Guidelines                           | 5-10 Years       | 28.72        |\n",
      "| Implement Feedback Mechanisms                        | 5-10 Years       | 22.34        |\n",
      "| Implement Feedback Mechanisms                        | 2-5 Years        | 21.89        |\n",
      "| Implement Feedback Mechanisms                        | 10+ Years        | 19.12        |\n",
      "| Implement Robust Security Measures                   | 10+ Years        | 41.18        |\n",
      "| Implement Robust Security Measures                   | 5-10 Years       | 31.91        |\n",
      "| Implement Robust Security Measures                   | 2-5 Years        | 29.35        |\n",
      "| Implement Transparent and Explainable Approaches     | 10+ Years        | 25           |\n",
      "| Implement Transparent and Explainable Approaches     | 2-5 Years        | 21.39        |\n",
      "| Implement Transparent and Explainable Approaches     | 5-10 Years       | 21.28        |\n",
      "| Invest in Training and Education                     | 5-10 Years       | 37.23        |\n",
      "| Invest in Training and Education                     | 2-5 Years        | 34.33        |\n",
      "| Invest in Training and Education                     | 10+ Years        | 32.35        |\n",
      "| Monitor AI System Performance                        | 10+ Years        | 44.12        |\n",
      "| Monitor AI System Performance                        | 2-5 Years        | 37.31        |\n",
      "| Monitor AI System Performance                        | 5-10 Years       | 36.17        |\n",
      "| Open Design and Development of Models and Datasets   | 10+ Years        | 27.94        |\n",
      "| Open Design and Development of Models and Datasets   | 2-5 Years        | 16.42        |\n",
      "| Open Design and Development of Models and Datasets   | 5-10 Years       | 15.96        |\n",
      "| Others, please specify                               | 5-10 Years       | 1.06         |\n",
      "| Others, please specify                               | 2-5 Years        | 0.5          |\n",
      "| Use AI Testing and Validation                        | 10+ Years        | 47.06        |\n",
      "| Use AI Testing and Validation                        | 2-5 Years        | 33.33        |\n",
      "| Use AI Testing and Validation                        | 5-10 Years       | 29.79        |\n",
      "| Use or Implement Privacy Enhancing Tools or Measures | 2-5 Years        | 27.86        |\n",
      "| Use or Implement Privacy Enhancing Tools or Measures | 5-10 Years       | 27.66        |\n",
      "| Use or Implement Privacy Enhancing Tools or Measures | 10+ Years        | 23.53        |\n",
      "\n",
      "Ranked Results for Gender:\n",
      "\n",
      "| Mitigation Strategy                                  | Gender                    | Percentage   |\n",
      "|:-----------------------------------------------------|:--------------------------|:-------------|\n",
      "| Adopt AI Governance Frameworks                       | Prefer not to say         | 50           |\n",
      "| Adopt AI Governance Frameworks                       | Female                    | 20.93        |\n",
      "| Adopt AI Governance Frameworks                       | Male                      | 18.35        |\n",
      "| Clean Data to Remove, Mitigate, or Minimize Biases   | Prefer not to say         | 50           |\n",
      "| Clean Data to Remove, Mitigate, or Minimize Biases   | Male                      | 40.29        |\n",
      "| Clean Data to Remove, Mitigate, or Minimize Biases   | Female                    | 37.98        |\n",
      "| Collaborate with Experts                             | Prefer not to say         | 50           |\n",
      "| Collaborate with Experts                             | Non-binary / Third gender | 33.33        |\n",
      "| Collaborate with Experts                             | Female                    | 17.83        |\n",
      "| Collaborate with Experts                             | Male                      | 16.91        |\n",
      "| Conduct Ethical and Privacy Impact Assessments       | Prefer not to say         | 50           |\n",
      "| Conduct Ethical and Privacy Impact Assessments       | Non-binary / Third gender | 33.33        |\n",
      "| Conduct Ethical and Privacy Impact Assessments       | Female                    | 24.81        |\n",
      "| Conduct Ethical and Privacy Impact Assessments       | Male                      | 15.47        |\n",
      "| Conduct Regular Audits and Assessments               | Prefer not to say         | 50           |\n",
      "| Conduct Regular Audits and Assessments               | Female                    | 38.76        |\n",
      "| Conduct Regular Audits and Assessments               | Male                      | 28.06        |\n",
      "| Create Contingency Plans                             | Prefer not to say         | 50           |\n",
      "| Create Contingency Plans                             | Male                      | 18.71        |\n",
      "| Create Contingency Plans                             | Female                    | 17.05        |\n",
      "| Develop Ethical Guidelines                           | Prefer not to say         | 50           |\n",
      "| Develop Ethical Guidelines                           | Female                    | 35.66        |\n",
      "| Develop Ethical Guidelines                           | Male                      | 30.22        |\n",
      "| Implement Feedback Mechanisms                        | Prefer not to say         | 50           |\n",
      "| Implement Feedback Mechanisms                        | Male                      | 21.94        |\n",
      "| Implement Feedback Mechanisms                        | Female                    | 20.16        |\n",
      "| Implement Robust Security Measures                   | Prefer not to say         | 50           |\n",
      "| Implement Robust Security Measures                   | Female                    | 36.43        |\n",
      "| Implement Robust Security Measures                   | Male                      | 29.5         |\n",
      "| Implement Transparent and Explainable Approaches     | Prefer not to say         | 50           |\n",
      "| Implement Transparent and Explainable Approaches     | Non-binary / Third gender | 33.33        |\n",
      "| Implement Transparent and Explainable Approaches     | Female                    | 24.03        |\n",
      "| Implement Transparent and Explainable Approaches     | Male                      | 21.58        |\n",
      "| Invest in Training and Education                     | Prefer not to say         | 50           |\n",
      "| Invest in Training and Education                     | Female                    | 37.98        |\n",
      "| Invest in Training and Education                     | Male                      | 33.45        |\n",
      "| Monitor AI System Performance                        | Prefer not to say         | 50           |\n",
      "| Monitor AI System Performance                        | Female                    | 39.53        |\n",
      "| Monitor AI System Performance                        | Male                      | 37.41        |\n",
      "| Monitor AI System Performance                        | Non-binary / Third gender | 33.33        |\n",
      "| Open Design and Development of Models and Datasets   | Prefer not to say         | 50           |\n",
      "| Open Design and Development of Models and Datasets   | Female                    | 20.16        |\n",
      "| Open Design and Development of Models and Datasets   | Male                      | 18.35        |\n",
      "| Others, please specify                               | Female                    | 0.78         |\n",
      "| Others, please specify                               | Male                      | 0.36         |\n",
      "| Use AI Testing and Validation                        | Prefer not to say         | 50           |\n",
      "| Use AI Testing and Validation                        | Male                      | 39.57        |\n",
      "| Use AI Testing and Validation                        | Female                    | 29.46        |\n",
      "| Use or Implement Privacy Enhancing Tools or Measures | Prefer not to say         | 50           |\n",
      "| Use or Implement Privacy Enhancing Tools or Measures | Non-binary / Third gender | 33.33        |\n",
      "| Use or Implement Privacy Enhancing Tools or Measures | Female                    | 28.68        |\n",
      "| Use or Implement Privacy Enhancing Tools or Measures | Male                      | 27.34        |\n",
      "\n",
      "Ranked Results for Company Size:\n",
      "\n",
      "| Mitigation Strategy                                  | Company Size     | Percentage   |\n",
      "|:-----------------------------------------------------|:-----------------|:-------------|\n",
      "| Adopt AI Governance Frameworks                       | 100+ Employees   | 21.69        |\n",
      "| Adopt AI Governance Frameworks                       | 21-50 Employees  | 19.44        |\n",
      "| Adopt AI Governance Frameworks                       | 6-20 Employees   | 18.87        |\n",
      "| Adopt AI Governance Frameworks                       | 51-100 Employees | 18.64        |\n",
      "| Adopt AI Governance Frameworks                       | 1-5 Employees    | 5.26         |\n",
      "| Clean Data to Remove, Mitigate, or Minimize Biases   | 100+ Employees   | 48.15        |\n",
      "| Clean Data to Remove, Mitigate, or Minimize Biases   | 51-100 Employees | 37.29        |\n",
      "| Clean Data to Remove, Mitigate, or Minimize Biases   | 6-20 Employees   | 35.85        |\n",
      "| Clean Data to Remove, Mitigate, or Minimize Biases   | 21-50 Employees  | 29.17        |\n",
      "| Clean Data to Remove, Mitigate, or Minimize Biases   | 1-5 Employees    | 23.68        |\n",
      "| Collaborate with Experts                             | 100+ Employees   | 21.69        |\n",
      "| Collaborate with Experts                             | 6-20 Employees   | 20.75        |\n",
      "| Collaborate with Experts                             | 21-50 Employees  | 12.5         |\n",
      "| Collaborate with Experts                             | 51-100 Employees | 11.86        |\n",
      "| Collaborate with Experts                             | 1-5 Employees    | 10.53        |\n",
      "| Conduct Ethical and Privacy Impact Assessments       | 6-20 Employees   | 24.53        |\n",
      "| Conduct Ethical and Privacy Impact Assessments       | 51-100 Employees | 23.73        |\n",
      "| Conduct Ethical and Privacy Impact Assessments       | 100+ Employees   | 18.52        |\n",
      "| Conduct Ethical and Privacy Impact Assessments       | 21-50 Employees  | 15.28        |\n",
      "| Conduct Ethical and Privacy Impact Assessments       | 1-5 Employees    | 7.89         |\n",
      "| Conduct Regular Audits and Assessments               | 51-100 Employees | 49.15        |\n",
      "| Conduct Regular Audits and Assessments               | 100+ Employees   | 34.39        |\n",
      "| Conduct Regular Audits and Assessments               | 6-20 Employees   | 26.42        |\n",
      "| Conduct Regular Audits and Assessments               | 21-50 Employees  | 22.22        |\n",
      "| Conduct Regular Audits and Assessments               | 1-5 Employees    | 10.53        |\n",
      "| Create Contingency Plans                             | 51-100 Employees | 30.51        |\n",
      "| Create Contingency Plans                             | 21-50 Employees  | 20.83        |\n",
      "| Create Contingency Plans                             | 1-5 Employees    | 15.79        |\n",
      "| Create Contingency Plans                             | 6-20 Employees   | 15.09        |\n",
      "| Create Contingency Plans                             | 100+ Employees   | 14.29        |\n",
      "| Develop Ethical Guidelines                           | 100+ Employees   | 35.98        |\n",
      "| Develop Ethical Guidelines                           | 6-20 Employees   | 32.08        |\n",
      "| Develop Ethical Guidelines                           | 51-100 Employees | 30.51        |\n",
      "| Develop Ethical Guidelines                           | 21-50 Employees  | 27.78        |\n",
      "| Develop Ethical Guidelines                           | 1-5 Employees    | 21.05        |\n",
      "| Implement Feedback Mechanisms                        | 100+ Employees   | 23.81        |\n",
      "| Implement Feedback Mechanisms                        | 21-50 Employees  | 23.61        |\n",
      "| Implement Feedback Mechanisms                        | 6-20 Employees   | 18.87        |\n",
      "| Implement Feedback Mechanisms                        | 51-100 Employees | 16.95        |\n",
      "| Implement Feedback Mechanisms                        | 1-5 Employees    | 13.16        |\n",
      "| Implement Robust Security Measures                   | 51-100 Employees | 44.07        |\n",
      "| Implement Robust Security Measures                   | 21-50 Employees  | 37.5         |\n",
      "| Implement Robust Security Measures                   | 6-20 Employees   | 30.19        |\n",
      "| Implement Robust Security Measures                   | 100+ Employees   | 29.1         |\n",
      "| Implement Robust Security Measures                   | 1-5 Employees    | 15.79        |\n",
      "| Implement Transparent and Explainable Approaches     | 6-20 Employees   | 26.42        |\n",
      "| Implement Transparent and Explainable Approaches     | 51-100 Employees | 23.73        |\n",
      "| Implement Transparent and Explainable Approaches     | 21-50 Employees  | 23.61        |\n",
      "| Implement Transparent and Explainable Approaches     | 100+ Employees   | 22.22        |\n",
      "| Implement Transparent and Explainable Approaches     | 1-5 Employees    | 13.16        |\n",
      "| Invest in Training and Education                     | 100+ Employees   | 40.74        |\n",
      "| Invest in Training and Education                     | 51-100 Employees | 33.9         |\n",
      "| Invest in Training and Education                     | 6-20 Employees   | 32.08        |\n",
      "| Invest in Training and Education                     | 21-50 Employees  | 30.56        |\n",
      "| Invest in Training and Education                     | 1-5 Employees    | 15.79        |\n",
      "| Monitor AI System Performance                        | 6-20 Employees   | 43.4         |\n",
      "| Monitor AI System Performance                        | 21-50 Employees  | 40.28        |\n",
      "| Monitor AI System Performance                        | 100+ Employees   | 39.15        |\n",
      "| Monitor AI System Performance                        | 51-100 Employees | 37.29        |\n",
      "| Monitor AI System Performance                        | 1-5 Employees    | 23.68        |\n",
      "| Open Design and Development of Models and Datasets   | 51-100 Employees | 25.42        |\n",
      "| Open Design and Development of Models and Datasets   | 6-20 Employees   | 22.64        |\n",
      "| Open Design and Development of Models and Datasets   | 21-50 Employees  | 18.06        |\n",
      "| Open Design and Development of Models and Datasets   | 100+ Employees   | 17.99        |\n",
      "| Open Design and Development of Models and Datasets   | 1-5 Employees    | 10.53        |\n",
      "| Others, please specify                               | 6-20 Employees   | 1.89         |\n",
      "| Others, please specify                               | 100+ Employees   | 0.53         |\n",
      "| Use AI Testing and Validation                        | 100+ Employees   | 39.15        |\n",
      "| Use AI Testing and Validation                        | 51-100 Employees | 37.29        |\n",
      "| Use AI Testing and Validation                        | 6-20 Employees   | 35.85        |\n",
      "| Use AI Testing and Validation                        | 1-5 Employees    | 31.58        |\n",
      "| Use AI Testing and Validation                        | 21-50 Employees  | 30.56        |\n",
      "| Use or Implement Privacy Enhancing Tools or Measures | 6-20 Employees   | 35.85        |\n",
      "| Use or Implement Privacy Enhancing Tools or Measures | 1-5 Employees    | 28.95        |\n",
      "| Use or Implement Privacy Enhancing Tools or Measures | 21-50 Employees  | 27.78        |\n",
      "| Use or Implement Privacy Enhancing Tools or Measures | 100+ Employees   | 26.46        |\n",
      "| Use or Implement Privacy Enhancing Tools or Measures | 51-100 Employees | 23.73        |\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Define file path\n",
    "file_path = 'AI_Study_Accepted_with_replacement_codes.csv'\n",
    "\n",
    "# Create a folder named 'graphs/b.2.5' if it doesn't exist\n",
    "if not os.path.exists('graphs/b.2.5'):\n",
    "    os.makedirs('graphs/b.2.5')\n",
    "\n",
    "# Demographic columns and their mappings (using column numbers)\n",
    "demographics = {\n",
    "    'Location': {\n",
    "        'column': 28,  # Column number for Location\n",
    "        'mapping': {\n",
    "            'North America': 'US',\n",
    "            'Central/South America': 'Other',\n",
    "            'EU/UK/EEA': 'Europe',\n",
    "            'Europe - Outside of EU/UK/EEA': 'Europe',\n",
    "            'Africa': 'Other',\n",
    "            'Middle East': 'Other',\n",
    "            'Asia': 'Other',\n",
    "            'Australia and Oceania': 'Other',\n",
    "            'Prefer not to say': 'Other',\n",
    "            'Other, please specify': 'Other'\n",
    "        }\n",
    "    },\n",
    "    'Company Type': {\n",
    "        'column': 26,  # Column number for Company Type\n",
    "        'mapping': {\n",
    "            'Multi-national Corporate': 'Multi-national',\n",
    "            'Startup/Small Business': 'Startup/Small',\n",
    "            'Academic Institution/Research Center': 'Academic/Research',\n",
    "            'Government': 'Government',\n",
    "            'Individual': 'Other',\n",
    "            'Other, please specify': 'Other'\n",
    "        }\n",
    "    },\n",
    "    'Role': {\n",
    "        'column': 30,  # Column number for Role\n",
    "        'mapping': {\n",
    "            'Administrative role (CEO, Chief Technical Officer, Chief Operating Officer, Chief Information Officer)': 'AI Manager',\n",
    "            'AI Manager': 'AI Manager',\n",
    "            'Requirements Analyst or Engineer': 'Requirements analyst',\n",
    "            'Scrum Master, Product Manager, or Project Manager': 'Requirements analyst',\n",
    "            'AI Engineer or Developer': 'AI developers',\n",
    "            '(Software) Developer, Designer, or Architect': 'AI developers',\n",
    "            'Data Scientist or Data Analyst': 'AI developers',\n",
    "            'Information Security Analyst or Engineer': 'Security/Privacy',\n",
    "            'Information Privacy Analyst or Engineer': 'Security/Privacy',\n",
    "            'AI Ethicist': 'Other',\n",
    "            'AI Researcher': 'AI Researcher',\n",
    "            '(Software) Quality Assurance Engineer or Tester': 'QA and Maintenance',\n",
    "            'Other, please specify': 'Other'\n",
    "        }\n",
    "    },\n",
    "    'Education': {\n",
    "        'column': 21,  # Column number for Education\n",
    "        'mapping': {\n",
    "            \"High School Degree\": \"High School Degree\",\n",
    "            \"Bachelor's Degree\": \"Bachelor's Degree\",\n",
    "            \"Master's Degree (i.e., MSc., M.A., etc.)\": \"Graduate Education\",\n",
    "            \"MBA (Master of Business Administration)\": \"Graduate Education\",\n",
    "            \"Graduate Certificates\": \"Graduate Education\",\n",
    "            \"Ph.D.\": \"Ph.D.\",\n",
    "            \"Other, please specify\": \"Other\"\n",
    "        }\n",
    "    },\n",
    "    'Dev Experience': {\n",
    "        'column': 32,  # Column number for Dev Experience\n",
    "        'mapping': {\n",
    "            'None': 'None',\n",
    "            '1-2 Years': '1-2 Years',\n",
    "            '2-5 Years': '2-5 Years',\n",
    "            '5-10 Years': '5-10 Years',\n",
    "            '10+ Years': '10+ Years'\n",
    "        }\n",
    "    },\n",
    "    'Gender': {\n",
    "        'column': 19,  # Column number for Gender\n",
    "        'mapping': {  # No predefined mapping for gender; use unique values directly\n",
    "            'Male': 'Male',\n",
    "            'Female': 'Female',\n",
    "            'Non-binary / Third gender': 'Non-binary / Third gender',\n",
    "            'Prefer not to say': 'Prefer not to say',\n",
    "            'Other, please specify': 'Other'\n",
    "        }\n",
    "    },\n",
    "    'Company Size': {\n",
    "        'column': 25,  # Column number for Company Size\n",
    "        'mapping': {\n",
    "            '1-5 Employees': '1-5 Employees',\n",
    "            '6-20 Employees': '6-20 Employees',\n",
    "            '21-50 Employees': '21-50 Employees',\n",
    "            '51-100 Employees': '51-100 Employees',\n",
    "            '101+ Employees': '100+ Employees'\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "def read_and_clean_csv(file_path):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, encoding='utf-8')\n",
    "        print(f\"Successfully read {file_path}.\")\n",
    "        return df\n",
    "    except UnicodeDecodeError:\n",
    "        print(f\"Failed to read {file_path} with utf-8 encoding.\")\n",
    "        return None\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        return None\n",
    "\n",
    "def process_data(df):\n",
    "    # Step 2: Exclude the first two rows\n",
    "    df = df.iloc[2:]\n",
    "\n",
    "    # Function to split responses and merge specific categories\n",
    "    def split_and_merge_responses(response):\n",
    "        if pd.isna(response):\n",
    "            return []\n",
    "        # First, protect the specific phrases we want to keep together\n",
    "        response = response.replace(\"Clean Data to Remove, Mitigate, or Minimize Biases\", \"Clean Data to Remove Mitigate or Minimize Biases\")\n",
    "        response = response.replace(\"Others, please specify\", \"Others please specify\")\n",
    "        parts = [part.strip() for part in response.split(',')]\n",
    "        # Now, restore the original phrases\n",
    "        parts = [part.replace(\"Clean Data to Remove Mitigate or Minimize Biases\", \"Clean Data to Remove, Mitigate, or Minimize Biases\") for part in parts]\n",
    "        parts = [part.replace(\"Others please specify\", \"Others, please specify\") for part in parts]\n",
    "        return parts\n",
    "\n",
    "    # Step 3: Process the responses using the split_and_merge_responses function\n",
    "    df['B.2.5'] = df['B.2.5'].apply(split_and_merge_responses)\n",
    "\n",
    "    # Step 4: Flatten the list of responses and count occurrences\n",
    "    all_responses = df['B.2.5'].explode().dropna().value_counts().reset_index()\n",
    "    all_responses.columns = ['Mitigation Strategy', 'Count']\n",
    "\n",
    "    # Step 5: Calculate total number of valid responses (rows with non-empty lists)\n",
    "    total_valid_responses = df[df['B.2.5'].apply(len) > 0].shape[0]\n",
    "\n",
    "    # Step 6: Calculate the percentage of rows that mention each strategy\n",
    "    all_responses['Percentage'] = (all_responses['Count'] / total_valid_responses * 100).round(2)\n",
    "\n",
    "    # --- Rank demographics by principle ---\n",
    "\n",
    "    all_results = {}\n",
    "    for demographic in demographics:\n",
    "        if demographics[demographic]['mapping']:\n",
    "            categories = set(demographics[demographic]['mapping'].values())\n",
    "            df['GroupedCategory'] = df.iloc[:, demographics[demographic]['column']].map(demographics[demographic]['mapping'])\n",
    "        else:\n",
    "            categories = df.iloc[:, demographics[demographic]['column']].dropna().unique()\n",
    "            df['GroupedCategory'] = df.iloc[:, demographics[demographic]['column']]\n",
    "\n",
    "        demographic_results = {}\n",
    "        for category in categories:\n",
    "            df_category = df[df['GroupedCategory'] == category]\n",
    "            category_responses = df_category['B.2.5'].explode().value_counts().reset_index()\n",
    "            category_responses.columns = ['Mitigation Strategy', 'Count']\n",
    "            category_responses['Percentage'] = (category_responses['Count'] / len(df_category) * 100).round(2)\n",
    "            demographic_results[category] = category_responses\n",
    "\n",
    "        combined_results = pd.concat(demographic_results, names=[demographic, 'Category'])\n",
    "        combined_results = combined_results.reset_index()\n",
    "\n",
    "        ranked_results = combined_results.groupby(['Mitigation Strategy', demographic])['Percentage'].mean().reset_index()\n",
    "        ranked_results = ranked_results.sort_values(by=['Mitigation Strategy', 'Percentage'], ascending=[True, False])\n",
    "\n",
    "        all_results[demographic] = ranked_results\n",
    "\n",
    "    return all_results\n",
    "\n",
    "# Main execution\n",
    "df = read_and_clean_csv(file_path)\n",
    "if df is not None:\n",
    "    print(df.columns)  # Print the columns for debugging\n",
    "    all_ranked_results = process_data(df)\n",
    "\n",
    "    # Determine the maximum number of unique demographic options across all demographics\n",
    "    max_demographic_options = max([len(result[demographic].unique()) for demographic, result in all_ranked_results.items()])\n",
    "\n",
    "    # Create a color scale with shades of blue and yellow\n",
    "    blue_colors = px.colors.sequential.Blues[2:]  # Start from a darker blue\n",
    "    yellow_colors = px.colors.sequential.YlOrRd[1:]  # Start from a darker yellow\n",
    "    color_scale = blue_colors[:max_demographic_options//2] + yellow_colors[max_demographic_options//2:]\n",
    "\n",
    "    for demographic, ranked_results in all_ranked_results.items():\n",
    "        # --- Create graph for each demographic ---\n",
    "        fig = px.bar(\n",
    "            ranked_results,\n",
    "            x='Mitigation Strategy',  # Mitigation strategies on the x-axis\n",
    "            y='Percentage',\n",
    "            color=demographic,  # Demographic options as colors\n",
    "            title=f'Mitigation Strategies by {demographic}',\n",
    "            labels={'Percentage': 'Average Percentage', 'Mitigation Strategy': 'Strategy'},\n",
    "            color_discrete_sequence=color_scale,  # Use the generated color scale\n",
    "            barmode='group'  # Grouped bar chart\n",
    "        )\n",
    "\n",
    "        fig.update_layout(\n",
    "            xaxis_tickangle=45,\n",
    "            xaxis_title='Mitigation Strategy',  # X-axis label\n",
    "            yaxis_title='Average Percentage',\n",
    "            title={\n",
    "                'y': 0.95,\n",
    "                'x': 0.5,\n",
    "                'xanchor': 'center',\n",
    "                'yanchor': 'top'\n",
    "            },\n",
    "            font=dict(size=12),\n",
    "            margin=dict(t=150),\n",
    "            yaxis_range=[0, 100]  # Set y-axis range to 0-100\n",
    "        )\n",
    "\n",
    "        # Show the figure in browser\n",
    "        fig.show(renderer=\"browser\")\n",
    "\n",
    "        # Print the ranked results\n",
    "        print(f\"\\nRanked Results for {demographic}:\\n\")\n",
    "        print(ranked_results.to_markdown(index=False, numalign=\"left\", stralign=\"left\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read AI_Study_Accepted.csv.\n",
      "Index(['Remove? (Yes/No/Maybe)', 'StartDate', 'EndDate', 'Finished',\n",
      "       'RecordedDate', 'Unnamed: 5', 'ResponseId', 'UserLanguage',\n",
      "       'Q_RecaptchaScore', 'Q_RelevantIDDuplicate',\n",
      "       ...\n",
      "       'C.1 _5', 'C.1 _6', 'C.1 _7', 'C.1 _8', 'C.2', 'C.3.1', 'C.3_1_TEXT',\n",
      "       'C.3_2_TEXT', 'C.3_3_TEXT', 'PROLIFIC_PID'],\n",
      "      dtype='object', length=234)\n",
      "\n",
      "Ranked Results for Location:\n",
      "\n",
      "\n",
      "Strategy: Adopt AI Governance Frameworks\n",
      "\n",
      "| Mitigation Strategy            | Location   | Percentage   |\n",
      "|:-------------------------------|:-----------|:-------------|\n",
      "| Adopt AI Governance Frameworks | Other      | 35.11        |\n",
      "| Adopt AI Governance Frameworks | US         | 26.95        |\n",
      "| Adopt AI Governance Frameworks | Europe     | 21.11        |\n",
      "\n",
      "Strategy: Clean Data to Remove, Mitigate, or Minimize Biases\n",
      "\n",
      "| Mitigation Strategy                                | Location   | Percentage   |\n",
      "|:---------------------------------------------------|:-----------|:-------------|\n",
      "| Clean Data to Remove, Mitigate, or Minimize Biases | Europe     | 55.56        |\n",
      "| Clean Data to Remove, Mitigate, or Minimize Biases | Other      | 55.32        |\n",
      "| Clean Data to Remove, Mitigate, or Minimize Biases | US         | 42.51        |\n",
      "\n",
      "Strategy: Collaborate with Experts\n",
      "\n",
      "| Mitigation Strategy      | Location   | Percentage   |\n",
      "|:-------------------------|:-----------|:-------------|\n",
      "| Collaborate with Experts | Europe     | 35.56        |\n",
      "| Collaborate with Experts | Other      | 20.21        |\n",
      "| Collaborate with Experts | US         | 17.96        |\n",
      "\n",
      "Strategy: Conduct Ethical and Privacy Impact Assessments\n",
      "\n",
      "| Mitigation Strategy                            | Location   | Percentage   |\n",
      "|:-----------------------------------------------|:-----------|:-------------|\n",
      "| Conduct Ethical and Privacy Impact Assessments | Other      | 38.3         |\n",
      "| Conduct Ethical and Privacy Impact Assessments | Europe     | 22.22        |\n",
      "| Conduct Ethical and Privacy Impact Assessments | US         | 21.56        |\n",
      "\n",
      "Strategy: Conduct Regular Audits and Assessments\n",
      "\n",
      "| Mitigation Strategy                    | Location   | Percentage   |\n",
      "|:---------------------------------------|:-----------|:-------------|\n",
      "| Conduct Regular Audits and Assessments | Other      | 58.51        |\n",
      "| Conduct Regular Audits and Assessments | Europe     | 38.89        |\n",
      "| Conduct Regular Audits and Assessments | US         | 38.32        |\n",
      "\n",
      "Strategy: Create Contingency Plans\n",
      "\n",
      "| Mitigation Strategy      | Location   | Percentage   |\n",
      "|:-------------------------|:-----------|:-------------|\n",
      "| Create Contingency Plans | Other      | 28.72        |\n",
      "| Create Contingency Plans | US         | 26.35        |\n",
      "| Create Contingency Plans | Europe     | 17.78        |\n",
      "\n",
      "Strategy: Develop Ethical Guidelines\n",
      "\n",
      "| Mitigation Strategy        | Location   | Percentage   |\n",
      "|:---------------------------|:-----------|:-------------|\n",
      "| Develop Ethical Guidelines | Europe     | 42.22        |\n",
      "| Develop Ethical Guidelines | US         | 41.92        |\n",
      "| Develop Ethical Guidelines | Other      | 38.3         |\n",
      "\n",
      "Strategy: Implement Feedback Mechanisms\n",
      "\n",
      "| Mitigation Strategy           | Location   | Percentage   |\n",
      "|:------------------------------|:-----------|:-------------|\n",
      "| Implement Feedback Mechanisms | Other      | 36.17        |\n",
      "| Implement Feedback Mechanisms | Europe     | 25.56        |\n",
      "| Implement Feedback Mechanisms | US         | 23.95        |\n",
      "\n",
      "Strategy: Implement Robust Security Measures\n",
      "\n",
      "| Mitigation Strategy                | Location   | Percentage   |\n",
      "|:-----------------------------------|:-----------|:-------------|\n",
      "| Implement Robust Security Measures | Other      | 50           |\n",
      "| Implement Robust Security Measures | US         | 39.52        |\n",
      "| Implement Robust Security Measures | Europe     | 35.56        |\n",
      "\n",
      "Strategy: Implement Transparent and Explainable Approaches\n",
      "\n",
      "| Mitigation Strategy                              | Location   | Percentage   |\n",
      "|:-------------------------------------------------|:-----------|:-------------|\n",
      "| Implement Transparent and Explainable Approaches | US         | 34.13        |\n",
      "| Implement Transparent and Explainable Approaches | Other      | 31.91        |\n",
      "| Implement Transparent and Explainable Approaches | Europe     | 18.89        |\n",
      "\n",
      "Strategy: Invest in Training and Education\n",
      "\n",
      "| Mitigation Strategy              | Location   | Percentage   |\n",
      "|:---------------------------------|:-----------|:-------------|\n",
      "| Invest in Training and Education | Other      | 52.13        |\n",
      "| Invest in Training and Education | Europe     | 47.78        |\n",
      "| Invest in Training and Education | US         | 41.32        |\n",
      "\n",
      "Strategy: Monitor AI System Performance\n",
      "\n",
      "| Mitigation Strategy           | Location   | Percentage   |\n",
      "|:------------------------------|:-----------|:-------------|\n",
      "| Monitor AI System Performance | Other      | 51.06        |\n",
      "| Monitor AI System Performance | Europe     | 50           |\n",
      "| Monitor AI System Performance | US         | 47.31        |\n",
      "\n",
      "Strategy: Open Design and Development of Models and Datasets\n",
      "\n",
      "| Mitigation Strategy                                | Location   | Percentage   |\n",
      "|:---------------------------------------------------|:-----------|:-------------|\n",
      "| Open Design and Development of Models and Datasets | US         | 26.95        |\n",
      "| Open Design and Development of Models and Datasets | Other      | 26.6         |\n",
      "| Open Design and Development of Models and Datasets | Europe     | 18.89        |\n",
      "\n",
      "Strategy: Others, please specify\n",
      "\n",
      "| Mitigation Strategy    | Location   | Percentage   |\n",
      "|:-----------------------|:-----------|:-------------|\n",
      "| Others, please specify | Europe     | 3.33         |\n",
      "| Others, please specify | Other      | 1.06         |\n",
      "| Others, please specify | US         | 0.6          |\n",
      "\n",
      "Strategy: Use AI Testing and Validation\n",
      "\n",
      "| Mitigation Strategy           | Location   | Percentage   |\n",
      "|:------------------------------|:-----------|:-------------|\n",
      "| Use AI Testing and Validation | Europe     | 45.56        |\n",
      "| Use AI Testing and Validation | US         | 44.91        |\n",
      "| Use AI Testing and Validation | Other      | 42.55        |\n",
      "\n",
      "Strategy: Use or Implement Privacy Enhancing Tools or Measures\n",
      "\n",
      "| Mitigation Strategy                                  | Location   | Percentage   |\n",
      "|:-----------------------------------------------------|:-----------|:-------------|\n",
      "| Use or Implement Privacy Enhancing Tools or Measures | Other      | 45.74        |\n",
      "| Use or Implement Privacy Enhancing Tools or Measures | US         | 35.93        |\n",
      "| Use or Implement Privacy Enhancing Tools or Measures | Europe     | 30           |\n",
      "\n",
      "Overall Ranked Strategies for Location:\n",
      "\n",
      "1. Clean Data to Remove, Mitigate, or Minimize Biases: 51.13%\n",
      "2. Monitor AI System Performance: 49.46%\n",
      "3. Invest in Training and Education: 47.08%\n",
      "4. Conduct Regular Audits and Assessments: 45.24%\n",
      "5. Use AI Testing and Validation: 44.34%\n",
      "6. Implement Robust Security Measures: 41.69%\n",
      "7. Develop Ethical Guidelines: 40.81%\n",
      "8. Use or Implement Privacy Enhancing Tools or Measures: 37.22%\n",
      "9. Implement Feedback Mechanisms: 28.56%\n",
      "10. Implement Transparent and Explainable Approaches: 28.31%\n",
      "11. Adopt AI Governance Frameworks: 27.72%\n",
      "12. Conduct Ethical and Privacy Impact Assessments: 27.36%\n",
      "13. Collaborate with Experts: 24.58%\n",
      "14. Create Contingency Plans: 24.28%\n",
      "15. Open Design and Development of Models and Datasets: 24.15%\n",
      "16. Others, please specify: 1.66%\n",
      "\n",
      "Ranked Results for Company Type:\n",
      "\n",
      "\n",
      "Strategy: Adopt AI Governance Frameworks\n",
      "\n",
      "| Mitigation Strategy            | Company Type      | Percentage   |\n",
      "|:-------------------------------|:------------------|:-------------|\n",
      "| Adopt AI Governance Frameworks | Government        | 39.29        |\n",
      "| Adopt AI Governance Frameworks | Startup/Small     | 30.83        |\n",
      "| Adopt AI Governance Frameworks | Multi-national    | 26.79        |\n",
      "| Adopt AI Governance Frameworks | Academic/Research | 24.44        |\n",
      "| Adopt AI Governance Frameworks | Other             | 22.5         |\n",
      "\n",
      "Strategy: Clean Data to Remove, Mitigate, or Minimize Biases\n",
      "\n",
      "| Mitigation Strategy                                | Company Type      | Percentage   |\n",
      "|:---------------------------------------------------|:------------------|:-------------|\n",
      "| Clean Data to Remove, Mitigate, or Minimize Biases | Academic/Research | 68.89        |\n",
      "| Clean Data to Remove, Mitigate, or Minimize Biases | Multi-national    | 58.93        |\n",
      "| Clean Data to Remove, Mitigate, or Minimize Biases | Government        | 53.57        |\n",
      "| Clean Data to Remove, Mitigate, or Minimize Biases | Other             | 45           |\n",
      "| Clean Data to Remove, Mitigate, or Minimize Biases | Startup/Small     | 34.17        |\n",
      "\n",
      "Strategy: Collaborate with Experts\n",
      "\n",
      "| Mitigation Strategy      | Company Type      | Percentage   |\n",
      "|:-------------------------|:------------------|:-------------|\n",
      "| Collaborate with Experts | Other             | 30           |\n",
      "| Collaborate with Experts | Academic/Research | 28.89        |\n",
      "| Collaborate with Experts | Multi-national    | 27.68        |\n",
      "| Collaborate with Experts | Startup/Small     | 17.5         |\n",
      "| Collaborate with Experts | Government        | 14.29        |\n",
      "\n",
      "Strategy: Conduct Ethical and Privacy Impact Assessments\n",
      "\n",
      "| Mitigation Strategy                            | Company Type      | Percentage   |\n",
      "|:-----------------------------------------------|:------------------|:-------------|\n",
      "| Conduct Ethical and Privacy Impact Assessments | Government        | 42.86        |\n",
      "| Conduct Ethical and Privacy Impact Assessments | Multi-national    | 29.46        |\n",
      "| Conduct Ethical and Privacy Impact Assessments | Startup/Small     | 26.67        |\n",
      "| Conduct Ethical and Privacy Impact Assessments | Academic/Research | 17.78        |\n",
      "| Conduct Ethical and Privacy Impact Assessments | Other             | 17.5         |\n",
      "\n",
      "Strategy: Conduct Regular Audits and Assessments\n",
      "\n",
      "| Mitigation Strategy                    | Company Type      | Percentage   |\n",
      "|:---------------------------------------|:------------------|:-------------|\n",
      "| Conduct Regular Audits and Assessments | Government        | 57.14        |\n",
      "| Conduct Regular Audits and Assessments | Academic/Research | 46.67        |\n",
      "| Conduct Regular Audits and Assessments | Multi-national    | 45.54        |\n",
      "| Conduct Regular Audits and Assessments | Startup/Small     | 42.5         |\n",
      "| Conduct Regular Audits and Assessments | Other             | 35           |\n",
      "\n",
      "Strategy: Create Contingency Plans\n",
      "\n",
      "| Mitigation Strategy      | Company Type      | Percentage   |\n",
      "|:-------------------------|:------------------|:-------------|\n",
      "| Create Contingency Plans | Multi-national    | 25.89        |\n",
      "| Create Contingency Plans | Startup/Small     | 25.83        |\n",
      "| Create Contingency Plans | Government        | 25           |\n",
      "| Create Contingency Plans | Other             | 25           |\n",
      "| Create Contingency Plans | Academic/Research | 17.78        |\n",
      "\n",
      "Strategy: Develop Ethical Guidelines\n",
      "\n",
      "| Mitigation Strategy        | Company Type      | Percentage   |\n",
      "|:---------------------------|:------------------|:-------------|\n",
      "| Develop Ethical Guidelines | Government        | 50           |\n",
      "| Develop Ethical Guidelines | Other             | 47.5         |\n",
      "| Develop Ethical Guidelines | Academic/Research | 46.67        |\n",
      "| Develop Ethical Guidelines | Multi-national    | 43.75        |\n",
      "| Develop Ethical Guidelines | Startup/Small     | 34.17        |\n",
      "\n",
      "Strategy: Implement Feedback Mechanisms\n",
      "\n",
      "| Mitigation Strategy           | Company Type      | Percentage   |\n",
      "|:------------------------------|:------------------|:-------------|\n",
      "| Implement Feedback Mechanisms | Multi-national    | 32.14        |\n",
      "| Implement Feedback Mechanisms | Government        | 28.57        |\n",
      "| Implement Feedback Mechanisms | Startup/Small     | 28.33        |\n",
      "| Implement Feedback Mechanisms | Other             | 22.5         |\n",
      "| Implement Feedback Mechanisms | Academic/Research | 17.78        |\n",
      "\n",
      "Strategy: Implement Robust Security Measures\n",
      "\n",
      "| Mitigation Strategy                | Company Type      | Percentage   |\n",
      "|:-----------------------------------|:------------------|:-------------|\n",
      "| Implement Robust Security Measures | Government        | 46.43        |\n",
      "| Implement Robust Security Measures | Multi-national    | 44.64        |\n",
      "| Implement Robust Security Measures | Startup/Small     | 42.5         |\n",
      "| Implement Robust Security Measures | Academic/Research | 35.56        |\n",
      "| Implement Robust Security Measures | Other             | 32.5         |\n",
      "\n",
      "Strategy: Implement Transparent and Explainable Approaches\n",
      "\n",
      "| Mitigation Strategy                              | Company Type      | Percentage   |\n",
      "|:-------------------------------------------------|:------------------|:-------------|\n",
      "| Implement Transparent and Explainable Approaches | Academic/Research | 37.78        |\n",
      "| Implement Transparent and Explainable Approaches | Government        | 35.71        |\n",
      "| Implement Transparent and Explainable Approaches | Multi-national    | 32.14        |\n",
      "| Implement Transparent and Explainable Approaches | Other             | 25           |\n",
      "| Implement Transparent and Explainable Approaches | Startup/Small     | 22.5         |\n",
      "\n",
      "Strategy: Invest in Training and Education\n",
      "\n",
      "| Mitigation Strategy              | Company Type      | Percentage   |\n",
      "|:---------------------------------|:------------------|:-------------|\n",
      "| Invest in Training and Education | Startup/Small     | 49.17        |\n",
      "| Invest in Training and Education | Multi-national    | 48.21        |\n",
      "| Invest in Training and Education | Academic/Research | 44.44        |\n",
      "| Invest in Training and Education | Government        | 42.86        |\n",
      "| Invest in Training and Education | Other             | 37.5         |\n",
      "\n",
      "Strategy: Monitor AI System Performance\n",
      "\n",
      "| Mitigation Strategy           | Company Type      | Percentage   |\n",
      "|:------------------------------|:------------------|:-------------|\n",
      "| Monitor AI System Performance | Other             | 60           |\n",
      "| Monitor AI System Performance | Government        | 53.57        |\n",
      "| Monitor AI System Performance | Multi-national    | 52.68        |\n",
      "| Monitor AI System Performance | Startup/Small     | 44.17        |\n",
      "| Monitor AI System Performance | Academic/Research | 42.22        |\n",
      "\n",
      "Strategy: Open Design and Development of Models and Datasets\n",
      "\n",
      "| Mitigation Strategy                                | Company Type      | Percentage   |\n",
      "|:---------------------------------------------------|:------------------|:-------------|\n",
      "| Open Design and Development of Models and Datasets | Government        | 32.14        |\n",
      "| Open Design and Development of Models and Datasets | Academic/Research | 31.11        |\n",
      "| Open Design and Development of Models and Datasets | Multi-national    | 26.79        |\n",
      "| Open Design and Development of Models and Datasets | Other             | 22.5         |\n",
      "| Open Design and Development of Models and Datasets | Startup/Small     | 20           |\n",
      "\n",
      "Strategy: Others, please specify\n",
      "\n",
      "| Mitigation Strategy    | Company Type   | Percentage   |\n",
      "|:-----------------------|:---------------|:-------------|\n",
      "| Others, please specify | Startup/Small  | 2.5          |\n",
      "| Others, please specify | Multi-national | 1.79         |\n",
      "\n",
      "Strategy: Use AI Testing and Validation\n",
      "\n",
      "| Mitigation Strategy           | Company Type      | Percentage   |\n",
      "|:------------------------------|:------------------|:-------------|\n",
      "| Use AI Testing and Validation | Multi-national    | 54.46        |\n",
      "| Use AI Testing and Validation | Startup/Small     | 41.67        |\n",
      "| Use AI Testing and Validation | Government        | 39.29        |\n",
      "| Use AI Testing and Validation | Academic/Research | 37.78        |\n",
      "| Use AI Testing and Validation | Other             | 37.5         |\n",
      "\n",
      "Strategy: Use or Implement Privacy Enhancing Tools or Measures\n",
      "\n",
      "| Mitigation Strategy                                  | Company Type      | Percentage   |\n",
      "|:-----------------------------------------------------|:------------------|:-------------|\n",
      "| Use or Implement Privacy Enhancing Tools or Measures | Other             | 42.5         |\n",
      "| Use or Implement Privacy Enhancing Tools or Measures | Multi-national    | 37.5         |\n",
      "| Use or Implement Privacy Enhancing Tools or Measures | Startup/Small     | 37.5         |\n",
      "| Use or Implement Privacy Enhancing Tools or Measures | Academic/Research | 35.56        |\n",
      "| Use or Implement Privacy Enhancing Tools or Measures | Government        | 32.14        |\n",
      "\n",
      "Overall Ranked Strategies for Company Type:\n",
      "\n",
      "1. Clean Data to Remove, Mitigate, or Minimize Biases: 52.11%\n",
      "2. Monitor AI System Performance: 50.53%\n",
      "3. Conduct Regular Audits and Assessments: 45.37%\n",
      "4. Invest in Training and Education: 44.44%\n",
      "5. Develop Ethical Guidelines: 44.42%\n",
      "6. Use AI Testing and Validation: 42.14%\n",
      "7. Implement Robust Security Measures: 40.33%\n",
      "8. Use or Implement Privacy Enhancing Tools or Measures: 37.04%\n",
      "9. Implement Transparent and Explainable Approaches: 30.63%\n",
      "10. Adopt AI Governance Frameworks: 28.77%\n",
      "11. Conduct Ethical and Privacy Impact Assessments: 26.85%\n",
      "12. Open Design and Development of Models and Datasets: 26.51%\n",
      "13. Implement Feedback Mechanisms: 25.86%\n",
      "14. Create Contingency Plans: 23.90%\n",
      "15. Collaborate with Experts: 23.67%\n",
      "16. Others, please specify: 2.15%\n",
      "\n",
      "Ranked Results for Role:\n",
      "\n",
      "\n",
      "Strategy: Adopt AI Governance Frameworks\n",
      "\n",
      "| Mitigation Strategy            | Role                 | Percentage   |\n",
      "|:-------------------------------|:---------------------|:-------------|\n",
      "| Adopt AI Governance Frameworks | Other                | 50           |\n",
      "| Adopt AI Governance Frameworks | AI Researcher        | 44           |\n",
      "| Adopt AI Governance Frameworks | QA and Maintenance   | 30.77        |\n",
      "| Adopt AI Governance Frameworks | Requirements analyst | 30           |\n",
      "| Adopt AI Governance Frameworks | AI developers        | 25.48        |\n",
      "| Adopt AI Governance Frameworks | AI Manager           | 22.54        |\n",
      "\n",
      "Strategy: Clean Data to Remove, Mitigate, or Minimize Biases\n",
      "\n",
      "| Mitigation Strategy                                | Role                 | Percentage   |\n",
      "|:---------------------------------------------------|:---------------------|:-------------|\n",
      "| Clean Data to Remove, Mitigate, or Minimize Biases | AI Researcher        | 72           |\n",
      "| Clean Data to Remove, Mitigate, or Minimize Biases | QA and Maintenance   | 69.23        |\n",
      "| Clean Data to Remove, Mitigate, or Minimize Biases | Security/Privacy     | 53.85        |\n",
      "| Clean Data to Remove, Mitigate, or Minimize Biases | AI developers        | 51.59        |\n",
      "| Clean Data to Remove, Mitigate, or Minimize Biases | AI Manager           | 43.66        |\n",
      "| Clean Data to Remove, Mitigate, or Minimize Biases | Requirements analyst | 34           |\n",
      "\n",
      "Strategy: Collaborate with Experts\n",
      "\n",
      "| Mitigation Strategy      | Role                 | Percentage   |\n",
      "|:-------------------------|:---------------------|:-------------|\n",
      "| Collaborate with Experts | AI Researcher        | 56           |\n",
      "| Collaborate with Experts | QA and Maintenance   | 46.15        |\n",
      "| Collaborate with Experts | Requirements analyst | 22           |\n",
      "| Collaborate with Experts | AI developers        | 20.38        |\n",
      "| Collaborate with Experts | AI Manager           | 16.9         |\n",
      "| Collaborate with Experts | Security/Privacy     | 7.69         |\n",
      "\n",
      "Strategy: Conduct Ethical and Privacy Impact Assessments\n",
      "\n",
      "| Mitigation Strategy                            | Role                 | Percentage   |\n",
      "|:-----------------------------------------------|:---------------------|:-------------|\n",
      "| Conduct Ethical and Privacy Impact Assessments | Other                | 50           |\n",
      "| Conduct Ethical and Privacy Impact Assessments | AI Manager           | 32.39        |\n",
      "| Conduct Ethical and Privacy Impact Assessments | QA and Maintenance   | 30.77        |\n",
      "| Conduct Ethical and Privacy Impact Assessments | AI developers        | 29.3         |\n",
      "| Conduct Ethical and Privacy Impact Assessments | AI Researcher        | 24           |\n",
      "| Conduct Ethical and Privacy Impact Assessments | Security/Privacy     | 15.38        |\n",
      "| Conduct Ethical and Privacy Impact Assessments | Requirements analyst | 8            |\n",
      "\n",
      "Strategy: Conduct Regular Audits and Assessments\n",
      "\n",
      "| Mitigation Strategy                    | Role                 | Percentage   |\n",
      "|:---------------------------------------|:---------------------|:-------------|\n",
      "| Conduct Regular Audits and Assessments | Other                | 100          |\n",
      "| Conduct Regular Audits and Assessments | AI Researcher        | 52           |\n",
      "| Conduct Regular Audits and Assessments | QA and Maintenance   | 46.15        |\n",
      "| Conduct Regular Audits and Assessments | Security/Privacy     | 46.15        |\n",
      "| Conduct Regular Audits and Assessments | AI Manager           | 45.07        |\n",
      "| Conduct Regular Audits and Assessments | Requirements analyst | 42           |\n",
      "| Conduct Regular Audits and Assessments | AI developers        | 41.4         |\n",
      "\n",
      "Strategy: Create Contingency Plans\n",
      "\n",
      "| Mitigation Strategy      | Role                 | Percentage   |\n",
      "|:-------------------------|:---------------------|:-------------|\n",
      "| Create Contingency Plans | Other                | 50           |\n",
      "| Create Contingency Plans | Requirements analyst | 36           |\n",
      "| Create Contingency Plans | QA and Maintenance   | 30.77        |\n",
      "| Create Contingency Plans | AI Manager           | 25.35        |\n",
      "| Create Contingency Plans | Security/Privacy     | 23.08        |\n",
      "| Create Contingency Plans | AI developers        | 21.66        |\n",
      "| Create Contingency Plans | AI Researcher        | 16           |\n",
      "\n",
      "Strategy: Develop Ethical Guidelines\n",
      "\n",
      "| Mitigation Strategy        | Role                 | Percentage   |\n",
      "|:---------------------------|:---------------------|:-------------|\n",
      "| Develop Ethical Guidelines | AI Researcher        | 60           |\n",
      "| Develop Ethical Guidelines | Other                | 50           |\n",
      "| Develop Ethical Guidelines | AI Manager           | 47.89        |\n",
      "| Develop Ethical Guidelines | QA and Maintenance   | 46.15        |\n",
      "| Develop Ethical Guidelines | AI developers        | 38.85        |\n",
      "| Develop Ethical Guidelines | Requirements analyst | 32           |\n",
      "| Develop Ethical Guidelines | Security/Privacy     | 15.38        |\n",
      "\n",
      "Strategy: Implement Feedback Mechanisms\n",
      "\n",
      "| Mitigation Strategy           | Role                 | Percentage   |\n",
      "|:------------------------------|:---------------------|:-------------|\n",
      "| Implement Feedback Mechanisms | Other                | 100          |\n",
      "| Implement Feedback Mechanisms | AI developers        | 31.85        |\n",
      "| Implement Feedback Mechanisms | QA and Maintenance   | 30.77        |\n",
      "| Implement Feedback Mechanisms | Requirements analyst | 26           |\n",
      "| Implement Feedback Mechanisms | AI Researcher        | 24           |\n",
      "| Implement Feedback Mechanisms | AI Manager           | 23.94        |\n",
      "| Implement Feedback Mechanisms | Security/Privacy     | 23.08        |\n",
      "\n",
      "Strategy: Implement Robust Security Measures\n",
      "\n",
      "| Mitigation Strategy                | Role                 | Percentage   |\n",
      "|:-----------------------------------|:---------------------|:-------------|\n",
      "| Implement Robust Security Measures | Security/Privacy     | 61.54        |\n",
      "| Implement Robust Security Measures | AI Manager           | 50.7         |\n",
      "| Implement Robust Security Measures | Other                | 50           |\n",
      "| Implement Robust Security Measures | AI Researcher        | 48           |\n",
      "| Implement Robust Security Measures | Requirements analyst | 40           |\n",
      "| Implement Robust Security Measures | AI developers        | 38.22        |\n",
      "| Implement Robust Security Measures | QA and Maintenance   | 30.77        |\n",
      "\n",
      "Strategy: Implement Transparent and Explainable Approaches\n",
      "\n",
      "| Mitigation Strategy                              | Role                 | Percentage   |\n",
      "|:-------------------------------------------------|:---------------------|:-------------|\n",
      "| Implement Transparent and Explainable Approaches | Other                | 100          |\n",
      "| Implement Transparent and Explainable Approaches | AI Manager           | 36.62        |\n",
      "| Implement Transparent and Explainable Approaches | AI Researcher        | 36           |\n",
      "| Implement Transparent and Explainable Approaches | AI developers        | 31.85        |\n",
      "| Implement Transparent and Explainable Approaches | Requirements analyst | 20           |\n",
      "| Implement Transparent and Explainable Approaches | QA and Maintenance   | 15.38        |\n",
      "| Implement Transparent and Explainable Approaches | Security/Privacy     | 7.69         |\n",
      "\n",
      "Strategy: Invest in Training and Education\n",
      "\n",
      "| Mitigation Strategy              | Role                 | Percentage   |\n",
      "|:---------------------------------|:---------------------|:-------------|\n",
      "| Invest in Training and Education | AI Researcher        | 60           |\n",
      "| Invest in Training and Education | AI Manager           | 54.93        |\n",
      "| Invest in Training and Education | Security/Privacy     | 53.85        |\n",
      "| Invest in Training and Education | Other                | 50           |\n",
      "| Invest in Training and Education | AI developers        | 40.76        |\n",
      "| Invest in Training and Education | QA and Maintenance   | 38.46        |\n",
      "| Invest in Training and Education | Requirements analyst | 38           |\n",
      "\n",
      "Strategy: Monitor AI System Performance\n",
      "\n",
      "| Mitigation Strategy           | Role                 | Percentage   |\n",
      "|:------------------------------|:---------------------|:-------------|\n",
      "| Monitor AI System Performance | QA and Maintenance   | 53.85        |\n",
      "| Monitor AI System Performance | AI developers        | 53.5         |\n",
      "| Monitor AI System Performance | Other                | 50           |\n",
      "| Monitor AI System Performance | Requirements analyst | 50           |\n",
      "| Monitor AI System Performance | AI Researcher        | 48           |\n",
      "| Monitor AI System Performance | Security/Privacy     | 46.15        |\n",
      "| Monitor AI System Performance | AI Manager           | 40.85        |\n",
      "\n",
      "Strategy: Open Design and Development of Models and Datasets\n",
      "\n",
      "| Mitigation Strategy                                | Role                 | Percentage   |\n",
      "|:---------------------------------------------------|:---------------------|:-------------|\n",
      "| Open Design and Development of Models and Datasets | Other                | 50           |\n",
      "| Open Design and Development of Models and Datasets | AI Researcher        | 36           |\n",
      "| Open Design and Development of Models and Datasets | AI Manager           | 26.76        |\n",
      "| Open Design and Development of Models and Datasets | AI developers        | 26.75        |\n",
      "| Open Design and Development of Models and Datasets | Requirements analyst | 20           |\n",
      "| Open Design and Development of Models and Datasets | Security/Privacy     | 15.38        |\n",
      "| Open Design and Development of Models and Datasets | QA and Maintenance   | 7.69         |\n",
      "\n",
      "Strategy: Others, please specify\n",
      "\n",
      "| Mitigation Strategy    | Role                 | Percentage   |\n",
      "|:-----------------------|:---------------------|:-------------|\n",
      "| Others, please specify | Requirements analyst | 6            |\n",
      "| Others, please specify | AI developers        | 1.27         |\n",
      "\n",
      "Strategy: Use AI Testing and Validation\n",
      "\n",
      "| Mitigation Strategy           | Role                 | Percentage   |\n",
      "|:------------------------------|:---------------------|:-------------|\n",
      "| Use AI Testing and Validation | QA and Maintenance   | 61.54        |\n",
      "| Use AI Testing and Validation | AI Researcher        | 60           |\n",
      "| Use AI Testing and Validation | AI developers        | 47.77        |\n",
      "| Use AI Testing and Validation | Security/Privacy     | 38.46        |\n",
      "| Use AI Testing and Validation | Requirements analyst | 36           |\n",
      "| Use AI Testing and Validation | AI Manager           | 32.39        |\n",
      "\n",
      "Strategy: Use or Implement Privacy Enhancing Tools or Measures\n",
      "\n",
      "| Mitigation Strategy                                  | Role                 | Percentage   |\n",
      "|:-----------------------------------------------------|:---------------------|:-------------|\n",
      "| Use or Implement Privacy Enhancing Tools or Measures | Other                | 50           |\n",
      "| Use or Implement Privacy Enhancing Tools or Measures | AI Manager           | 45.07        |\n",
      "| Use or Implement Privacy Enhancing Tools or Measures | AI Researcher        | 44           |\n",
      "| Use or Implement Privacy Enhancing Tools or Measures | Security/Privacy     | 38.46        |\n",
      "| Use or Implement Privacy Enhancing Tools or Measures | Requirements analyst | 38           |\n",
      "| Use or Implement Privacy Enhancing Tools or Measures | QA and Maintenance   | 30.77        |\n",
      "| Use or Implement Privacy Enhancing Tools or Measures | AI developers        | 29.94        |\n",
      "\n",
      "Overall Ranked Strategies for Role:\n",
      "\n",
      "1. Clean Data to Remove, Mitigate, or Minimize Biases: 54.05%\n",
      "2. Conduct Regular Audits and Assessments: 53.25%\n",
      "3. Monitor AI System Performance: 48.91%\n",
      "4. Invest in Training and Education: 48.00%\n",
      "5. Use AI Testing and Validation: 46.03%\n",
      "6. Implement Robust Security Measures: 45.60%\n",
      "7. Develop Ethical Guidelines: 41.47%\n",
      "8. Use or Implement Privacy Enhancing Tools or Measures: 39.46%\n",
      "9. Implement Feedback Mechanisms: 37.09%\n",
      "10. Implement Transparent and Explainable Approaches: 35.36%\n",
      "11. Adopt AI Governance Frameworks: 33.80%\n",
      "12. Create Contingency Plans: 28.98%\n",
      "13. Collaborate with Experts: 28.19%\n",
      "14. Conduct Ethical and Privacy Impact Assessments: 27.12%\n",
      "15. Open Design and Development of Models and Datasets: 26.08%\n",
      "16. Others, please specify: 3.63%\n",
      "\n",
      "Ranked Results for Education:\n",
      "\n",
      "\n",
      "Strategy: Adopt AI Governance Frameworks\n",
      "\n",
      "| Mitigation Strategy            | Education          | Percentage   |\n",
      "|:-------------------------------|:-------------------|:-------------|\n",
      "| Adopt AI Governance Frameworks | Other              | 40           |\n",
      "| Adopt AI Governance Frameworks | Bachelor's Degree  | 30.53        |\n",
      "| Adopt AI Governance Frameworks | Graduate Education | 30           |\n",
      "| Adopt AI Governance Frameworks | Ph.D.              | 19.35        |\n",
      "| Adopt AI Governance Frameworks | High School Degree | 9.09         |\n",
      "\n",
      "Strategy: Clean Data to Remove, Mitigate, or Minimize Biases\n",
      "\n",
      "| Mitigation Strategy                                | Education          | Percentage   |\n",
      "|:---------------------------------------------------|:-------------------|:-------------|\n",
      "| Clean Data to Remove, Mitigate, or Minimize Biases | Ph.D.              | 51.61        |\n",
      "| Clean Data to Remove, Mitigate, or Minimize Biases | Bachelor's Degree  | 51.15        |\n",
      "| Clean Data to Remove, Mitigate, or Minimize Biases | Graduate Education | 50           |\n",
      "| Clean Data to Remove, Mitigate, or Minimize Biases | Other              | 40           |\n",
      "| Clean Data to Remove, Mitigate, or Minimize Biases | High School Degree | 36.36        |\n",
      "\n",
      "Strategy: Collaborate with Experts\n",
      "\n",
      "| Mitigation Strategy      | Education          | Percentage   |\n",
      "|:-------------------------|:-------------------|:-------------|\n",
      "| Collaborate with Experts | Other              | 60           |\n",
      "| Collaborate with Experts | Ph.D.              | 32.26        |\n",
      "| Collaborate with Experts | Graduate Education | 23.75        |\n",
      "| Collaborate with Experts | Bachelor's Degree  | 19.85        |\n",
      "| Collaborate with Experts | High School Degree | 13.64        |\n",
      "\n",
      "Strategy: Conduct Ethical and Privacy Impact Assessments\n",
      "\n",
      "| Mitigation Strategy                            | Education          | Percentage   |\n",
      "|:-----------------------------------------------|:-------------------|:-------------|\n",
      "| Conduct Ethical and Privacy Impact Assessments | Bachelor's Degree  | 29.01        |\n",
      "| Conduct Ethical and Privacy Impact Assessments | Graduate Education | 28.12        |\n",
      "| Conduct Ethical and Privacy Impact Assessments | Ph.D.              | 22.58        |\n",
      "| Conduct Ethical and Privacy Impact Assessments | Other              | 20           |\n",
      "| Conduct Ethical and Privacy Impact Assessments | High School Degree | 9.09         |\n",
      "\n",
      "Strategy: Conduct Regular Audits and Assessments\n",
      "\n",
      "| Mitigation Strategy                    | Education          | Percentage   |\n",
      "|:---------------------------------------|:-------------------|:-------------|\n",
      "| Conduct Regular Audits and Assessments | Graduate Education | 47.5         |\n",
      "| Conduct Regular Audits and Assessments | Ph.D.              | 45.16        |\n",
      "| Conduct Regular Audits and Assessments | Bachelor's Degree  | 43.51        |\n",
      "| Conduct Regular Audits and Assessments | Other              | 40           |\n",
      "| Conduct Regular Audits and Assessments | High School Degree | 22.73        |\n",
      "\n",
      "Strategy: Create Contingency Plans\n",
      "\n",
      "| Mitigation Strategy      | Education          | Percentage   |\n",
      "|:-------------------------|:-------------------|:-------------|\n",
      "| Create Contingency Plans | Bachelor's Degree  | 29.77        |\n",
      "| Create Contingency Plans | Graduate Education | 23.75        |\n",
      "| Create Contingency Plans | Other              | 20           |\n",
      "| Create Contingency Plans | High School Degree | 18.18        |\n",
      "| Create Contingency Plans | Ph.D.              | 16.13        |\n",
      "\n",
      "Strategy: Develop Ethical Guidelines\n",
      "\n",
      "| Mitigation Strategy        | Education          | Percentage   |\n",
      "|:---------------------------|:-------------------|:-------------|\n",
      "| Develop Ethical Guidelines | Bachelor's Degree  | 48.85        |\n",
      "| Develop Ethical Guidelines | Ph.D.              | 48.39        |\n",
      "| Develop Ethical Guidelines | Other              | 40           |\n",
      "| Develop Ethical Guidelines | High School Degree | 36.36        |\n",
      "| Develop Ethical Guidelines | Graduate Education | 33.75        |\n",
      "\n",
      "Strategy: Implement Feedback Mechanisms\n",
      "\n",
      "| Mitigation Strategy           | Education          | Percentage   |\n",
      "|:------------------------------|:-------------------|:-------------|\n",
      "| Implement Feedback Mechanisms | Other              | 40           |\n",
      "| Implement Feedback Mechanisms | Bachelor's Degree  | 32.06        |\n",
      "| Implement Feedback Mechanisms | Graduate Education | 28.75        |\n",
      "| Implement Feedback Mechanisms | High School Degree | 18.18        |\n",
      "| Implement Feedback Mechanisms | Ph.D.              | 9.68         |\n",
      "\n",
      "Strategy: Implement Robust Security Measures\n",
      "\n",
      "| Mitigation Strategy                | Education          | Percentage   |\n",
      "|:-----------------------------------|:-------------------|:-------------|\n",
      "| Implement Robust Security Measures | Bachelor's Degree  | 48.09        |\n",
      "| Implement Robust Security Measures | Graduate Education | 41.25        |\n",
      "| Implement Robust Security Measures | Other              | 40           |\n",
      "| Implement Robust Security Measures | Ph.D.              | 32.26        |\n",
      "| Implement Robust Security Measures | High School Degree | 22.73        |\n",
      "\n",
      "Strategy: Implement Transparent and Explainable Approaches\n",
      "\n",
      "| Mitigation Strategy                              | Education          | Percentage   |\n",
      "|:-------------------------------------------------|:-------------------|:-------------|\n",
      "| Implement Transparent and Explainable Approaches | Ph.D.              | 41.94        |\n",
      "| Implement Transparent and Explainable Approaches | Bachelor's Degree  | 32.82        |\n",
      "| Implement Transparent and Explainable Approaches | Graduate Education | 26.25        |\n",
      "| Implement Transparent and Explainable Approaches | Other              | 20           |\n",
      "| Implement Transparent and Explainable Approaches | High School Degree | 13.64        |\n",
      "\n",
      "Strategy: Invest in Training and Education\n",
      "\n",
      "| Mitigation Strategy              | Education          | Percentage   |\n",
      "|:---------------------------------|:-------------------|:-------------|\n",
      "| Invest in Training and Education | Other              | 60           |\n",
      "| Invest in Training and Education | Ph.D.              | 48.39        |\n",
      "| Invest in Training and Education | Bachelor's Degree  | 48.09        |\n",
      "| Invest in Training and Education | High School Degree | 45.45        |\n",
      "| Invest in Training and Education | Graduate Education | 43.75        |\n",
      "\n",
      "Strategy: Monitor AI System Performance\n",
      "\n",
      "| Mitigation Strategy           | Education          | Percentage   |\n",
      "|:------------------------------|:-------------------|:-------------|\n",
      "| Monitor AI System Performance | Other              | 100          |\n",
      "| Monitor AI System Performance | Graduate Education | 50.62        |\n",
      "| Monitor AI System Performance | Bachelor's Degree  | 48.85        |\n",
      "| Monitor AI System Performance | Ph.D.              | 41.94        |\n",
      "| Monitor AI System Performance | High School Degree | 40.91        |\n",
      "\n",
      "Strategy: Open Design and Development of Models and Datasets\n",
      "\n",
      "| Mitigation Strategy                                | Education          | Percentage   |\n",
      "|:---------------------------------------------------|:-------------------|:-------------|\n",
      "| Open Design and Development of Models and Datasets | Ph.D.              | 35.48        |\n",
      "| Open Design and Development of Models and Datasets | Graduate Education | 25           |\n",
      "| Open Design and Development of Models and Datasets | Bachelor's Degree  | 24.43        |\n",
      "| Open Design and Development of Models and Datasets | Other              | 20           |\n",
      "| Open Design and Development of Models and Datasets | High School Degree | 9.09         |\n",
      "\n",
      "Strategy: Others, please specify\n",
      "\n",
      "| Mitigation Strategy    | Education          | Percentage   |\n",
      "|:-----------------------|:-------------------|:-------------|\n",
      "| Others, please specify | Graduate Education | 3.12         |\n",
      "\n",
      "Strategy: Use AI Testing and Validation\n",
      "\n",
      "| Mitigation Strategy           | Education          | Percentage   |\n",
      "|:------------------------------|:-------------------|:-------------|\n",
      "| Use AI Testing and Validation | Other              | 100          |\n",
      "| Use AI Testing and Validation | High School Degree | 54.55        |\n",
      "| Use AI Testing and Validation | Bachelor's Degree  | 48.85        |\n",
      "| Use AI Testing and Validation | Ph.D.              | 41.94        |\n",
      "| Use AI Testing and Validation | Graduate Education | 38.12        |\n",
      "\n",
      "Strategy: Use or Implement Privacy Enhancing Tools or Measures\n",
      "\n",
      "| Mitigation Strategy                                  | Education          | Percentage   |\n",
      "|:-----------------------------------------------------|:-------------------|:-------------|\n",
      "| Use or Implement Privacy Enhancing Tools or Measures | Bachelor's Degree  | 45.04        |\n",
      "| Use or Implement Privacy Enhancing Tools or Measures | Other              | 40           |\n",
      "| Use or Implement Privacy Enhancing Tools or Measures | Ph.D.              | 38.71        |\n",
      "| Use or Implement Privacy Enhancing Tools or Measures | High School Degree | 31.82        |\n",
      "| Use or Implement Privacy Enhancing Tools or Measures | Graduate Education | 30           |\n",
      "\n",
      "Overall Ranked Strategies for Education:\n",
      "\n",
      "1. Use AI Testing and Validation: 56.69%\n",
      "2. Monitor AI System Performance: 56.46%\n",
      "3. Invest in Training and Education: 49.14%\n",
      "4. Clean Data to Remove, Mitigate, or Minimize Biases: 45.82%\n",
      "5. Develop Ethical Guidelines: 41.47%\n",
      "6. Conduct Regular Audits and Assessments: 39.78%\n",
      "7. Use or Implement Privacy Enhancing Tools or Measures: 37.11%\n",
      "8. Implement Robust Security Measures: 36.87%\n",
      "9. Collaborate with Experts: 29.90%\n",
      "10. Implement Transparent and Explainable Approaches: 26.93%\n",
      "11. Adopt AI Governance Frameworks: 25.79%\n",
      "12. Implement Feedback Mechanisms: 25.73%\n",
      "13. Open Design and Development of Models and Datasets: 22.80%\n",
      "14. Conduct Ethical and Privacy Impact Assessments: 21.76%\n",
      "15. Create Contingency Plans: 21.57%\n",
      "16. Others, please specify: 3.12%\n",
      "\n",
      "Ranked Results for Dev Experience:\n",
      "\n",
      "\n",
      "Strategy: Adopt AI Governance Frameworks\n",
      "\n",
      "| Mitigation Strategy            | Dev Experience   | Percentage   |\n",
      "|:-------------------------------|:-----------------|:-------------|\n",
      "| Adopt AI Governance Frameworks | 5-10 Years       | 32.63        |\n",
      "| Adopt AI Governance Frameworks | 10+ Years        | 27.45        |\n",
      "| Adopt AI Governance Frameworks | 2-5 Years        | 24.85        |\n",
      "\n",
      "Strategy: Clean Data to Remove, Mitigate, or Minimize Biases\n",
      "\n",
      "| Mitigation Strategy                                | Dev Experience   | Percentage   |\n",
      "|:---------------------------------------------------|:-----------------|:-------------|\n",
      "| Clean Data to Remove, Mitigate, or Minimize Biases | 10+ Years        | 56.86        |\n",
      "| Clean Data to Remove, Mitigate, or Minimize Biases | 5-10 Years       | 49.47        |\n",
      "| Clean Data to Remove, Mitigate, or Minimize Biases | 2-5 Years        | 45.56        |\n",
      "\n",
      "Strategy: Collaborate with Experts\n",
      "\n",
      "| Mitigation Strategy      | Dev Experience   | Percentage   |\n",
      "|:-------------------------|:-----------------|:-------------|\n",
      "| Collaborate with Experts | 10+ Years        | 27.45        |\n",
      "| Collaborate with Experts | 5-10 Years       | 21.05        |\n",
      "| Collaborate with Experts | 2-5 Years        | 19.53        |\n",
      "\n",
      "Strategy: Conduct Ethical and Privacy Impact Assessments\n",
      "\n",
      "| Mitigation Strategy                            | Dev Experience   | Percentage   |\n",
      "|:-----------------------------------------------|:-----------------|:-------------|\n",
      "| Conduct Ethical and Privacy Impact Assessments | 5-10 Years       | 29.47        |\n",
      "| Conduct Ethical and Privacy Impact Assessments | 10+ Years        | 29.41        |\n",
      "| Conduct Ethical and Privacy Impact Assessments | 2-5 Years        | 26.04        |\n",
      "\n",
      "Strategy: Conduct Regular Audits and Assessments\n",
      "\n",
      "| Mitigation Strategy                    | Dev Experience   | Percentage   |\n",
      "|:---------------------------------------|:-----------------|:-------------|\n",
      "| Conduct Regular Audits and Assessments | 10+ Years        | 50.98        |\n",
      "| Conduct Regular Audits and Assessments | 5-10 Years       | 44.21        |\n",
      "| Conduct Regular Audits and Assessments | 2-5 Years        | 42.6         |\n",
      "\n",
      "Strategy: Create Contingency Plans\n",
      "\n",
      "| Mitigation Strategy      | Dev Experience   | Percentage   |\n",
      "|:-------------------------|:-----------------|:-------------|\n",
      "| Create Contingency Plans | 10+ Years        | 29.41        |\n",
      "| Create Contingency Plans | 5-10 Years       | 26.32        |\n",
      "| Create Contingency Plans | 2-5 Years        | 21.89        |\n",
      "\n",
      "Strategy: Develop Ethical Guidelines\n",
      "\n",
      "| Mitigation Strategy        | Dev Experience   | Percentage   |\n",
      "|:---------------------------|:-----------------|:-------------|\n",
      "| Develop Ethical Guidelines | 10+ Years        | 47.06        |\n",
      "| Develop Ethical Guidelines | 2-5 Years        | 39.05        |\n",
      "| Develop Ethical Guidelines | 5-10 Years       | 35.79        |\n",
      "\n",
      "Strategy: Implement Feedback Mechanisms\n",
      "\n",
      "| Mitigation Strategy           | Dev Experience   | Percentage   |\n",
      "|:------------------------------|:-----------------|:-------------|\n",
      "| Implement Feedback Mechanisms | 2-5 Years        | 29.59        |\n",
      "| Implement Feedback Mechanisms | 10+ Years        | 27.45        |\n",
      "| Implement Feedback Mechanisms | 5-10 Years       | 27.37        |\n",
      "\n",
      "Strategy: Implement Robust Security Measures\n",
      "\n",
      "| Mitigation Strategy                | Dev Experience   | Percentage   |\n",
      "|:-----------------------------------|:-----------------|:-------------|\n",
      "| Implement Robust Security Measures | 10+ Years        | 54.9         |\n",
      "| Implement Robust Security Measures | 5-10 Years       | 42.11        |\n",
      "| Implement Robust Security Measures | 2-5 Years        | 39.05        |\n",
      "\n",
      "Strategy: Implement Transparent and Explainable Approaches\n",
      "\n",
      "| Mitigation Strategy                              | Dev Experience   | Percentage   |\n",
      "|:-------------------------------------------------|:-----------------|:-------------|\n",
      "| Implement Transparent and Explainable Approaches | 10+ Years        | 35.29        |\n",
      "| Implement Transparent and Explainable Approaches | 2-5 Years        | 28.99        |\n",
      "| Implement Transparent and Explainable Approaches | 5-10 Years       | 26.32        |\n",
      "\n",
      "Strategy: Invest in Training and Education\n",
      "\n",
      "| Mitigation Strategy              | Dev Experience   | Percentage   |\n",
      "|:---------------------------------|:-----------------|:-------------|\n",
      "| Invest in Training and Education | 5-10 Years       | 49.47        |\n",
      "| Invest in Training and Education | 2-5 Years        | 45.56        |\n",
      "| Invest in Training and Education | 10+ Years        | 45.1         |\n",
      "\n",
      "Strategy: Monitor AI System Performance\n",
      "\n",
      "| Mitigation Strategy           | Dev Experience   | Percentage   |\n",
      "|:------------------------------|:-----------------|:-------------|\n",
      "| Monitor AI System Performance | 10+ Years        | 58.82        |\n",
      "| Monitor AI System Performance | 5-10 Years       | 49.47        |\n",
      "| Monitor AI System Performance | 2-5 Years        | 46.75        |\n",
      "\n",
      "Strategy: Open Design and Development of Models and Datasets\n",
      "\n",
      "| Mitigation Strategy                                | Dev Experience   | Percentage   |\n",
      "|:---------------------------------------------------|:-----------------|:-------------|\n",
      "| Open Design and Development of Models and Datasets | 10+ Years        | 37.25        |\n",
      "| Open Design and Development of Models and Datasets | 2-5 Years        | 22.49        |\n",
      "| Open Design and Development of Models and Datasets | 5-10 Years       | 20           |\n",
      "\n",
      "Strategy: Others, please specify\n",
      "\n",
      "| Mitigation Strategy    | Dev Experience   | Percentage   |\n",
      "|:-----------------------|:-----------------|:-------------|\n",
      "| Others, please specify | 5-10 Years       | 3.16         |\n",
      "| Others, please specify | 2-5 Years        | 1.18         |\n",
      "\n",
      "Strategy: Use AI Testing and Validation\n",
      "\n",
      "| Mitigation Strategy           | Dev Experience   | Percentage   |\n",
      "|:------------------------------|:-----------------|:-------------|\n",
      "| Use AI Testing and Validation | 10+ Years        | 62.75        |\n",
      "| Use AI Testing and Validation | 2-5 Years        | 42.01        |\n",
      "| Use AI Testing and Validation | 5-10 Years       | 35.79        |\n",
      "\n",
      "Strategy: Use or Implement Privacy Enhancing Tools or Measures\n",
      "\n",
      "| Mitigation Strategy                                  | Dev Experience   | Percentage   |\n",
      "|:-----------------------------------------------------|:-----------------|:-------------|\n",
      "| Use or Implement Privacy Enhancing Tools or Measures | 5-10 Years       | 37.89        |\n",
      "| Use or Implement Privacy Enhancing Tools or Measures | 2-5 Years        | 36.69        |\n",
      "| Use or Implement Privacy Enhancing Tools or Measures | 10+ Years        | 31.37        |\n",
      "\n",
      "Overall Ranked Strategies for Dev Experience:\n",
      "\n",
      "1. Monitor AI System Performance: 51.68%\n",
      "2. Clean Data to Remove, Mitigate, or Minimize Biases: 50.63%\n",
      "3. Use AI Testing and Validation: 46.85%\n",
      "4. Invest in Training and Education: 46.71%\n",
      "5. Conduct Regular Audits and Assessments: 45.93%\n",
      "6. Implement Robust Security Measures: 45.35%\n",
      "7. Develop Ethical Guidelines: 40.63%\n",
      "8. Use or Implement Privacy Enhancing Tools or Measures: 35.32%\n",
      "9. Implement Transparent and Explainable Approaches: 30.20%\n",
      "10. Adopt AI Governance Frameworks: 28.31%\n",
      "11. Conduct Ethical and Privacy Impact Assessments: 28.31%\n",
      "12. Implement Feedback Mechanisms: 28.14%\n",
      "13. Open Design and Development of Models and Datasets: 26.58%\n",
      "14. Create Contingency Plans: 25.87%\n",
      "15. Collaborate with Experts: 22.68%\n",
      "16. Others, please specify: 2.17%\n",
      "\n",
      "Ranked Results for Gender:\n",
      "\n",
      "\n",
      "Strategy: Adopt AI Governance Frameworks\n",
      "\n",
      "| Mitigation Strategy            | Gender                    | Percentage   |\n",
      "|:-------------------------------|:--------------------------|:-------------|\n",
      "| Adopt AI Governance Frameworks | Non-binary / Third gender | 50           |\n",
      "| Adopt AI Governance Frameworks | Female                    | 30.63        |\n",
      "| Adopt AI Governance Frameworks | Male                      | 25.94        |\n",
      "\n",
      "Strategy: Clean Data to Remove, Mitigate, or Minimize Biases\n",
      "\n",
      "| Mitigation Strategy                                | Gender   | Percentage   |\n",
      "|:---------------------------------------------------|:---------|:-------------|\n",
      "| Clean Data to Remove, Mitigate, or Minimize Biases | Male     | 50.63        |\n",
      "| Clean Data to Remove, Mitigate, or Minimize Biases | Female   | 47.75        |\n",
      "\n",
      "Strategy: Collaborate with Experts\n",
      "\n",
      "| Mitigation Strategy      | Gender                    | Percentage   |\n",
      "|:-------------------------|:--------------------------|:-------------|\n",
      "| Collaborate with Experts | Non-binary / Third gender | 50           |\n",
      "| Collaborate with Experts | Female                    | 25.23        |\n",
      "| Collaborate with Experts | Male                      | 21.34        |\n",
      "\n",
      "Strategy: Conduct Ethical and Privacy Impact Assessments\n",
      "\n",
      "| Mitigation Strategy                            | Gender                    | Percentage   |\n",
      "|:-----------------------------------------------|:--------------------------|:-------------|\n",
      "| Conduct Ethical and Privacy Impact Assessments | Non-binary / Third gender | 50           |\n",
      "| Conduct Ethical and Privacy Impact Assessments | Female                    | 34.23        |\n",
      "| Conduct Ethical and Privacy Impact Assessments | Male                      | 22.59        |\n",
      "\n",
      "Strategy: Conduct Regular Audits and Assessments\n",
      "\n",
      "| Mitigation Strategy                    | Gender   | Percentage   |\n",
      "|:---------------------------------------|:---------|:-------------|\n",
      "| Conduct Regular Audits and Assessments | Female   | 51.35        |\n",
      "| Conduct Regular Audits and Assessments | Male     | 41           |\n",
      "\n",
      "Strategy: Create Contingency Plans\n",
      "\n",
      "| Mitigation Strategy      | Gender                    | Percentage   |\n",
      "|:-------------------------|:--------------------------|:-------------|\n",
      "| Create Contingency Plans | Non-binary / Third gender | 50           |\n",
      "| Create Contingency Plans | Female                    | 26.13        |\n",
      "| Create Contingency Plans | Male                      | 23.43        |\n",
      "\n",
      "Strategy: Develop Ethical Guidelines\n",
      "\n",
      "| Mitigation Strategy        | Gender                    | Percentage   |\n",
      "|:---------------------------|:--------------------------|:-------------|\n",
      "| Develop Ethical Guidelines | Non-binary / Third gender | 50           |\n",
      "| Develop Ethical Guidelines | Female                    | 45.95        |\n",
      "| Develop Ethical Guidelines | Male                      | 38.91        |\n",
      "\n",
      "Strategy: Implement Feedback Mechanisms\n",
      "\n",
      "| Mitigation Strategy           | Gender                    | Percentage   |\n",
      "|:------------------------------|:--------------------------|:-------------|\n",
      "| Implement Feedback Mechanisms | Non-binary / Third gender | 50           |\n",
      "| Implement Feedback Mechanisms | Male                      | 27.62        |\n",
      "| Implement Feedback Mechanisms | Female                    | 27.03        |\n",
      "\n",
      "Strategy: Implement Robust Security Measures\n",
      "\n",
      "| Mitigation Strategy                | Gender   | Percentage   |\n",
      "|:-----------------------------------|:---------|:-------------|\n",
      "| Implement Robust Security Measures | Female   | 46.85        |\n",
      "| Implement Robust Security Measures | Male     | 39.33        |\n",
      "\n",
      "Strategy: Implement Transparent and Explainable Approaches\n",
      "\n",
      "| Mitigation Strategy                              | Gender                    | Percentage   |\n",
      "|:-------------------------------------------------|:--------------------------|:-------------|\n",
      "| Implement Transparent and Explainable Approaches | Non-binary / Third gender | 50           |\n",
      "| Implement Transparent and Explainable Approaches | Female                    | 35.14        |\n",
      "| Implement Transparent and Explainable Approaches | Male                      | 26.78        |\n",
      "\n",
      "Strategy: Invest in Training and Education\n",
      "\n",
      "| Mitigation Strategy              | Gender   | Percentage   |\n",
      "|:---------------------------------|:---------|:-------------|\n",
      "| Invest in Training and Education | Female   | 50.45        |\n",
      "| Invest in Training and Education | Male     | 44.77        |\n",
      "\n",
      "Strategy: Monitor AI System Performance\n",
      "\n",
      "| Mitigation Strategy           | Gender                    | Percentage   |\n",
      "|:------------------------------|:--------------------------|:-------------|\n",
      "| Monitor AI System Performance | Female                    | 52.25        |\n",
      "| Monitor AI System Performance | Non-binary / Third gender | 50           |\n",
      "| Monitor AI System Performance | Male                      | 46.86        |\n",
      "\n",
      "Strategy: Open Design and Development of Models and Datasets\n",
      "\n",
      "| Mitigation Strategy                                | Gender   | Percentage   |\n",
      "|:---------------------------------------------------|:---------|:-------------|\n",
      "| Open Design and Development of Models and Datasets | Female   | 27.03        |\n",
      "| Open Design and Development of Models and Datasets | Male     | 23.43        |\n",
      "\n",
      "Strategy: Others, please specify\n",
      "\n",
      "| Mitigation Strategy    | Gender   | Percentage   |\n",
      "|:-----------------------|:---------|:-------------|\n",
      "| Others, please specify | Female   | 3.6          |\n",
      "| Others, please specify | Male     | 0.42         |\n",
      "\n",
      "Strategy: Use AI Testing and Validation\n",
      "\n",
      "| Mitigation Strategy           | Gender   | Percentage   |\n",
      "|:------------------------------|:---------|:-------------|\n",
      "| Use AI Testing and Validation | Male     | 47.28        |\n",
      "| Use AI Testing and Validation | Female   | 38.74        |\n",
      "\n",
      "Strategy: Use or Implement Privacy Enhancing Tools or Measures\n",
      "\n",
      "| Mitigation Strategy                                  | Gender                    | Percentage   |\n",
      "|:-----------------------------------------------------|:--------------------------|:-------------|\n",
      "| Use or Implement Privacy Enhancing Tools or Measures | Non-binary / Third gender | 50           |\n",
      "| Use or Implement Privacy Enhancing Tools or Measures | Female                    | 40.54        |\n",
      "| Use or Implement Privacy Enhancing Tools or Measures | Male                      | 35.15        |\n",
      "\n",
      "Overall Ranked Strategies for Gender:\n",
      "\n",
      "1. Monitor AI System Performance: 49.70%\n",
      "2. Clean Data to Remove, Mitigate, or Minimize Biases: 49.19%\n",
      "3. Invest in Training and Education: 47.61%\n",
      "4. Conduct Regular Audits and Assessments: 46.17%\n",
      "5. Develop Ethical Guidelines: 44.95%\n",
      "6. Implement Robust Security Measures: 43.09%\n",
      "7. Use AI Testing and Validation: 43.01%\n",
      "8. Use or Implement Privacy Enhancing Tools or Measures: 41.90%\n",
      "9. Implement Transparent and Explainable Approaches: 37.31%\n",
      "10. Conduct Ethical and Privacy Impact Assessments: 35.61%\n",
      "11. Adopt AI Governance Frameworks: 35.52%\n",
      "12. Implement Feedback Mechanisms: 34.88%\n",
      "13. Create Contingency Plans: 33.19%\n",
      "14. Collaborate with Experts: 32.19%\n",
      "15. Open Design and Development of Models and Datasets: 25.23%\n",
      "16. Others, please specify: 2.01%\n",
      "\n",
      "Ranked Results for Company Size:\n",
      "\n",
      "\n",
      "Strategy: Adopt AI Governance Frameworks\n",
      "\n",
      "| Mitigation Strategy            | Company Size     | Percentage   |\n",
      "|:-------------------------------|:-----------------|:-------------|\n",
      "| Adopt AI Governance Frameworks | 51-100 Employees | 32.14        |\n",
      "| Adopt AI Governance Frameworks | 100+ Employees   | 31.16        |\n",
      "| Adopt AI Governance Frameworks | 6-20 Employees   | 28.07        |\n",
      "| Adopt AI Governance Frameworks | 21-50 Employees  | 23.29        |\n",
      "| Adopt AI Governance Frameworks | 1-5 Employees    | 8.33         |\n",
      "\n",
      "Strategy: Clean Data to Remove, Mitigate, or Minimize Biases\n",
      "\n",
      "| Mitigation Strategy                                | Company Size     | Percentage   |\n",
      "|:---------------------------------------------------|:-----------------|:-------------|\n",
      "| Clean Data to Remove, Mitigate, or Minimize Biases | 100+ Employees   | 66.67        |\n",
      "| Clean Data to Remove, Mitigate, or Minimize Biases | 51-100 Employees | 42.86        |\n",
      "| Clean Data to Remove, Mitigate, or Minimize Biases | 6-20 Employees   | 38.6         |\n",
      "| Clean Data to Remove, Mitigate, or Minimize Biases | 1-5 Employees    | 37.5         |\n",
      "| Clean Data to Remove, Mitigate, or Minimize Biases | 21-50 Employees  | 35.62        |\n",
      "\n",
      "Strategy: Collaborate with Experts\n",
      "\n",
      "| Mitigation Strategy      | Company Size     | Percentage   |\n",
      "|:-------------------------|:-----------------|:-------------|\n",
      "| Collaborate with Experts | 100+ Employees   | 30.43        |\n",
      "| Collaborate with Experts | 6-20 Employees   | 24.56        |\n",
      "| Collaborate with Experts | 21-50 Employees  | 17.81        |\n",
      "| Collaborate with Experts | 1-5 Employees    | 16.67        |\n",
      "| Collaborate with Experts | 51-100 Employees | 14.29        |\n",
      "\n",
      "Strategy: Conduct Ethical and Privacy Impact Assessments\n",
      "\n",
      "| Mitigation Strategy                            | Company Size     | Percentage   |\n",
      "|:-----------------------------------------------|:-----------------|:-------------|\n",
      "| Conduct Ethical and Privacy Impact Assessments | 51-100 Employees | 35.71        |\n",
      "| Conduct Ethical and Privacy Impact Assessments | 6-20 Employees   | 28.07        |\n",
      "| Conduct Ethical and Privacy Impact Assessments | 100+ Employees   | 26.81        |\n",
      "| Conduct Ethical and Privacy Impact Assessments | 21-50 Employees  | 21.92        |\n",
      "| Conduct Ethical and Privacy Impact Assessments | 1-5 Employees    | 12.5         |\n",
      "\n",
      "Strategy: Conduct Regular Audits and Assessments\n",
      "\n",
      "| Mitigation Strategy                    | Company Size     | Percentage   |\n",
      "|:---------------------------------------|:-----------------|:-------------|\n",
      "| Conduct Regular Audits and Assessments | 51-100 Employees | 67.86        |\n",
      "| Conduct Regular Audits and Assessments | 100+ Employees   | 48.55        |\n",
      "| Conduct Regular Audits and Assessments | 6-20 Employees   | 36.84        |\n",
      "| Conduct Regular Audits and Assessments | 21-50 Employees  | 31.51        |\n",
      "| Conduct Regular Audits and Assessments | 1-5 Employees    | 20.83        |\n",
      "\n",
      "Strategy: Create Contingency Plans\n",
      "\n",
      "| Mitigation Strategy      | Company Size     | Percentage   |\n",
      "|:-------------------------|:-----------------|:-------------|\n",
      "| Create Contingency Plans | 51-100 Employees | 33.93        |\n",
      "| Create Contingency Plans | 21-50 Employees  | 30.14        |\n",
      "| Create Contingency Plans | 1-5 Employees    | 25           |\n",
      "| Create Contingency Plans | 6-20 Employees   | 21.05        |\n",
      "| Create Contingency Plans | 100+ Employees   | 19.57        |\n",
      "\n",
      "Strategy: Develop Ethical Guidelines\n",
      "\n",
      "| Mitigation Strategy        | Company Size     | Percentage   |\n",
      "|:---------------------------|:-----------------|:-------------|\n",
      "| Develop Ethical Guidelines | 100+ Employees   | 48.55        |\n",
      "| Develop Ethical Guidelines | 6-20 Employees   | 38.6         |\n",
      "| Develop Ethical Guidelines | 21-50 Employees  | 38.36        |\n",
      "| Develop Ethical Guidelines | 51-100 Employees | 35.71        |\n",
      "| Develop Ethical Guidelines | 1-5 Employees    | 29.17        |\n",
      "\n",
      "Strategy: Implement Feedback Mechanisms\n",
      "\n",
      "| Mitigation Strategy           | Company Size     | Percentage   |\n",
      "|:------------------------------|:-----------------|:-------------|\n",
      "| Implement Feedback Mechanisms | 100+ Employees   | 32.61        |\n",
      "| Implement Feedback Mechanisms | 21-50 Employees  | 30.14        |\n",
      "| Implement Feedback Mechanisms | 6-20 Employees   | 24.56        |\n",
      "| Implement Feedback Mechanisms | 1-5 Employees    | 20.83        |\n",
      "| Implement Feedback Mechanisms | 51-100 Employees | 19.64        |\n",
      "\n",
      "Strategy: Implement Robust Security Measures\n",
      "\n",
      "| Mitigation Strategy                | Company Size     | Percentage   |\n",
      "|:-----------------------------------|:-----------------|:-------------|\n",
      "| Implement Robust Security Measures | 51-100 Employees | 50           |\n",
      "| Implement Robust Security Measures | 21-50 Employees  | 49.32        |\n",
      "| Implement Robust Security Measures | 100+ Employees   | 39.86        |\n",
      "| Implement Robust Security Measures | 6-20 Employees   | 36.84        |\n",
      "| Implement Robust Security Measures | 1-5 Employees    | 25           |\n",
      "\n",
      "Strategy: Implement Transparent and Explainable Approaches\n",
      "\n",
      "| Mitigation Strategy                              | Company Size     | Percentage   |\n",
      "|:-------------------------------------------------|:-----------------|:-------------|\n",
      "| Implement Transparent and Explainable Approaches | 100+ Employees   | 31.16        |\n",
      "| Implement Transparent and Explainable Approaches | 21-50 Employees  | 30.14        |\n",
      "| Implement Transparent and Explainable Approaches | 6-20 Employees   | 28.07        |\n",
      "| Implement Transparent and Explainable Approaches | 51-100 Employees | 26.79        |\n",
      "| Implement Transparent and Explainable Approaches | 1-5 Employees    | 25           |\n",
      "\n",
      "Strategy: Invest in Training and Education\n",
      "\n",
      "| Mitigation Strategy              | Company Size     | Percentage   |\n",
      "|:---------------------------------|:-----------------|:-------------|\n",
      "| Invest in Training and Education | 100+ Employees   | 55.8         |\n",
      "| Invest in Training and Education | 51-100 Employees | 48.21        |\n",
      "| Invest in Training and Education | 6-20 Employees   | 42.11        |\n",
      "| Invest in Training and Education | 21-50 Employees  | 38.36        |\n",
      "| Invest in Training and Education | 1-5 Employees    | 20.83        |\n",
      "\n",
      "Strategy: Monitor AI System Performance\n",
      "\n",
      "| Mitigation Strategy           | Company Size     | Percentage   |\n",
      "|:------------------------------|:-----------------|:-------------|\n",
      "| Monitor AI System Performance | 100+ Employees   | 55.8         |\n",
      "| Monitor AI System Performance | 21-50 Employees  | 47.95        |\n",
      "| Monitor AI System Performance | 51-100 Employees | 44.64        |\n",
      "| Monitor AI System Performance | 6-20 Employees   | 43.86        |\n",
      "| Monitor AI System Performance | 1-5 Employees    | 33.33        |\n",
      "\n",
      "Strategy: Open Design and Development of Models and Datasets\n",
      "\n",
      "| Mitigation Strategy                                | Company Size     | Percentage   |\n",
      "|:---------------------------------------------------|:-----------------|:-------------|\n",
      "| Open Design and Development of Models and Datasets | 51-100 Employees | 32.14        |\n",
      "| Open Design and Development of Models and Datasets | 100+ Employees   | 25.36        |\n",
      "| Open Design and Development of Models and Datasets | 21-50 Employees  | 23.29        |\n",
      "| Open Design and Development of Models and Datasets | 6-20 Employees   | 22.81        |\n",
      "| Open Design and Development of Models and Datasets | 1-5 Employees    | 16.67        |\n",
      "\n",
      "Strategy: Others, please specify\n",
      "\n",
      "| Mitigation Strategy    | Company Size    | Percentage   |\n",
      "|:-----------------------|:----------------|:-------------|\n",
      "| Others, please specify | 6-20 Employees  | 3.51         |\n",
      "| Others, please specify | 21-50 Employees | 2.74         |\n",
      "| Others, please specify | 100+ Employees  | 0.72         |\n",
      "\n",
      "Strategy: Use AI Testing and Validation\n",
      "\n",
      "| Mitigation Strategy           | Company Size     | Percentage   |\n",
      "|:------------------------------|:-----------------|:-------------|\n",
      "| Use AI Testing and Validation | 100+ Employees   | 54.35        |\n",
      "| Use AI Testing and Validation | 1-5 Employees    | 45.83        |\n",
      "| Use AI Testing and Validation | 51-100 Employees | 42.86        |\n",
      "| Use AI Testing and Validation | 6-20 Employees   | 38.6         |\n",
      "| Use AI Testing and Validation | 21-50 Employees  | 32.88        |\n",
      "\n",
      "Strategy: Use or Implement Privacy Enhancing Tools or Measures\n",
      "\n",
      "| Mitigation Strategy                                  | Company Size     | Percentage   |\n",
      "|:-----------------------------------------------------|:-----------------|:-------------|\n",
      "| Use or Implement Privacy Enhancing Tools or Measures | 1-5 Employees    | 54.17        |\n",
      "| Use or Implement Privacy Enhancing Tools or Measures | 6-20 Employees   | 38.6         |\n",
      "| Use or Implement Privacy Enhancing Tools or Measures | 100+ Employees   | 36.96        |\n",
      "| Use or Implement Privacy Enhancing Tools or Measures | 21-50 Employees  | 35.62        |\n",
      "| Use or Implement Privacy Enhancing Tools or Measures | 51-100 Employees | 28.57        |\n",
      "\n",
      "Overall Ranked Strategies for Company Size:\n",
      "\n",
      "1. Monitor AI System Performance: 45.12%\n",
      "2. Clean Data to Remove, Mitigate, or Minimize Biases: 44.25%\n",
      "3. Use AI Testing and Validation: 42.90%\n",
      "4. Conduct Regular Audits and Assessments: 41.12%\n",
      "5. Invest in Training and Education: 41.06%\n",
      "6. Implement Robust Security Measures: 40.20%\n",
      "7. Use or Implement Privacy Enhancing Tools or Measures: 38.78%\n",
      "8. Develop Ethical Guidelines: 38.08%\n",
      "9. Implement Transparent and Explainable Approaches: 28.23%\n",
      "10. Create Contingency Plans: 25.94%\n",
      "11. Implement Feedback Mechanisms: 25.56%\n",
      "12. Conduct Ethical and Privacy Impact Assessments: 25.00%\n",
      "13. Adopt AI Governance Frameworks: 24.60%\n",
      "14. Open Design and Development of Models and Datasets: 24.05%\n",
      "15. Collaborate with Experts: 20.75%\n",
      "16. Others, please specify: 2.32%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Define file path\n",
    "file_path = 'AI_Study_Accepted.csv'\n",
    "\n",
    "# Demographic columns and their mappings (using column numbers)\n",
    "demographics = {\n",
    "    'Location': {\n",
    "        'column': 28,  # Column number for Location\n",
    "        'mapping': {\n",
    "            'North America': 'US',\n",
    "            'Central/South America': 'Other',\n",
    "            'EU/UK/EEA': 'Europe',\n",
    "            'Europe - Outside of EU/UK/EEA': 'Europe',\n",
    "            'Africa': 'Other',\n",
    "            'Middle East': 'Other',\n",
    "            'Asia': 'Other',\n",
    "            'Australia and Oceania': 'Other',\n",
    "            'Prefer not to say': 'Other',\n",
    "            'Other, please specify': 'Other'\n",
    "        }\n",
    "    },\n",
    "    'Company Type': {\n",
    "        'column': 26,  # Column number for Company Type\n",
    "        'mapping': {\n",
    "            'Multi-national Corporate': 'Multi-national',\n",
    "            'Startup/Small Business': 'Startup/Small',\n",
    "            'Academic Institution/Research Center': 'Academic/Research',\n",
    "            'Government': 'Government',\n",
    "            'Individual': 'Other',\n",
    "            'Other, please specify': 'Other'\n",
    "        }\n",
    "    },\n",
    "    'Role': {\n",
    "        'column': 30,  # Column number for Role\n",
    "        'mapping': {\n",
    "            'Administrative role (CEO, Chief Technical Officer, Chief Operating Officer, Chief Information Officer)': 'AI Manager',\n",
    "            'AI Manager': 'AI Manager',\n",
    "            'Requirements Analyst or Engineer': 'Requirements analyst',\n",
    "            'Scrum Master, Product Manager, or Project Manager': 'Requirements analyst',\n",
    "            'AI Engineer or Developer': 'AI developers',\n",
    "            '(Software) Developer, Designer, or Architect': 'AI developers',\n",
    "            'Data Scientist or Data Analyst': 'AI developers',\n",
    "            'Information Security Analyst or Engineer': 'Security/Privacy',\n",
    "            'Information Privacy Analyst or Engineer': 'Security/Privacy',\n",
    "            'AI Ethicist': 'Other',\n",
    "            'AI Researcher': 'AI Researcher',\n",
    "            '(Software) Quality Assurance Engineer or Tester': 'QA and Maintenance',\n",
    "            'Other, please specify': 'Other'\n",
    "        }\n",
    "    },\n",
    "    'Education': {\n",
    "        'column': 21,  # Column number for Education\n",
    "        'mapping': {\n",
    "            \"High School Degree\": \"High School Degree\",\n",
    "            \"Bachelor's Degree\": \"Bachelor's Degree\",\n",
    "            \"Master's Degree (i.e., MSc., M.A., etc.)\": \"Graduate Education\",\n",
    "            \"MBA (Master of Business Administration)\": \"Graduate Education\",\n",
    "            \"Graduate Certificates\": \"Graduate Education\",\n",
    "            \"Ph.D.\": \"Ph.D.\",\n",
    "            \"Other, please specify\": \"Other\"\n",
    "        }\n",
    "    },\n",
    "    'Dev Experience': {\n",
    "        'column': 32,  # Column number for Dev Experience\n",
    "        'mapping': {\n",
    "            'None': 'None',\n",
    "            '1-2 Years': '1-2 Years',\n",
    "            '2-5 Years': '2-5 Years',\n",
    "            '5-10 Years': '5-10 Years',\n",
    "            '10+ Years': '10+ Years'\n",
    "        }\n",
    "    },\n",
    "    'Gender': {\n",
    "        'column': 19,  # Column number for Gender\n",
    "        'mapping': {  # No predefined mapping for gender; use unique values directly\n",
    "            'Male': 'Male',\n",
    "            'Female': 'Female',\n",
    "            'Non-binary / Third gender': 'Non-binary / Third gender',\n",
    "            'Prefer not to say': 'Prefer not to say',\n",
    "            'Other, please specify': 'Other'\n",
    "        }\n",
    "    },\n",
    "    'Company Size': {\n",
    "        'column': 25,  # Column number for Company Size\n",
    "        'mapping': {\n",
    "            '1-5 Employees': '1-5 Employees',\n",
    "            '6-20 Employees': '6-20 Employees',\n",
    "            '21-50 Employees': '21-50 Employees',\n",
    "            '51-100 Employees': '51-100 Employees',\n",
    "            '101+ Employees': '100+ Employees'\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "def read_and_clean_csv(file_path):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, encoding='utf-8')\n",
    "        print(f\"Successfully read {file_path}.\")\n",
    "        return df\n",
    "    except UnicodeDecodeError:\n",
    "        print(f\"Failed to read {file_path} with utf-8 encoding.\")\n",
    "        return None\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        return None\n",
    "\n",
    "def process_data(df, demographic):\n",
    "    if demographics[demographic]['mapping']:\n",
    "        categories = set(demographics[demographic]['mapping'].values())\n",
    "        df['GroupedCategory'] = df.iloc[:, demographics[demographic]['column']].map(demographics[demographic]['mapping'])\n",
    "    else:\n",
    "        categories = df.iloc[:, demographics[demographic]['column']].dropna().unique()\n",
    "        df['GroupedCategory'] = df.iloc[:, demographics[demographic]['column']]\n",
    "\n",
    "    all_results = {}\n",
    "\n",
    "    for category in categories:\n",
    "        df_category = df[df['GroupedCategory'] == category]\n",
    "\n",
    "        # Step 2: Exclude the first two rows\n",
    "        df_category = df_category.iloc[2:]\n",
    "\n",
    "        # Function to split responses and merge specific categories\n",
    "        def split_and_merge_responses(response):\n",
    "            if pd.isna(response):\n",
    "                return []\n",
    "            response = response.replace(\"Clean Data to Remove, Mitigate, or Minimize Biases\", \"Clean Data to Remove Mitigate or Minimize Biases\")\n",
    "            response = response.replace(\"Others, please specify\", \"Others please specify\")\n",
    "            parts = [part.strip() for part in response.split(',')]\n",
    "            parts = [part.replace(\"Clean Data to Remove Mitigate or Minimize Biases\", \"Clean Data to Remove, Mitigate, or Minimize Biases\") for part in parts]\n",
    "            parts = [part.replace(\"Others please specify\", \"Others, please specify\") for part in parts]\n",
    "            return parts\n",
    "\n",
    "        # Step 3: Process the responses using the split_and_merge_responses function\n",
    "        df_category['B.2.5'] = df_category['B.2.5'].apply(split_and_merge_responses)\n",
    "\n",
    "        # Step 4: Flatten the list of responses and count occurrences\n",
    "        all_responses = df_category['B.2.5'].explode().dropna().value_counts().reset_index()\n",
    "        all_responses.columns = ['Mitigation Strategy', 'Count']\n",
    "\n",
    "        # Step 5: Calculate total number of valid responses (rows with non-empty lists)\n",
    "        total_valid_responses = df_category[df_category['B.2.5'].apply(len) > 0].shape[0]\n",
    "\n",
    "        # Step 6: Calculate the percentage of rows that mention each strategy\n",
    "        all_responses['Percentage'] = (all_responses['Count'] / total_valid_responses * 100).round(2)\n",
    "\n",
    "        all_results[category] = all_responses\n",
    "\n",
    "    # Combine and rank results\n",
    "    combined_results = pd.concat(all_results, names=[demographic, 'Category'])\n",
    "    combined_results = combined_results.reset_index()\n",
    "\n",
    "    ranked_results = combined_results.groupby(['Mitigation Strategy', demographic])['Percentage'].mean().reset_index()\n",
    "    ranked_results = ranked_results.sort_values(by=['Mitigation Strategy', 'Percentage'], ascending=[True, False])\n",
    "\n",
    "    return ranked_results\n",
    "\n",
    "# Main execution\n",
    "df = read_and_clean_csv(file_path)\n",
    "if df is not None:\n",
    "    print(df.columns)  # Print the columns for debugging\n",
    "\n",
    "    for demographic in demographics:\n",
    "        ranked_results = process_data(df, demographic)\n",
    "\n",
    "        # --- Print ranked results for all strategies ---\n",
    "        print(f\"\\nRanked Results for {demographic}:\\n\")\n",
    "        for strategy in ranked_results['Mitigation Strategy'].unique():\n",
    "            strategy_results = ranked_results[ranked_results['Mitigation Strategy'] == strategy]\n",
    "            print(f\"\\nStrategy: {strategy}\\n\")\n",
    "            print(strategy_results.to_markdown(index=False, numalign=\"left\", stralign=\"left\"))\n",
    "\n",
    "        # --- Print overall ranked strategies for the demographic ---\n",
    "        print(f\"\\nOverall Ranked Strategies for {demographic}:\\n\")\n",
    "        overall_ranking = ranked_results.groupby('Mitigation Strategy')['Percentage'].mean().sort_values(ascending=False)\n",
    "        for i, (strategy, percentage) in enumerate(overall_ranking.items()):\n",
    "            print(f\"{i+1}. {strategy}: {percentage:.2f}%\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B.9.1 Effectiveness of AI Ethics Principles Integration\n",
      "Total respondents: 65\n",
      "Breakdown of responses: Moderately Effectively: 19 responses (29.23%), Extremely Effectively: 19 responses (29.23%), Somewhat Effectively: 17 responses (26.15%), Moderately Ineffectively: 6 responses (9.23%), Extremely Ineffectively: 3 responses (4.62%), Prefer not to say: 1 responses (1.54%)\n",
      "Total mentions across all effectiveness levels: 65, Average mentions per effectiveness level: 10.83, Most common response: Moderately Effectively (19 mentions, 29.23% of respondents), Least common response: Prefer not to say (1 mentions, 1.54% of respondents)\n"
     ]
    }
   ],
   "source": [
    "####################\n",
    "# B.9.1\n",
    "####################\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Step 1: Read CSV file into a DataFrame\n",
    "df = pd.read_csv(ai_study)\n",
    "\n",
    "# Step 2: Exclude the first two rows\n",
    "df = df.iloc[2:]\n",
    "\n",
    "# Step 3: Remove NaNs or empty values in 'B.9.1'\n",
    "df = df[df['B.9.1'].notna()]  # Remove NaNs\n",
    "df['B.9.1'] = df['B.9.1'].astype(str).apply(lambda x: x.strip())\n",
    "df = df[df['B.9.1'] != \"\"]  # Remove empty strings\n",
    "\n",
    "# Step 4: Count occurrences of each response\n",
    "response_counts = df['B.9.1'].value_counts().reset_index()\n",
    "response_counts.columns = ['Response', 'Count']\n",
    "\n",
    "# Step 5: Calculate total number of valid responses\n",
    "total_valid_responses = df.shape[0]\n",
    "\n",
    "# Step 6: Calculate the percentage of each option based on valid responses\n",
    "response_counts['Percentage'] = (response_counts['Count'] / total_valid_responses * 100).round(2)\n",
    "\n",
    "# Step 7: Visualize the results with a Pie Chart using Plotly\n",
    "fig = px.pie(response_counts, names='Response', values='Count',\n",
    "             title='B.9.1 Effectiveness of AI Ethics Principles Integration',\n",
    "             color_discrete_sequence=px.colors.sequential.RdBu,\n",
    "             labels={'Response': 'Effectiveness Level', 'Count': 'Number of Responses'})\n",
    "\n",
    "# Add percentage text to the pie slices\n",
    "fig.update_traces(textposition='inside', textinfo='percent+label')\n",
    "\n",
    "# Step 8: Show the figure\n",
    "fig.show(renderer=\"browser\")\n",
    "\n",
    "# Step 9: Generate a statistical report\n",
    "print(\"B.9.1 Effectiveness of AI Ethics Principles Integration\")\n",
    "\n",
    "print(f\"Total respondents: {total_valid_responses}\")\n",
    "print(\"Breakdown of responses:\", end=\" \")\n",
    "print(\", \".join([f\"{row['Response']}: {row['Count']} responses ({row['Percentage']}%)\" for _, row in response_counts.iterrows()]))\n",
    "\n",
    "# Calculate additional statistics\n",
    "total_mentions = response_counts['Count'].sum()\n",
    "average_mentions = total_mentions / len(response_counts)\n",
    "most_common = response_counts.iloc[0]\n",
    "least_common = response_counts.iloc[-1]\n",
    "\n",
    "print(f\"Total mentions across all effectiveness levels: {total_mentions}, \", end=\"\")\n",
    "print(f\"Average mentions per effectiveness level: {average_mentions:.2f}, \", end=\"\")\n",
    "print(f\"Most common response: {most_common['Response']} ({most_common['Count']} mentions, {most_common['Percentage']}% of respondents), \", end=\"\")\n",
    "print(f\"Least common response: {least_common['Response']} ({least_common['Count']} mentions, {least_common['Percentage']}% of respondents)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B.9.2 Which of the following actions has your company taken to promote ethical practices in AI? Select all that apply.\n",
      "Total respondents: 64\n",
      "Breakdown of responses: Provided AI ethics training for employees: 40 mentions (62.5% of respondents), Implemented ethical guidelines for AI development and deployment: 37 mentions (57.81% of respondents), Established an AI ethics committee: 35 mentions (54.69% of respondents), Engages with external experts on AI ethics: 34 mentions (53.12% of respondents), Regularly audits AI systems for ethical compliance: 32 mentions (50.0% of respondents), Prefer not to say: 3 mentions (4.69% of respondents)\n",
      "Total mentions across all actions: 181, Average mentions per action: 30.17, Most common action: Provided AI ethics training for employees (40 mentions, 62.5% of respondents), Least common action: Prefer not to say (3 mentions, 4.69% of respondents)\n"
     ]
    }
   ],
   "source": [
    "####################\n",
    "# B.9.2\n",
    "####################\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Step 1: Read CSV file into a DataFrame\n",
    "df = pd.read_csv(ai_study)\n",
    "\n",
    "# Step 2: Exclude the first two rows\n",
    "df = df.iloc[2:]\n",
    "\n",
    "# Function to split responses and merge specific categories\n",
    "def split_and_merge_responses(response):\n",
    "    if pd.isna(response):\n",
    "        return []\n",
    "    parts = [part.strip() for part in str(response).split(',')]\n",
    "    return parts\n",
    "\n",
    "# Step 3: Process the responses using the split_and_merge_responses function\n",
    "df['B.9.2'] = df['B.9.2'].apply(split_and_merge_responses)\n",
    "\n",
    "# Step 4: Flatten the list of responses and count occurrences\n",
    "all_responses = df['B.9.2'].explode().dropna().value_counts().reset_index()\n",
    "all_responses.columns = ['Action', 'Count']\n",
    "\n",
    "# Step 5: Calculate total number of valid responses (rows with non-empty lists)\n",
    "total_valid_responses = df[df['B.9.2'].apply(len) > 0].shape[0]\n",
    "\n",
    "# Step 6: Calculate the percentage of rows that mention each action\n",
    "all_responses['Percentage'] = (all_responses['Count'] / total_valid_responses * 100).round(2)\n",
    "\n",
    "# Step 7: Visualize the results with a Bar Chart using Plotly\n",
    "fig = px.bar(all_responses, x='Action', y='Count',\n",
    "             title='B.9.2 Actions Taken to Promote Ethical Practices in AI',\n",
    "             labels={'Action': 'Action', 'Count': 'Number of Mentions'},\n",
    "             color='Count',\n",
    "             color_continuous_scale='Blues',\n",
    "             text=all_responses['Percentage'].apply(lambda x: f'{x}% of respondents'))\n",
    "\n",
    "# Update layout to make the chart clearer\n",
    "fig.update_layout(xaxis_tickangle=45, xaxis_title='Action', yaxis_title='Number of Mentions')\n",
    "\n",
    "# Step 8: Show the figure\n",
    "fig.show(renderer=\"browser\")\n",
    "\n",
    "# Step 9: Generate a statistical report\n",
    "question_text = \"B.9.2 Which of the following actions has your company taken to promote ethical practices in AI? Select all that apply.\"\n",
    "print(question_text)\n",
    "\n",
    "print(f\"Total respondents: {total_valid_responses}\")\n",
    "print(\"Breakdown of responses:\", end=\" \")\n",
    "print(\", \".join([f\"{row['Action']}: {row['Count']} mentions ({row['Percentage']}% of respondents)\" for _, row in all_responses.iterrows()]))\n",
    "\n",
    "total_mentions = all_responses['Count'].sum()\n",
    "average_mentions = total_mentions / len(all_responses)\n",
    "most_common = all_responses.iloc[0]\n",
    "least_common = all_responses.iloc[-1]\n",
    "\n",
    "print(f\"Total mentions across all actions: {total_mentions}, \", end=\"\")\n",
    "print(f\"Average mentions per action: {average_mentions:.2f}, \", end=\"\")\n",
    "print(f\"Most common action: {most_common['Action']} ({most_common['Count']} mentions, {most_common['Percentage']}% of respondents), \", end=\"\")\n",
    "print(f\"Least common action: {least_common['Action']} ({least_common['Count']} mentions, {least_common['Percentage']}% of respondents)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B.9.3 Who is primarily responsible for ensuring AI ethics principles are followed in your company? Select all that applies.\n",
      "Total respondents: 65\n",
      "Breakdown of responses: AI Development Team: 43 mentions (66.15% of respondents), Upper Management: 39 mentions (60.0% of respondents), Internal Legal and Compliance Team: 28 mentions (43.08% of respondents), AI Ethics Committee: 26 mentions (40.0% of respondents), Prefer not to say: 1 mentions (1.54% of respondents)\n",
      "Total mentions across all responsible parties: 137, Average mentions per responsible party: 27.40, Most common responsible party: AI Development Team (43 mentions, 66.15% of respondents), Least common responsible party: Prefer not to say (1 mentions, 1.54% of respondents)\n"
     ]
    }
   ],
   "source": [
    "####################\n",
    "# B.9.3\n",
    "####################\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Step 1: Read CSV file into a DataFrame\n",
    "df = pd.read_csv(ai_study)\n",
    "\n",
    "# Step 2: Exclude the first two rows\n",
    "df = df.iloc[2:]\n",
    "\n",
    "# Function to split responses and merge specific categories\n",
    "def split_and_merge_responses(response):\n",
    "    if pd.isna(response):\n",
    "        return []\n",
    "    parts = [part.strip() for part in str(response).split(',')]\n",
    "    return parts\n",
    "\n",
    "# Step 3: Process the responses using the split_and_merge_responses function\n",
    "df['B.9.3'] = df['B.9.3'].apply(split_and_merge_responses)\n",
    "\n",
    "# Step 4: Flatten the list of responses and count occurrences\n",
    "all_responses = df['B.9.3'].explode().dropna().value_counts().reset_index()\n",
    "all_responses.columns = ['Responsible Party', 'Count']\n",
    "\n",
    "# Step 5: Calculate total number of valid responses (rows with non-empty lists)\n",
    "total_valid_responses = df[df['B.9.3'].apply(len) > 0].shape[0]\n",
    "\n",
    "# Step 6: Calculate the percentage of rows that mention each responsible party\n",
    "all_responses['Percentage'] = (all_responses['Count'] / total_valid_responses * 100).round(2)\n",
    "\n",
    "# Step 7: Visualize the results with a Bar Chart using Plotly\n",
    "fig = px.bar(all_responses, x='Responsible Party', y='Count',\n",
    "             title='B.9.3 Responsibility for Ensuring AI Ethics Principles are Followed',\n",
    "             labels={'Responsible Party': 'Responsible Party', 'Count': 'Number of Mentions'},\n",
    "             color='Count',\n",
    "             color_continuous_scale='Blues',\n",
    "             text=all_responses['Percentage'].apply(lambda x: f'{x}% of respondents'))\n",
    "\n",
    "# Update layout to make the chart clearer\n",
    "fig.update_layout(xaxis_tickangle=45, xaxis_title='Responsible Party', yaxis_title='Number of Mentions')\n",
    "\n",
    "# Step 8: Show the figure\n",
    "fig.show(renderer=\"browser\")\n",
    "\n",
    "# Step 9: Generate a statistical report\n",
    "question_text = \"B.9.3 Who is primarily responsible for ensuring AI ethics principles are followed in your company? Select all that applies.\"\n",
    "print(question_text)\n",
    "\n",
    "print(f\"Total respondents: {total_valid_responses}\")\n",
    "print(\"Breakdown of responses:\", end=\" \")\n",
    "print(\", \".join([f\"{row['Responsible Party']}: {row['Count']} mentions ({row['Percentage']}% of respondents)\" for _, row in all_responses.iterrows()]))\n",
    "\n",
    "total_mentions = all_responses['Count'].sum()\n",
    "average_mentions = total_mentions / len(all_responses)\n",
    "most_common = all_responses.iloc[0]\n",
    "least_common = all_responses.iloc[-1]\n",
    "\n",
    "print(f\"Total mentions across all responsible parties: {total_mentions}, \", end=\"\")\n",
    "print(f\"Average mentions per responsible party: {average_mentions:.2f}, \", end=\"\")\n",
    "print(f\"Most common responsible party: {most_common['Responsible Party']} ({most_common['Count']} mentions, {most_common['Percentage']}% of respondents), \", end=\"\")\n",
    "print(f\"Least common responsible party: {least_common['Responsible Party']} ({least_common['Count']} mentions, {least_common['Percentage']}% of respondents)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B.9.4 How often do AI ethics principles influence business decisions in your company?\n",
      "Total respondents: 64\n",
      "Breakdown of responses: Often: 30 responses (46.88%), Sometimes: 15 responses (23.44%), Always: 10 responses (15.62%), Never: 6 responses (9.38%), Rarely: 3 responses (4.69%)\n",
      "Total mentions across all frequency levels: 64, Average mentions per frequency level: 12.80, Most common response: Often (30 mentions, 46.88% of respondents), Least common response: Rarely (3 mentions, 4.69% of respondents)\n"
     ]
    }
   ],
   "source": [
    "####################\n",
    "# B.9.4\n",
    "####################\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Step 1: Read CSV file into a DataFrame\n",
    "df = pd.read_csv(ai_study)\n",
    "\n",
    "# Step 2: Exclude the first two rows\n",
    "df = df.iloc[2:]\n",
    "\n",
    "# Step 3: Remove NaNs or empty values in 'B.9.4'\n",
    "df = df[df['B.9.4'].notna()]  # Remove NaNs\n",
    "df['B.9.4'] = df['B.9.4'].astype(str).apply(lambda x: x.strip())\n",
    "df = df[df['B.9.4'] != \"\"]  # Remove empty strings\n",
    "\n",
    "# Step 4: Count occurrences of each response\n",
    "response_counts = df['B.9.4'].value_counts().reset_index()\n",
    "response_counts.columns = ['Response', 'Count']\n",
    "\n",
    "# Step 5: Calculate total number of valid responses\n",
    "total_valid_responses = df.shape[0]\n",
    "\n",
    "# Step 6: Calculate the percentage of each option based on valid responses\n",
    "response_counts['Percentage'] = (response_counts['Count'] / total_valid_responses * 100).round(2)\n",
    "\n",
    "# Step 7: Visualize the results with a Pie Chart using Plotly\n",
    "fig = px.pie(response_counts, names='Response', values='Count',\n",
    "             title='B.9.4 Frequency of AI Ethics Principles Influencing Business Decisions',\n",
    "             color_discrete_sequence=px.colors.sequential.RdBu,\n",
    "             labels={'Response': 'Frequency', 'Count': 'Number of Responses'})\n",
    "\n",
    "# Add percentage text to the pie slices\n",
    "fig.update_traces(textposition='inside', textinfo='percent+label')\n",
    "\n",
    "# Step 8: Show the figure\n",
    "fig.show(renderer=\"browser\")\n",
    "\n",
    "# Step 9: Generate a statistical report\n",
    "question_text = \"B.9.4 How often do AI ethics principles influence business decisions in your company?\"\n",
    "print(question_text)\n",
    "\n",
    "print(f\"Total respondents: {total_valid_responses}\")\n",
    "print(\"Breakdown of responses:\", end=\" \")\n",
    "print(\", \".join([f\"{row['Response']}: {row['Count']} responses ({row['Percentage']}%)\" for _, row in response_counts.iterrows()]))\n",
    "\n",
    "total_mentions = response_counts['Count'].sum()\n",
    "average_mentions = total_mentions / len(response_counts)\n",
    "most_common = response_counts.iloc[0]\n",
    "least_common = response_counts.iloc[-1]\n",
    "\n",
    "print(f\"Total mentions across all frequency levels: {total_mentions}, \", end=\"\")\n",
    "print(f\"Average mentions per frequency level: {average_mentions:.2f}, \", end=\"\")\n",
    "print(f\"Most common response: {most_common['Response']} ({most_common['Count']} mentions, {most_common['Percentage']}% of respondents), \", end=\"\")\n",
    "print(f\"Least common response: {least_common['Response']} ({least_common['Count']} mentions, {least_common['Percentage']}% of respondents)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B.10.1 How often do you include ethical considerations in your AI requirements documentation?\n",
      "Total respondents: 35\n",
      "Breakdown of responses: Often: 12 responses (34.29%), Always: 8 responses (22.86%), Sometimes: 7 responses (20.0%), Rarely: 6 responses (17.14%), Never: 2 responses (5.71%)\n",
      "Total mentions across all frequency levels: 35, Average mentions per frequency level: 7.00, Most common response: Often (12 mentions, 34.29% of respondents), Least common response: Never (2 mentions, 5.71% of respondents)\n"
     ]
    }
   ],
   "source": [
    "####################\n",
    "# B.10.1\n",
    "####################\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Step 1: Read CSV file into a DataFrame\n",
    "df = pd.read_csv(ai_study)\n",
    "\n",
    "# Step 2: Exclude the first two rows\n",
    "df = df.iloc[2:]\n",
    "\n",
    "# Step 3: Remove NaNs or empty values in 'B.10.1'\n",
    "df = df[df['B.10.1'].notna()]  # Remove NaNs\n",
    "df['B.10.1'] = df['B.10.1'].astype(str).apply(lambda x: x.strip())\n",
    "df = df[df['B.10.1'] != \"\"]  # Remove empty strings\n",
    "\n",
    "# Step 4: Count occurrences of each response\n",
    "response_counts = df['B.10.1'].value_counts().reset_index()\n",
    "response_counts.columns = ['Response', 'Count']\n",
    "\n",
    "# Step 5: Calculate total number of valid responses\n",
    "total_valid_responses = df.shape[0]\n",
    "\n",
    "# Step 6: Calculate the percentage of each option based on valid responses\n",
    "response_counts['Percentage'] = (response_counts['Count'] / total_valid_responses * 100).round(2)\n",
    "\n",
    "# Step 7: Visualize the results with a Pie Chart using Plotly\n",
    "question_text = \"B.10.1 How often do you include ethical considerations in your AI requirements documentation?\"\n",
    "fig = px.pie(response_counts, names='Response', values='Count',\n",
    "             title=question_text,\n",
    "             color_discrete_sequence=px.colors.sequential.RdBu,\n",
    "             labels={'Response': 'Frequency', 'Count': 'Number of Responses'})\n",
    "\n",
    "# Add percentage text to the pie slices\n",
    "fig.update_traces(textposition='inside', textinfo='percent+label')\n",
    "\n",
    "# Step 8: Show the figure\n",
    "fig.show(renderer=\"browser\")\n",
    "\n",
    "# Step 9: Generate a statistical report\n",
    "print(question_text)\n",
    "\n",
    "print(f\"Total respondents: {total_valid_responses}\")\n",
    "print(\"Breakdown of responses:\", end=\" \")\n",
    "print(\", \".join([f\"{row['Response']}: {row['Count']} responses ({row['Percentage']}%)\" for _, row in response_counts.iterrows()]))\n",
    "\n",
    "total_mentions = response_counts['Count'].sum()\n",
    "average_mentions = total_mentions / len(response_counts)\n",
    "most_common = response_counts.iloc[0]\n",
    "least_common = response_counts.iloc[-1]\n",
    "\n",
    "print(f\"Total mentions across all frequency levels: {total_mentions}, \", end=\"\")\n",
    "print(f\"Average mentions per frequency level: {average_mentions:.2f}, \", end=\"\")\n",
    "print(f\"Most common response: {most_common['Response']} ({most_common['Count']} mentions, {most_common['Percentage']}% of respondents), \", end=\"\")\n",
    "print(f\"Least common response: {least_common['Response']} ({least_common['Count']} mentions, {least_common['Percentage']}% of respondents)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B.10.2 How do ethical requirements impact the overall AI project lifecycle?\n",
      "Total respondents: 35\n",
      "Breakdown of responses: Somewhat enhance the project outcomes: 17 responses (48.57%), Somewhat hinders the project outcomes: 9 responses (25.71%), Significantly enhance the project outcomes: 4 responses (11.43%), No impact at all on the project outcomes: 3 responses (8.57%), Significantly hinders the project outcomes: 1 responses (2.86%), Prefer not to say: 1 responses (2.86%)\n",
      "Total mentions across all impact levels: 35, Average mentions per impact level: 5.83, Most common response: Somewhat enhance the project outcomes (17 mentions, 48.57% of respondents), Least common response: Prefer not to say (1 mentions, 2.86% of respondents)\n"
     ]
    }
   ],
   "source": [
    "####################\n",
    "# B.10.2\n",
    "####################\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Step 1: Read CSV file into a DataFrame\n",
    "df = pd.read_csv(ai_study)\n",
    "\n",
    "# Step 2: Exclude the first two rows\n",
    "df = df.iloc[2:]\n",
    "\n",
    "# Step 3: Remove NaNs or empty values in 'B.10.2'\n",
    "df = df[df['B.10.2'].notna()]  # Remove NaNs\n",
    "df['B.10.2'] = df['B.10.2'].astype(str).apply(lambda x: x.strip())\n",
    "df = df[df['B.10.2'] != \"\"]  # Remove empty strings\n",
    "\n",
    "# Step 4: Count occurrences of each response\n",
    "response_counts = df['B.10.2'].value_counts().reset_index()\n",
    "response_counts.columns = ['Response', 'Count']\n",
    "\n",
    "# Step 5: Calculate total number of valid responses\n",
    "total_valid_responses = df.shape[0]\n",
    "\n",
    "# Step 6: Calculate the percentage of each option based on valid responses\n",
    "response_counts['Percentage'] = (response_counts['Count'] / total_valid_responses * 100).round(2)\n",
    "\n",
    "# Step 7: Visualize the results with a Pie Chart using Plotly\n",
    "question_text = \"B.10.2 How do ethical requirements impact the overall AI project lifecycle?\"\n",
    "fig = px.pie(response_counts, names='Response', values='Count',\n",
    "             title=question_text,\n",
    "             color_discrete_sequence=px.colors.sequential.RdBu,\n",
    "             labels={'Response': 'Impact', 'Count': 'Number of Responses'})\n",
    "\n",
    "# Add percentage text to the pie slices\n",
    "fig.update_traces(textposition='inside', textinfo='percent+label')\n",
    "\n",
    "# Step 8: Show the figure\n",
    "fig.show(renderer=\"browser\")\n",
    "\n",
    "# Step 9: Generate a statistical report\n",
    "print(question_text)\n",
    "\n",
    "print(f\"Total respondents: {total_valid_responses}\")\n",
    "print(\"Breakdown of responses:\", end=\" \")\n",
    "print(\", \".join([f\"{row['Response']}: {row['Count']} responses ({row['Percentage']}%)\" for _, row in response_counts.iterrows()]))\n",
    "\n",
    "total_mentions = response_counts['Count'].sum()\n",
    "average_mentions = total_mentions / len(response_counts)\n",
    "most_common = response_counts.iloc[0]\n",
    "least_common = response_counts.iloc[-1]\n",
    "\n",
    "print(f\"Total mentions across all impact levels: {total_mentions}, \", end=\"\")\n",
    "print(f\"Average mentions per impact level: {average_mentions:.2f}, \", end=\"\")\n",
    "print(f\"Most common response: {most_common['Response']} ({most_common['Count']} mentions, {most_common['Percentage']}% of respondents), \", end=\"\")\n",
    "print(f\"Least common response: {least_common['Response']} ({least_common['Count']} mentions, {least_common['Percentage']}% of respondents)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B.10.3 Which AI ethics principles do you prioritize when defining AI requirements? Select all that apply.\n",
      "Total respondents: 33\n",
      "Breakdown of responses: Data Protection and Right to Privacy: 21 mentions (63.64% of respondents), Transparency and Explainability of AI Systems: 15 mentions (45.45% of respondents), Harm Prevention and Beneficence: 11 mentions (33.33% of respondents), Non-Discrimination and Freedom of Privileges: 10 mentions (30.3% of respondents), Fairness and Justice: 9 mentions (27.27% of respondents), Respect for Human Rights: 9 mentions (27.27% of respondents), Democracy and Rule of Law: 8 mentions (24.24% of respondents), Accountability and Responsibility: 6 mentions (18.18% of respondents), Environment and Social Responsibility: 4 mentions (12.12% of respondents), All: 4 mentions (12.12% of respondents)\n",
      "Total mentions across all principles: 97, Average mentions per principle: 9.70, Most common principle: Data Protection and Right to Privacy (21 mentions, 63.64% of respondents), Least common principle: All (4 mentions, 12.12% of respondents)\n",
      "B.10.3 Which AI ethics principles do you prioritize when defining AI requirements? Select all that apply.\n",
      "Total respondents: 33\n",
      "Breakdown of responses: Data Protection and Right to Privacy: 21 mentions (63.64% of respondents), Transparency and Explainability of AI Systems: 15 mentions (45.45% of respondents), Harm Prevention and Beneficence: 11 mentions (33.33% of respondents), Non-Discrimination and Freedom of Privileges: 10 mentions (30.3% of respondents), Fairness and Justice: 9 mentions (27.27% of respondents), Respect for Human Rights: 9 mentions (27.27% of respondents), Democracy and Rule of Law: 8 mentions (24.24% of respondents), Accountability and Responsibility: 6 mentions (18.18% of respondents), Environment and Social Responsibility: 4 mentions (12.12% of respondents), All: 4 mentions (12.12% of respondents)\n",
      "Total mentions across all principles: 97, Average mentions per principle: 9.70, Most common principle: Data Protection and Right to Privacy (21 mentions, 63.64% of respondents), Least common principle: All (4 mentions, 12.12% of respondents)\n"
     ]
    }
   ],
   "source": [
    "####################\n",
    "# B.10.3\n",
    "####################\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Step 1: Read CSV file into a DataFrame\n",
    "df = pd.read_csv(ai_study)\n",
    "\n",
    "# Step 2: Exclude the first two rows\n",
    "df = df.iloc[2:]\n",
    "\n",
    "# Function to split responses and merge specific categories\n",
    "def split_and_merge_responses(response):\n",
    "    if pd.isna(response):\n",
    "        return []\n",
    "    parts = [part.strip() for part in str(response).split(',')]\n",
    "    return parts\n",
    "\n",
    "# Step 3: Process the responses using the split_and_merge_responses function\n",
    "df['B.10.3'] = df['B.10.3'].apply(split_and_merge_responses)\n",
    "\n",
    "# Step 4: Flatten the list of responses and count occurrences\n",
    "all_responses = df['B.10.3'].explode().dropna().value_counts().reset_index()\n",
    "all_responses.columns = ['Principle', 'Count']\n",
    "\n",
    "# Step 5: Calculate total number of valid responses (rows with non-empty lists)\n",
    "total_valid_responses = df[df['B.10.3'].apply(len) > 0].shape[0]\n",
    "\n",
    "# Step 6: Calculate the percentage of rows that mention each principle\n",
    "all_responses['Percentage'] = (all_responses['Count'] / total_valid_responses * 100).round(2)\n",
    "\n",
    "# Step 7: Visualize the results with a Bar Chart using Plotly\n",
    "question_text = \"B.10.3 Which AI ethics principles do you prioritize when defining AI requirements? Select all that apply.\"\n",
    "fig = px.bar(all_responses, x='Principle', y='Count',\n",
    "             title=question_text,\n",
    "             labels={'Principle': 'AI Ethics Principle', 'Count': 'Number of Mentions'},\n",
    "             color='Count',\n",
    "             color_continuous_scale='Blues',\n",
    "             text=all_responses['Percentage'].apply(lambda x: f'{x}% of respondents'))\n",
    "\n",
    "# Update layout to make the chart clearer\n",
    "fig.update_layout(xaxis_tickangle=45, xaxis_title='AI Ethics Principle', yaxis_title='Number of Mentions')\n",
    "\n",
    "# Step 8: Show the figure\n",
    "fig.show(renderer=\"browser\")\n",
    "\n",
    "# Step 9: Generate a statistical report\n",
    "print(question_text)\n",
    "\n",
    "print(f\"Total respondents: {total_valid_responses}\")\n",
    "print(\"Breakdown of responses:\", end=\" \")\n",
    "print(\", \".join([f\"{row['Principle']}: {row['Count']} mentions ({row['Percentage']}% of respondents)\" for _, row in all_responses.iterrows()]))\n",
    "\n",
    "total_mentions = all_responses['Count'].sum()\n",
    "average_mentions = total_mentions / len(all_responses)\n",
    "most_common = all_responses.iloc[0]\n",
    "least_common = all_responses.iloc[-1]\n",
    "\n",
    "print(f\"Total mentions across all principles: {total_mentions}, \", end=\"\")\n",
    "print(f\"Average mentions per principle: {average_mentions:.2f}, \", end=\"\")\n",
    "print(f\"Most common principle: {most_common['Principle']} ({most_common['Count']} mentions, {most_common['Percentage']}% of respondents), \", end=\"\")\n",
    "print(f\"Least common principle: {least_common['Principle']} ({least_common['Count']} mentions, {least_common['Percentage']}% of respondents)\")####################\n",
    "# B.10.3\n",
    "####################\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Step 1: Read CSV file into a DataFrame\n",
    "df = pd.read_csv(ai_study)\n",
    "\n",
    "# Step 2: Exclude the first two rows\n",
    "df = df.iloc[2:]\n",
    "\n",
    "# Function to split responses and merge specific categories\n",
    "def split_and_merge_responses(response):\n",
    "    if pd.isna(response):\n",
    "        return []\n",
    "    parts = [part.strip() for part in str(response).split(',')]\n",
    "    return parts\n",
    "\n",
    "# Step 3: Process the responses using the split_and_merge_responses function\n",
    "df['B.10.3'] = df['B.10.3'].apply(split_and_merge_responses)\n",
    "\n",
    "# Step 4: Flatten the list of responses and count occurrences\n",
    "all_responses = df['B.10.3'].explode().dropna().value_counts().reset_index()\n",
    "all_responses.columns = ['Principle', 'Count']\n",
    "\n",
    "# Step 5: Calculate total number of valid responses (rows with non-empty lists)\n",
    "total_valid_responses = df[df['B.10.3'].apply(len) > 0].shape[0]\n",
    "\n",
    "# Step 6: Calculate the percentage of rows that mention each principle\n",
    "all_responses['Percentage'] = (all_responses['Count'] / total_valid_responses * 100).round(2)\n",
    "\n",
    "# Step 7: Visualize the results with a Bar Chart using Plotly\n",
    "question_text = \"B.10.3 Which AI ethics principles do you prioritize when defining AI requirements? Select all that apply.\"\n",
    "fig = px.bar(all_responses, x='Principle', y='Count',\n",
    "             title=question_text,\n",
    "             labels={'Principle': 'AI Ethics Principle', 'Count': 'Number of Mentions'},\n",
    "             color='Count',\n",
    "             color_continuous_scale='Blues',\n",
    "             text=all_responses['Percentage'].apply(lambda x: f'{x}% of respondents'))\n",
    "\n",
    "# Update layout to make the chart clearer\n",
    "fig.update_layout(xaxis_tickangle=45, xaxis_title='AI Ethics Principle', yaxis_title='Number of Mentions')\n",
    "\n",
    "# Step 8: Show the figure\n",
    "fig.show(renderer=\"browser\")\n",
    "\n",
    "# Step 9: Generate a statistical report\n",
    "print(question_text)\n",
    "\n",
    "print(f\"Total respondents: {total_valid_responses}\")\n",
    "print(\"Breakdown of responses:\", end=\" \")\n",
    "print(\", \".join([f\"{row['Principle']}: {row['Count']} mentions ({row['Percentage']}% of respondents)\" for _, row in all_responses.iterrows()]))\n",
    "\n",
    "total_mentions = all_responses['Count'].sum()\n",
    "average_mentions = total_mentions / len(all_responses)\n",
    "most_common = all_responses.iloc[0]\n",
    "least_common = all_responses.iloc[-1]\n",
    "\n",
    "print(f\"Total mentions across all principles: {total_mentions}, \", end=\"\")\n",
    "print(f\"Average mentions per principle: {average_mentions:.2f}, \", end=\"\")\n",
    "print(f\"Most common principle: {most_common['Principle']} ({most_common['Count']} mentions, {most_common['Percentage']}% of respondents), \", end=\"\")\n",
    "print(f\"Least common principle: {least_common['Principle']} ({least_common['Count']} mentions, {least_common['Percentage']}% of respondents)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B.11.1 What methods do you use to mitigate biases in AI algorithms? Select all that apply.\n",
      "Total respondents: 138\n",
      "Breakdown of responses: Evaluating the results of the models: 83 mentions (60.14% of respondents), Ensure including diverse and representative training data: 67 mentions (48.55% of respondents), Regular bias audits and testing: 61 mentions (44.2% of respondents), Regular data cleaning: 60 mentions (43.48% of respondents), Peer reviews and collaborative development: 58 mentions (42.03% of respondents), User feedback and iterative improvements: 57 mentions (41.3% of respondents), Conducting regular ethics impact assessments: 48 mentions (34.78% of respondents), Identify and examine vulnerable groups in your AI system: 47 mentions (34.06% of respondents), Implementing fairness constraints in models: 46 mentions (33.33% of respondents), Using bias-aware algorithms: 39 mentions (28.26% of respondents), Finetuning decision boundaries: 35 mentions (25.36% of respondents), Prefer not to say: 3 mentions (2.17% of respondents), Other: 3 mentions (2.17% of respondents)\n",
      "Total mentions across all methods: 607, Average mentions per method: 46.69, Most common method: Evaluating the results of the models (83 mentions, 60.14% of respondents), Least common method: Other (3 mentions, 2.17% of respondents)\n"
     ]
    }
   ],
   "source": [
    "####################\n",
    "# B.11.1\n",
    "####################\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import re\n",
    "\n",
    "# Step 1: Read CSV file into a DataFrame\n",
    "df = pd.read_csv(ai_study)\n",
    "\n",
    "# Step 2: Exclude the first two rows\n",
    "df = df.iloc[2:]\n",
    "\n",
    "# Function to split responses and merge specific categories\n",
    "def split_and_merge_responses(response):\n",
    "    if pd.isna(response):\n",
    "        return []\n",
    "    # Split by comma, but keep commas within quotes\n",
    "    parts = re.split(r',\\s*(?=(?:[^\"]*\"[^\"]*\")*[^\"]*$)', response)\n",
    "    # Clean up each part and merge \"Other\" with \"please specify\"\n",
    "    cleaned_parts = []\n",
    "    for part in parts:\n",
    "        part = part.strip().strip('\"')\n",
    "        if part.lower() == 'other':\n",
    "            continue\n",
    "        elif part.lower().startswith('please specify'):\n",
    "            cleaned_parts.append('Other')\n",
    "        elif part:\n",
    "            cleaned_parts.append(part)\n",
    "    return cleaned_parts\n",
    "\n",
    "# Step 3: Process the responses using the split_and_merge_responses function\n",
    "df['B.11.1'] = df['B.11.1'].apply(split_and_merge_responses)\n",
    "\n",
    "# Step 4: Flatten the list of responses and count occurrences\n",
    "all_responses = df['B.11.1'].explode().dropna().value_counts().reset_index()\n",
    "all_responses.columns = ['Method', 'Count']\n",
    "\n",
    "# Step 5: Calculate total number of valid responses (rows with non-empty lists)\n",
    "total_valid_responses = df[df['B.11.1'].apply(len) > 0].shape[0]\n",
    "\n",
    "# Step 6: Calculate the percentage of rows that mention each method\n",
    "all_responses['Percentage'] = (all_responses['Count'] / total_valid_responses * 100).round(2)\n",
    "\n",
    "# Step 7: Visualize the results with a Bar Chart using Plotly\n",
    "question_text = \"B.11.1 What methods do you use to mitigate biases in AI algorithms? Select all that apply.\"\n",
    "fig = px.bar(all_responses, x='Method', y='Count',\n",
    "             title=question_text,\n",
    "             labels={'Method': 'Bias Mitigation Method', 'Count': 'Number of Mentions'},\n",
    "             color='Count',\n",
    "             color_continuous_scale='Blues',\n",
    "             text=all_responses['Percentage'].apply(lambda x: f'{x}% of respondents'))\n",
    "\n",
    "# Update layout to make the chart clearer and set the title to bold\n",
    "fig.update_layout(\n",
    "    xaxis_tickangle=45,\n",
    "    xaxis_title='Bias Mitigation Method',\n",
    "    yaxis_title='Number of Mentions',\n",
    "    title={\n",
    "        'text': f\"<b>{question_text}</b>\",  # Wrap the title in <b> tags to make it bold\n",
    "        'y':0.95,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'\n",
    "    }\n",
    ")\n",
    "\n",
    "# Step 8: Show the figure\n",
    "fig.show(renderer=\"browser\")\n",
    "\n",
    "# Step 9: Generate a statistical report\n",
    "print(question_text)\n",
    "\n",
    "print(f\"Total respondents: {total_valid_responses}\")\n",
    "print(\"Breakdown of responses:\", end=\" \")\n",
    "print(\", \".join([f\"{row['Method']}: {row['Count']} mentions ({row['Percentage']}% of respondents)\" for _, row in all_responses.iterrows()]))\n",
    "\n",
    "total_mentions = all_responses['Count'].sum()\n",
    "average_mentions = total_mentions / len(all_responses)\n",
    "most_common = all_responses.iloc[0]\n",
    "least_common = all_responses.iloc[-1]\n",
    "\n",
    "print(f\"Total mentions across all methods: {total_mentions}, \", end=\"\")\n",
    "print(f\"Average mentions per method: {average_mentions:.2f}, \", end=\"\")\n",
    "print(f\"Most common method: {most_common['Method']} ({most_common['Count']} mentions, {most_common['Percentage']}% of respondents), \", end=\"\")\n",
    "print(f\"Least common method: {least_common['Method']} ({least_common['Count']} mentions, {least_common['Percentage']}% of respondents)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# B.11.1 by Location\n",
    "####################\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import re\n",
    "\n",
    "# Step 1: Read CSV file into a DataFrame\n",
    "df = pd.read_csv(ai_study)\n",
    "\n",
    "# Step 2: Exclude the first two rows and set the location column\n",
    "df = df.iloc[2:]\n",
    "df['Location'] = df.iloc[:, 28]  # Assuming the location is in column 29 (index 28)\n",
    "\n",
    "# Function to split responses and merge specific categories\n",
    "def split_and_merge_responses(response):\n",
    "    if pd.isna(response):\n",
    "        return []\n",
    "    parts = re.split(r',\\s*(?=(?:[^\"]*\"[^\"]*\")*[^\"]*$)', response)\n",
    "    cleaned_parts = []\n",
    "    for part in parts:\n",
    "        part = part.strip().strip('\"')\n",
    "        if part.lower() == 'other':\n",
    "            continue\n",
    "        elif part.lower().startswith('other, please specify'):\n",
    "            cleaned_parts.append('Other, please specify')\n",
    "        elif part:\n",
    "            cleaned_parts.append(part)\n",
    "    return cleaned_parts\n",
    "\n",
    "# Step 3: Process the responses using the split_and_merge_responses function\n",
    "df['B.11.1'] = df['B.11.1'].apply(split_and_merge_responses)\n",
    "\n",
    "# Step 4: Create a new dataframe with location and response combinations\n",
    "location_responses = df.explode('B.11.1')[['Location', 'B.11.1']].dropna()\n",
    "\n",
    "# Step 5: Calculate percentages for each response within each location\n",
    "location_percentages = location_responses.groupby('Location')['B.11.1'].value_counts(normalize=True).unstack().fillna(0) * 100\n",
    "\n",
    "# Step 6: Create a subplot for each location\n",
    "fig = make_subplots(rows=len(location_percentages), cols=1, \n",
    "                    subplot_titles=location_percentages.index,\n",
    "                    vertical_spacing=0.05)\n",
    "\n",
    "# Step 7: Add bar traces for each location\n",
    "for i, location in enumerate(location_percentages.index, start=1):\n",
    "    fig.add_trace(\n",
    "        go.Bar(x=location_percentages.columns, y=location_percentages.loc[location],\n",
    "               name=location, text=location_percentages.loc[location].round(1),\n",
    "               textposition='outside'),\n",
    "        row=i, col=1\n",
    "    )\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(height=400*len(location_percentages), width=1200, \n",
    "                  title_text=\"B.11.1 Methods to Mitigate Biases in AI Algorithms by Location (Percentage)\",\n",
    "                  showlegend=False)\n",
    "\n",
    "fig.update_xaxes(tickangle=45)\n",
    "fig.update_yaxes(range=[0, 100])\n",
    "\n",
    "# Step 8: Show the figure\n",
    "fig.show(renderer=\"browser\")\n",
    "\n",
    "# Step 9: Generate a statistical report\n",
    "print(\"B.11.1 Methods to Mitigate Biases in AI Algorithms by Location\")\n",
    "print(\"\\nPercentage of responses for each method by location:\")\n",
    "print(location_percentages.round(2).to_string())\n",
    "\n",
    "print(\"\\nMost common method for each location:\")\n",
    "for location in location_percentages.index:\n",
    "    most_common = location_percentages.loc[location].idxmax()\n",
    "    percentage = location_percentages.loc[location, most_common]\n",
    "    print(f\"{location}: {most_common} ({percentage:.2f}%)\")\n",
    "\n",
    "print(\"\\nLeast common method for each location:\")\n",
    "for location in location_percentages.index:\n",
    "    least_common = location_percentages.loc[location].idxmin()\n",
    "    percentage = location_percentages.loc[location, least_common]\n",
    "    print(f\"{location}: {least_common} ({percentage:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B.11.2 How important is it to you that the AI systems you develop are transparent and explainable?\n",
      "Total respondents: 140\n",
      "Breakdown of responses: Extremely Important: 73 responses (52.14%), Moderately Important: 33 responses (23.57%), Somewhat Important: 22 responses (15.71%), Not Very Important: 7 responses (5.0%), Not At All Important: 5 responses (3.57%)\n",
      "Total mentions across all importance levels: 140, Average mentions per importance level: 28.00, Most common response: Extremely Important (73 mentions, 52.14% of respondents), Least common response: Not At All Important (5 mentions, 3.57% of respondents)\n"
     ]
    }
   ],
   "source": [
    "####################\n",
    "# B.11.2\n",
    "####################\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Step 1: Read CSV file into a DataFrame\n",
    "df = pd.read_csv(ai_study)\n",
    "\n",
    "# Step 2: Exclude the first two rows\n",
    "df = df.iloc[2:]\n",
    "\n",
    "# Step 3: Remove NaNs or empty values in 'B.11.2'\n",
    "df = df[df['B.11.2'].notna()]  # Remove NaNs\n",
    "df['B.11.2'] = df['B.11.2'].astype(str).apply(lambda x: x.strip())\n",
    "df = df[df['B.11.2'] != \"\"]  # Remove empty strings\n",
    "\n",
    "# Step 4: Count occurrences of each response\n",
    "response_counts = df['B.11.2'].value_counts().reset_index()\n",
    "response_counts.columns = ['Response', 'Count']\n",
    "\n",
    "# Step 5: Calculate total number of valid responses\n",
    "total_valid_responses = df.shape[0]\n",
    "\n",
    "# Step 6: Calculate the percentage of each option based on valid responses\n",
    "response_counts['Percentage'] = (response_counts['Count'] / total_valid_responses * 100).round(2)\n",
    "\n",
    "# Step 7: Visualize the results with a Pie Chart using Plotly\n",
    "question_text = \"B.11.2 How important is it to you that the AI systems you develop are transparent and explainable?\"\n",
    "fig = px.pie(response_counts, names='Response', values='Count',\n",
    "             title=question_text,\n",
    "             color_discrete_sequence=px.colors.sequential.RdBu,\n",
    "             labels={'Response': 'Importance Level', 'Count': 'Number of Responses'})\n",
    "\n",
    "# Add percentage text to the pie slices\n",
    "fig.update_traces(textposition='inside', textinfo='percent+label')\n",
    "\n",
    "# Step 8: Show the figure\n",
    "fig.show(renderer=\"browser\")\n",
    "\n",
    "# Step 9: Generate a statistical report\n",
    "print(question_text)\n",
    "\n",
    "print(f\"Total respondents: {total_valid_responses}\")\n",
    "print(\"Breakdown of responses:\", end=\" \")\n",
    "print(\", \".join([f\"{row['Response']}: {row['Count']} responses ({row['Percentage']}%)\" for _, row in response_counts.iterrows()]))\n",
    "\n",
    "total_mentions = response_counts['Count'].sum()\n",
    "average_mentions = total_mentions / len(response_counts)\n",
    "most_common = response_counts.iloc[0]\n",
    "least_common = response_counts.iloc[-1]\n",
    "\n",
    "print(f\"Total mentions across all importance levels: {total_mentions}, \", end=\"\")\n",
    "print(f\"Average mentions per importance level: {average_mentions:.2f}, \", end=\"\")\n",
    "print(f\"Most common response: {most_common['Response']} ({most_common['Count']} mentions, {most_common['Percentage']}% of respondents), \", end=\"\")\n",
    "print(f\"Least common response: {least_common['Response']} ({least_common['Count']} mentions, {least_common['Percentage']}% of respondents)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B.11.3 How confident are you in making ethical decisions during AI development?\n",
      "Total respondents: 140\n",
      "Breakdown of responses: Moderately Confident: 54 responses (38.57%), Extremely Confident: 36 responses (25.71%), Somewhat Confident: 32 responses (22.86%), Not Very Confident: 11 responses (7.86%), Not At All Confident: 6 responses (4.29%), Prefer not to say: 1 responses (0.71%)\n",
      "Total mentions across all confidence levels: 140, Average mentions per confidence level: 23.33, Most common response: Moderately Confident (54 mentions, 38.57% of respondents), Least common response: Prefer not to say (1 mentions, 0.71% of respondents)\n"
     ]
    }
   ],
   "source": [
    "####################\n",
    "# B.11.3\n",
    "####################\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Step 1: Read CSV file into a DataFrame\n",
    "df = pd.read_csv(ai_study)\n",
    "\n",
    "# Step 2: Exclude the first two rows\n",
    "df = df.iloc[2:]\n",
    "\n",
    "# Step 3: Remove NaNs or empty values in 'B.11.3'\n",
    "df = df[df['B.11.3'].notna()]  # Remove NaNs\n",
    "df['B.11.3'] = df['B.11.3'].astype(str).apply(lambda x: x.strip())\n",
    "df = df[df['B.11.3'] != \"\"]  # Remove empty strings\n",
    "\n",
    "# Step 4: Count occurrences of each response\n",
    "response_counts = df['B.11.3'].value_counts().reset_index()\n",
    "response_counts.columns = ['Response', 'Count']\n",
    "\n",
    "# Step 5: Calculate total number of valid responses\n",
    "total_valid_responses = df.shape[0]\n",
    "\n",
    "# Step 6: Calculate the percentage of each option based on valid responses\n",
    "response_counts['Percentage'] = (response_counts['Count'] / total_valid_responses * 100).round(2)\n",
    "\n",
    "# Step 7: Visualize the results with a Pie Chart using Plotly\n",
    "question_text = \"B.11.3 How confident are you in making ethical decisions during AI development?\"\n",
    "fig = px.pie(response_counts, names='Response', values='Count',\n",
    "             title=question_text,\n",
    "             color_discrete_sequence=px.colors.sequential.RdBu,\n",
    "             labels={'Response': 'Confidence Level', 'Count': 'Number of Responses'})\n",
    "\n",
    "# Add percentage text to the pie slices\n",
    "fig.update_traces(textposition='inside', textinfo='percent+label')\n",
    "\n",
    "# Step 8: Show the figure\n",
    "fig.show(renderer=\"browser\")\n",
    "\n",
    "# Step 9: Generate a statistical report\n",
    "print(question_text)\n",
    "\n",
    "print(f\"Total respondents: {total_valid_responses}\")\n",
    "print(\"Breakdown of responses:\", end=\" \")\n",
    "print(\", \".join([f\"{row['Response']}: {row['Count']} responses ({row['Percentage']}%)\" for _, row in response_counts.iterrows()]))\n",
    "\n",
    "total_mentions = response_counts['Count'].sum()\n",
    "average_mentions = total_mentions / len(response_counts)\n",
    "most_common = response_counts.iloc[0]\n",
    "least_common = response_counts.iloc[-1]\n",
    "\n",
    "print(f\"Total mentions across all confidence levels: {total_mentions}, \", end=\"\")\n",
    "print(f\"Average mentions per confidence level: {average_mentions:.2f}, \", end=\"\")\n",
    "print(f\"Most common response: {most_common['Response']} ({most_common['Count']} mentions, {most_common['Percentage']}% of respondents), \", end=\"\")\n",
    "print(f\"Least common response: {least_common['Response']} ({least_common['Count']} mentions, {least_common['Percentage']}% of respondents)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AD: What types of training or resources would help you better integrate AI ethics<br>into your development work?\n",
      "Total respondents: 139\n",
      "Breakdown of responses: Access to ethical guidelines and best practices: 82 mentions (58.99% of respondents), Collaboration with AI ethicists and legal experts: 78 mentions (56.12% of respondents), Regular AI ethics workshops and training: 74 mentions (53.24% of respondents), Case studies of AI ethics implementation: 72 mentions (51.8% of respondents), Regular AI ethics reviews and feedback sessions: 66 mentions (47.48% of respondents), Support for continuous education related to AI ethics: 55 mentions (39.57% of respondents), Prefer not to say: 3 mentions (2.16% of respondents), Other: 1 mentions (0.72% of respondents)\n",
      "Total mentions across all resource types: 431, Average mentions per resource type: 23.18, Most common resource: Access to ethical guidelines and best practices (82 mentions, 58.99% of respondents), Least common resource: Other (1 mentions, 0.72% of respondents)\n"
     ]
    }
   ],
   "source": [
    "####################\n",
    "# B.11.4\n",
    "####################\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import re\n",
    "\n",
    "# Step 1: Read CSV file into a DataFrame\n",
    "df = pd.read_csv(ai_study)\n",
    "\n",
    "# Step 2: Exclude the first two rows\n",
    "df = df.iloc[2:]\n",
    "\n",
    "# Function to split responses and merge specific categories\n",
    "def split_and_merge_responses(response):\n",
    "    if pd.isna(response):\n",
    "        return []\n",
    "    parts = re.split(r',\\s*(?=(?:[^\"]*\"[^\"]*\")*[^\"]*$)', response)\n",
    "    cleaned_parts = []\n",
    "    for part in parts:\n",
    "        part = part.strip().strip('\"')\n",
    "        if part.lower() == 'other':\n",
    "            continue\n",
    "        elif part.lower().startswith('please specify'):\n",
    "            cleaned_parts.append('Other')\n",
    "        elif part:\n",
    "            cleaned_parts.append(part)\n",
    "    return cleaned_parts\n",
    "\n",
    "# Step 3: Process the responses using the split_and_merge_responses function\n",
    "df['B.11.4'] = df['B.11.4'].apply(split_and_merge_responses)\n",
    "\n",
    "# Step 4: Flatten the list of responses and count occurrences\n",
    "all_responses = df['B.11.4'].explode().dropna().value_counts().reset_index()\n",
    "all_responses.columns = ['Resource', 'Count']\n",
    "\n",
    "# Step 5: Calculate total number of valid responses (rows with non-empty lists)\n",
    "total_valid_responses = df[df['B.11.4'].apply(len) > 0].shape[0]\n",
    "\n",
    "# Step 6: Calculate the percentage of rows that mention each resource\n",
    "all_responses['Percentage'] = (all_responses['Count'] / total_valid_responses * 100).round(2)\n",
    "\n",
    "# Step 7: Visualize the results with a Bar Chart using Plotly\n",
    "question_text = \"AD: What types of training or resources would help you better integrate AI ethics<br>into your development work?\"\n",
    "fig = px.bar(all_responses, x='Resource', y='Count',\n",
    "             labels={'Resource': 'Training or Resource Type', 'Count': 'Number of Mentions'},\n",
    "             color='Count',\n",
    "             color_continuous_scale='Blues',\n",
    "             text=all_responses['Percentage'].apply(lambda x: f'<b>{x:.1f}%</b>'))\n",
    "\n",
    "# Update layout to make the chart clearer and set the title to bold\n",
    "fig.update_layout(\n",
    "    xaxis_tickangle=45,\n",
    "    xaxis_title='Training or Resource Type',\n",
    "    yaxis_title='Number of Mentions',\n",
    "    title={\n",
    "        'text': f\"<b>{question_text}</b>\",\n",
    "        'y':0.95,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'\n",
    "    },\n",
    "    font=dict(size=12)\n",
    ")\n",
    "\n",
    "# Update traces to make percentage text bold and bigger\n",
    "fig.update_traces(textposition='inside', textfont=dict(size=14))\n",
    "\n",
    "# Step 8: Show the figure\n",
    "fig.show(renderer=\"browser\")\n",
    "\n",
    "# ... (rest of the code remains the same)\n",
    "\n",
    "# Step 9: Generate a statistical report\n",
    "print(question_text)\n",
    "\n",
    "print(f\"Total respondents: {total_valid_responses}\")\n",
    "print(\"Breakdown of responses:\", end=\" \")\n",
    "print(\", \".join([f\"{row['Resource']}: {row['Count']} mentions ({row['Percentage']}% of respondents)\" for _, row in all_responses.iterrows()]))\n",
    "\n",
    "total_mentions = all_responses['Count'].sum()\n",
    "average_mentions = total_mentions / len(all_responses)\n",
    "most_common = all_responses.iloc[0]\n",
    "least_common = all_responses.iloc[-1]\n",
    "\n",
    "print(f\"Total mentions across all resource types: {total_mentions}, \", end=\"\")\n",
    "print(f\"Average mentions per resource type: {average_responses:.2f}, \", end=\"\")\n",
    "print(f\"Most common resource: {most_common['Resource']} ({most_common['Count']} mentions, {most_common['Percentage']}% of respondents), \", end=\"\")\n",
    "print(f\"Least common resource: {least_common['Resource']} ({least_common['Count']} mentions, {least_common['Percentage']}% of respondents)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B.12.1 What techniques do you use to identify biases in AI systems? Select all that apply.\n",
      "Total respondents: 15\n",
      "Breakdown of responses: Identifying and testing results for vulnerable groups in your AI system: 10 mentions (66.67% of respondents), User testing with diverse groups: 9 mentions (60.0% of respondents), Reviewing training data for diversity: 8 mentions (53.33% of respondents), Regular bias audits and testing: 7 mentions (46.67% of respondents), Analyzing model outputs for discriminatory patterns: 7 mentions (46.67% of respondents), Bias detection tools and software: 6 mentions (40.0% of respondents), Peer reviews and collaborative development: 4 mentions (26.67% of respondents), Evaluating the correct implementation of fairness constraints in models: 3 mentions (20.0% of respondents), Prefer not to say: 2 mentions (13.33% of respondents)\n",
      "Total mentions across all techniques: 56, Average mentions per technique: 6.22, Most common technique: Identifying and testing results for vulnerable groups in your AI system (10 mentions, 66.67% of respondents), Least common technique: Prefer not to say (2 mentions, 13.33% of respondents)\n"
     ]
    }
   ],
   "source": [
    "####################\n",
    "# B.12.1\n",
    "####################\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import re\n",
    "\n",
    "# Step 1: Read CSV file into a DataFrame\n",
    "df = pd.read_csv(ai_study)\n",
    "\n",
    "# Step 2: Exclude the first two rows\n",
    "df = df.iloc[2:]\n",
    "\n",
    "# Function to split responses and merge specific categories\n",
    "def split_and_merge_responses(response):\n",
    "    if pd.isna(response):\n",
    "        return []\n",
    "    # Split by comma, but keep commas within quotes\n",
    "    parts = re.split(r',\\s*(?=(?:[^\"]*\"[^\"]*\")*[^\"]*$)', response)\n",
    "    # Clean up each part and merge \"Other\" with \"please specify\"\n",
    "    cleaned_parts = []\n",
    "    for part in parts:\n",
    "        part = part.strip().strip('\"')\n",
    "        if part.lower() == 'other':\n",
    "            continue\n",
    "        elif part.lower().startswith('please specify'):\n",
    "            cleaned_parts.append('Other')\n",
    "        elif part:\n",
    "            cleaned_parts.append(part)\n",
    "    return cleaned_parts\n",
    "\n",
    "# Step 3: Process the responses using the split_and_merge_responses function\n",
    "df['B.12.1'] = df['B.12.1'].apply(split_and_merge_responses)\n",
    "\n",
    "# Step 4: Flatten the list of responses and count occurrences\n",
    "all_responses = df['B.12.1'].explode().dropna().value_counts().reset_index()\n",
    "all_responses.columns = ['Technique', 'Count']\n",
    "\n",
    "# Step 5: Calculate total number of valid responses (rows with non-empty lists)\n",
    "total_valid_responses = df[df['B.12.1'].apply(len) > 0].shape[0]\n",
    "\n",
    "# Step 6: Calculate the percentage of rows that mention each technique\n",
    "all_responses['Percentage'] = (all_responses['Count'] / total_valid_responses * 100).round(2)\n",
    "\n",
    "# Step 7: Visualize the results with a Bar Chart using Plotly\n",
    "question_text = \"B.12.1 What techniques do you use to identify biases in AI systems? Select all that apply.\"\n",
    "fig = px.bar(all_responses, x='Technique', y='Count',\n",
    "             title=question_text,\n",
    "             labels={'Technique': 'Bias Identification Technique', 'Count': 'Number of Mentions'},\n",
    "             color='Count',\n",
    "             color_continuous_scale='Blues',\n",
    "             text=all_responses['Percentage'].apply(lambda x: f'{x}% of respondents'))\n",
    "\n",
    "# Update layout to make the chart clearer\n",
    "fig.update_layout(xaxis_tickangle=45, xaxis_title='Bias Identification Technique', yaxis_title='Number of Mentions')\n",
    "\n",
    "# Step 8: Show the figure\n",
    "fig.show(renderer=\"browser\")\n",
    "\n",
    "# Step 9: Generate a statistical report\n",
    "print(question_text)\n",
    "\n",
    "print(f\"Total respondents: {total_valid_responses}\")\n",
    "print(\"Breakdown of responses:\", end=\" \")\n",
    "print(\", \".join([f\"{row['Technique']}: {row['Count']} mentions ({row['Percentage']}% of respondents)\" for _, row in all_responses.iterrows()]))\n",
    "\n",
    "total_mentions = all_responses['Count'].sum()\n",
    "average_mentions = total_mentions / len(all_responses)\n",
    "most_common = all_responses.iloc[0]\n",
    "least_common = all_responses.iloc[-1]\n",
    "\n",
    "print(f\"Total mentions across all techniques: {total_mentions}, \", end=\"\")\n",
    "print(f\"Average mentions per technique: {average_mentions:.2f}, \", end=\"\")\n",
    "print(f\"Most common technique: {most_common['Technique']} ({most_common['Count']} mentions, {most_common['Percentage']}% of respondents), \", end=\"\")\n",
    "print(f\"Least common technique: {least_common['Technique']} ({least_common['Count']} mentions, {least_common['Percentage']}% of respondents)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B.12.2 How important is training on AI ethics for your role as QA or tester?\n",
      "Total respondents: 15\n",
      "Breakdown of responses: Extremely Important: 6 responses (40.0%), Somewhat Important: 5 responses (33.33%), Not Very Important: 2 responses (13.33%), Moderately Important: 2 responses (13.33%)\n",
      "Total mentions across all importance levels: 15, Average mentions per importance level: 3.75, Most common response: Extremely Important (6 mentions, 40.0% of respondents), Least common response: Moderately Important (2 mentions, 13.33% of respondents)\n"
     ]
    }
   ],
   "source": [
    "####################\n",
    "# B.12.2\n",
    "####################\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Step 1: Read CSV file into a DataFrame\n",
    "df = pd.read_csv(ai_study)\n",
    "\n",
    "# Step 2: Exclude the first two rows\n",
    "df = df.iloc[2:]\n",
    "\n",
    "# Step 3: Remove NaNs or empty values in 'B.12.2'\n",
    "df = df[df['B.12.2'].notna()]  # Remove NaNs\n",
    "df['B.12.2'] = df['B.12.2'].astype(str).apply(lambda x: x.strip())\n",
    "df = df[df['B.12.2'] != \"\"]  # Remove empty strings\n",
    "\n",
    "# Step 4: Count occurrences of each response\n",
    "response_counts = df['B.12.2'].value_counts().reset_index()\n",
    "response_counts.columns = ['Response', 'Count']\n",
    "\n",
    "# Step 5: Calculate total number of valid responses\n",
    "total_valid_responses = df.shape[0]\n",
    "\n",
    "# Step 6: Calculate the percentage of each option based on valid responses\n",
    "response_counts['Percentage'] = (response_counts['Count'] / total_valid_responses * 100).round(2)\n",
    "\n",
    "# Step 7: Visualize the results with a Pie Chart using Plotly\n",
    "question_text = \"B.12.2 How important is training on AI ethics for your role as QA or tester?\"\n",
    "fig = px.pie(response_counts, names='Response', values='Count',\n",
    "             title=question_text,\n",
    "             color_discrete_sequence=px.colors.sequential.RdBu,\n",
    "             labels={'Response': 'Importance Level', 'Count': 'Number of Responses'})\n",
    "\n",
    "# Add percentage text to the pie slices\n",
    "fig.update_traces(textposition='inside', textinfo='percent+label')\n",
    "\n",
    "# Step 8: Show the figure\n",
    "fig.show(renderer=\"browser\")\n",
    "\n",
    "# Step 9: Generate a statistical report\n",
    "print(question_text)\n",
    "\n",
    "print(f\"Total respondents: {total_valid_responses}\")\n",
    "print(\"Breakdown of responses:\", end=\" \")\n",
    "print(\", \".join([f\"{row['Response']}: {row['Count']} responses ({row['Percentage']}%)\" for _, row in response_counts.iterrows()]))\n",
    "\n",
    "total_mentions = response_counts['Count'].sum()\n",
    "average_mentions = total_mentions / len(response_counts)\n",
    "most_common = response_counts.iloc[0]\n",
    "least_common = response_counts.iloc[-1]\n",
    "\n",
    "print(f\"Total mentions across all importance levels: {total_mentions}, \", end=\"\")\n",
    "print(f\"Average mentions per importance level: {average_mentions:.2f}, \", end=\"\")\n",
    "print(f\"Most common response: {most_common['Response']} ({most_common['Count']} mentions, {most_common['Percentage']}% of respondents), \", end=\"\")\n",
    "print(f\"Least common response: {least_common['Response']} ({least_common['Count']} mentions, {least_common['Percentage']}% of respondents)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B.12.3 How confident are you in making ethical decisions during AI development?\n",
      "Total respondents: 15\n",
      "Breakdown of responses: Somewhat Confident: 6 responses (40.0%), Moderately Confident: 5 responses (33.33%), Extremely Confident: 4 responses (26.67%)\n",
      "Total mentions across all confidence levels: 15, Average mentions per confidence level: 5.00, Most common response: Somewhat Confident (6 mentions, 40.0% of respondents), Least common response: Extremely Confident (4 mentions, 26.67% of respondents)\n"
     ]
    }
   ],
   "source": [
    "####################\n",
    "# B.12.3\n",
    "####################\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Step 1: Read CSV file into a DataFrame\n",
    "df = pd.read_csv(ai_study)\n",
    "\n",
    "# Step 2: Exclude the first two rows\n",
    "df = df.iloc[2:]\n",
    "\n",
    "# Step 3: Remove NaNs or empty values in 'B.12.3'\n",
    "df = df[df['B.12.3'].notna()]  # Remove NaNs\n",
    "df['B.12.3'] = df['B.12.3'].astype(str).apply(lambda x: x.strip())\n",
    "df = df[df['B.12.3'] != \"\"]  # Remove empty strings\n",
    "\n",
    "# Step 4: Count occurrences of each response\n",
    "response_counts = df['B.12.3'].value_counts().reset_index()\n",
    "response_counts.columns = ['Response', 'Count']\n",
    "\n",
    "# Step 5: Calculate total number of valid responses\n",
    "total_valid_responses = df.shape[0]\n",
    "\n",
    "# Step 6: Calculate the percentage of each option based on valid responses\n",
    "response_counts['Percentage'] = (response_counts['Count'] / total_valid_responses * 100).round(2)\n",
    "\n",
    "# Step 7: Visualize the results with a Pie Chart using Plotly\n",
    "question_text = \"B.12.3 How confident are you in making ethical decisions during AI development?\"\n",
    "fig = px.pie(response_counts, names='Response', values='Count',\n",
    "             title=question_text,\n",
    "             color_discrete_sequence=px.colors.sequential.RdBu,\n",
    "             labels={'Response': 'Confidence Level', 'Count': 'Number of Responses'})\n",
    "\n",
    "# Add percentage text to the pie slices\n",
    "fig.update_traces(textposition='inside', textinfo='percent+label')\n",
    "\n",
    "# Step 8: Show the figure\n",
    "fig.show(renderer=\"browser\")\n",
    "\n",
    "# Step 9: Generate a statistical report\n",
    "print(question_text)\n",
    "\n",
    "print(f\"Total respondents: {total_valid_responses}\")\n",
    "print(\"Breakdown of responses:\", end=\" \")\n",
    "print(\", \".join([f\"{row['Response']}: {row['Count']} responses ({row['Percentage']}%)\" for _, row in response_counts.iterrows()]))\n",
    "\n",
    "total_mentions = response_counts['Count'].sum()\n",
    "average_mentions = total_mentions / len(response_counts)\n",
    "most_common = response_counts.iloc[0]\n",
    "least_common = response_counts.iloc[-1]\n",
    "\n",
    "print(f\"Total mentions across all confidence levels: {total_mentions}, \", end=\"\")\n",
    "print(f\"Average mentions per confidence level: {average_mentions:.2f}, \", end=\"\")\n",
    "print(f\"Most common response: {most_common['Response']} ({most_common['Count']} mentions, {most_common['Percentage']}% of respondents), \", end=\"\")\n",
    "print(f\"Least common response: {least_common['Response']} ({least_common['Count']} mentions, {least_common['Percentage']}% of respondents)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B.12.4 How do you ensure data privacy is maintained during AI testing? Select all that apply.\n",
      "Total respondents: 15\n",
      "Breakdown of responses: Using secure testing environments: 12 mentions (80.0% of respondents), Conducting privacy impact assessments: 7 mentions (46.67% of respondents), Anonymizing test data: 7 mentions (46.67% of respondents), Regularly updating privacy policies: 6 mentions (40.0% of respondents), Implementing access controls: 6 mentions (40.0% of respondents), Use of synthetic data: 2 mentions (13.33% of respondents), Prefer not to say: 1 mentions (6.67% of respondents)\n",
      "Total mentions across all methods: 41, Average mentions per method: 5.86, Most common method: Using secure testing environments (12 mentions, 80.0% of respondents), Least common method: Prefer not to say (1 mentions, 6.67% of respondents)\n"
     ]
    }
   ],
   "source": [
    "####################\n",
    "# B.12.4\n",
    "####################\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import re\n",
    "\n",
    "# Step 1: Read CSV file into a DataFrame\n",
    "df = pd.read_csv(ai_study)\n",
    "\n",
    "# Step 2: Exclude the first two rows\n",
    "df = df.iloc[2:]\n",
    "\n",
    "# Function to split responses and merge specific categories\n",
    "def split_and_merge_responses(response):\n",
    "    if pd.isna(response):\n",
    "        return []\n",
    "    # Split by comma, but keep commas within quotes\n",
    "    parts = re.split(r',\\s*(?=(?:[^\"]*\"[^\"]*\")*[^\"]*$)', response)\n",
    "    # Clean up each part and merge \"Other\" with \"please specify\"\n",
    "    cleaned_parts = []\n",
    "    for part in parts:\n",
    "        part = part.strip().strip('\"')\n",
    "        if part.lower() == 'other':\n",
    "            continue\n",
    "        elif part.lower().startswith('please specify'):\n",
    "            cleaned_parts.append('Other')\n",
    "        elif part:\n",
    "            cleaned_parts.append(part)\n",
    "    return cleaned_parts\n",
    "\n",
    "# Step 3: Process the responses using the split_and_merge_responses function\n",
    "df['B.12.4'] = df['B.12.4'].apply(split_and_merge_responses)\n",
    "\n",
    "# Step 4: Flatten the list of responses and count occurrences\n",
    "all_responses = df['B.12.4'].explode().dropna().value_counts().reset_index()\n",
    "all_responses.columns = ['Method', 'Count']\n",
    "\n",
    "# Step 5: Calculate total number of valid responses (rows with non-empty lists)\n",
    "total_valid_responses = df[df['B.12.4'].apply(len) > 0].shape[0]\n",
    "\n",
    "# Step 6: Calculate the percentage of rows that mention each method\n",
    "all_responses['Percentage'] = (all_responses['Count'] / total_valid_responses * 100).round(2)\n",
    "\n",
    "# Step 7: Visualize the results with a Bar Chart using Plotly\n",
    "question_text = \"B.12.4 How do you ensure data privacy is maintained during AI testing? Select all that apply.\"\n",
    "fig = px.bar(all_responses, x='Method', y='Count',\n",
    "             title=question_text,\n",
    "             labels={'Method': 'Privacy Maintenance Method', 'Count': 'Number of Mentions'},\n",
    "             color='Count',\n",
    "             color_continuous_scale='Blues',\n",
    "             text=all_responses['Percentage'].apply(lambda x: f'{x}% of respondents'))\n",
    "\n",
    "# Update layout to make the chart clearer\n",
    "fig.update_layout(xaxis_tickangle=45, xaxis_title='Privacy Maintenance Method', yaxis_title='Number of Mentions')\n",
    "\n",
    "# Step 8: Show the figure\n",
    "fig.show(renderer=\"browser\")\n",
    "\n",
    "# Step 9: Generate a statistical report\n",
    "print(question_text)\n",
    "\n",
    "print(f\"Total respondents: {total_valid_responses}\")\n",
    "print(\"Breakdown of responses:\", end=\" \")\n",
    "print(\", \".join([f\"{row['Method']}: {row['Count']} mentions ({row['Percentage']}% of respondents)\" for _, row in all_responses.iterrows()]))\n",
    "\n",
    "total_mentions = all_responses['Count'].sum()\n",
    "average_mentions = total_mentions / len(all_responses)\n",
    "most_common = all_responses.iloc[0]\n",
    "least_common = all_responses.iloc[-1]\n",
    "\n",
    "print(f\"Total mentions across all methods: {total_mentions}, \", end=\"\")\n",
    "print(f\"Average mentions per method: {average_mentions:.2f}, \", end=\"\")\n",
    "print(f\"Most common method: {most_common['Method']} ({most_common['Count']} mentions, {most_common['Percentage']}% of respondents), \", end=\"\")\n",
    "print(f\"Least common method: {least_common['Method']} ({least_common['Count']} mentions, {least_common['Percentage']}% of respondents)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
